{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SRGAN V2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1HaIiCDVYz7YqW5-SzmeBPrUXjQMrFbxV",
      "authorship_tag": "ABX9TyPkET/JyqeL/RzPtxabCcc2"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OInjcNGHLiFs",
        "colab_type": "code",
        "outputId": "8b95594d-7eff-4230-af69-8f336848d87d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 679
        }
      },
      "source": [
        "!pip install scipy==1.0.0\n",
        "!pip install numpy==1.17.4\n",
        "!pip install pyyaml h5py  # Required to save models in HDF5 format"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scipy==1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/5e/caa01ba7be11600b6a9d39265440d7b3be3d69206da887c42bef049521f2/scipy-1.0.0-cp36-cp36m-manylinux1_x86_64.whl (50.0MB)\n",
            "\u001b[K     |████████████████████████████████| 50.0MB 82kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy==1.0.0) (1.18.3)\n",
            "\u001b[31mERROR: tensorflow 2.2.0rc3 has requirement scipy==1.4.1; python_version >= \"3\", but you'll have scipy 1.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: seaborn 0.10.1 has requirement scipy>=1.0.1, but you'll have scipy 1.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: plotnine 0.6.0 has requirement scipy>=1.2.0, but you'll have scipy 1.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: cvxpy 1.0.31 has requirement scipy>=1.1.0, but you'll have scipy 1.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: scipy\n",
            "  Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "Successfully installed scipy-1.0.0\n",
            "Collecting numpy==1.17.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d2/ab/43e678759326f728de861edbef34b8e2ad1b1490505f20e0d1f0716c3bf4/numpy-1.17.4-cp36-cp36m-manylinux1_x86_64.whl (20.0MB)\n",
            "\u001b[K     |████████████████████████████████| 20.0MB 82.4MB/s \n",
            "\u001b[31mERROR: tensorflow 2.2.0rc3 has requirement scipy==1.4.1; python_version >= \"3\", but you'll have scipy 1.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: seaborn 0.10.1 has requirement scipy>=1.0.1, but you'll have scipy 1.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: plotnine 0.6.0 has requirement scipy>=1.2.0, but you'll have scipy 1.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: cvxpy 1.0.31 has requirement scipy>=1.1.0, but you'll have scipy 1.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Found existing installation: numpy 1.18.3\n",
            "    Uninstalling numpy-1.18.3:\n",
            "      Successfully uninstalled numpy-1.18.3\n",
            "Successfully installed numpy-1.17.4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (2.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from h5py) (1.17.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnMj8hQSWDes",
        "colab_type": "code",
        "outputId": "7c58f4f4-7d6b-4504-eda8-0ab92c4dbecd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVJQSW1NNTRm",
        "colab_type": "code",
        "outputId": "765b6ff2-246b-4524-ea52-40d11bc6a5f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "map2zxKGNVS9",
        "colab_type": "code",
        "outputId": "1e404d72-3161-4e21-f4de-4fdda811ffee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Import libraries\n",
        "import time\n",
        "import keras\n",
        "from keras import Input\n",
        "from keras.layers import BatchNormalization, Activation, Add, LeakyReLU, Dense, MaxPooling2D\n",
        "from keras.layers.advanced_activations import PReLU\n",
        "from keras.layers.convolutional import Conv2D, UpSampling2D, Conv2DTranspose\n",
        "from keras.applications import VGG19\n",
        "from keras.applications import ResNet50\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "import glob\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from scipy.misc import imresize, imread\n",
        "from keras import backend as K\n",
        "import math\n",
        "import numpy\n",
        "from skimage.measure import compare_ssim\n",
        "import csv\n",
        "import os.path"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6H8ucmwRDF0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_vgg():\n",
        "    \"\"\"\n",
        "    Builds a pre-trained VGG19 model that outputs image features extracted at the\n",
        "    third block of the model\n",
        "    \"\"\"\n",
        "    input_shape = (256, 256, 3)\n",
        "    vgg = VGG19(weights=\"imagenet\")\n",
        "    # Set the outputs to outputs of last conv. layer in block 3\n",
        "    # See architecture at: https://github.com/keras-team/keras/blob/master/keras/applications/vgg19.py\n",
        "    vgg.outputs = [vgg.layers[9].output]\n",
        "\n",
        "    img = Input(shape=input_shape)\n",
        "\n",
        "    # Extract the image features\n",
        "    img_features = vgg(img)\n",
        "\n",
        "    return Model(inputs=[img], outputs=[img_features], name='VGG')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bE6z0oexRWKP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Residual block for generator network\n",
        "def residual_block(x):\n",
        "    \"\"\"\n",
        "    Residual block\n",
        "    \"\"\"\n",
        "    filters = [64, 64]\n",
        "    kernel_size = 3\n",
        "    strides = 1\n",
        "    padding = \"same\"\n",
        "    momentum = 0.8\n",
        "    activation = PReLU()\n",
        "\n",
        "    res = Conv2D(filters=filters[0], kernel_size=kernel_size,\n",
        "                 strides=strides, padding=padding)(x)\n",
        "    res = Activation(activation=activation)(res)\n",
        "    res = BatchNormalization(momentum=momentum)(res)\n",
        "\n",
        "    res = Conv2D(filters=filters[1], kernel_size=kernel_size,\n",
        "                 strides=strides, padding=padding)(res)\n",
        "    res = BatchNormalization(momentum=momentum)(res)\n",
        "\n",
        "    # Add res and x\n",
        "    res = Add()([res, x])\n",
        "    return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMu-ti9ARZmK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_generator():\n",
        "    \"\"\"\n",
        "    Create a generator network using the hyperparameter values defined below\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    residual_blocks = 16\n",
        "    momentum = 0.8\n",
        "    input_shape = (64, 64, 3)\n",
        "    counter = 0\n",
        "\n",
        "    # Input Layer of the generator network\n",
        "    input_layer = Input(shape=input_shape)\n",
        "\n",
        "    # Add the pre-residual block\n",
        "    gen1 = Conv2D(filters=64, kernel_size=9, strides=1, padding='same')(input_layer)\n",
        "    gen1 = Activation(PReLU())(gen1)\n",
        "    # Add 16 residual blocks\n",
        "    res = residual_block(gen1)\n",
        "    for i in range(residual_blocks - 1):\n",
        "        res = residual_block(res)\n",
        "\n",
        "    # Add the post-residual block\n",
        "    gen2 = Conv2D(filters=64, kernel_size=3, strides=1, padding='same')(res)\n",
        "    gen2 = BatchNormalization(momentum=momentum)(gen2)\n",
        "\n",
        "    # Take the sum of the output from the pre-residual block(gen1) and\n",
        "    #  the post-residual block(gen2)\n",
        "    gen3 = Add(name='trial')([gen2, gen1])\n",
        "\n",
        "    # Add an upsampling block\n",
        "    gen4 = UpSampling2D(size=2)(gen3)\n",
        "    # gen4 = Conv2DTranspose(256, kernel_size=3, strides=2, padding='same')(gen3)\n",
        "    gen4 = Conv2D(filters=256, kernel_size=3, strides=1, padding='same')(gen4)\n",
        "    gen4 = Activation(PReLU())(gen4)\n",
        "\n",
        "    # Add another upsampling block\n",
        "    gen5 = UpSampling2D(size=2)(gen4)\n",
        "    # gen5 = Conv2DTranspose(256, kernel_size=3, strides=2, padding='same')(gen4)\n",
        "    gen5 = Conv2D(filters=256, kernel_size=3, strides=1, padding='same')(gen5)\n",
        "    gen5 = Activation(PReLU())(gen5)\n",
        "\n",
        "    # Output convolution layer\n",
        "    gen6 = Conv2D(filters=3, kernel_size=9, strides=1, padding='same', activation='tanh')(gen5)\n",
        "\n",
        "    # Auto-Encoder\n",
        "    x = Conv2D(512, (3, 3), activation='relu', strides=1, padding='same')(gen6)\n",
        "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "    x = Conv2D(256, (3, 3), activation='relu', strides=1, padding='same')(x)\n",
        "    encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "    # at this point the representation is (7, 7, 32)\n",
        "\n",
        "    x = Conv2D(256, (3, 3), activation='relu', strides=1, padding='same')(encoded)\n",
        "    x = UpSampling2D((2, 2))(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', strides=1, padding='same')(x)\n",
        "    x = UpSampling2D((2, 2))(x)\n",
        "    decoded = Conv2D(3, (3, 3), activation='tanh', strides=1, padding='same')(x)\n",
        "    # Keras model\n",
        "    model = Model(inputs=[input_layer], outputs=[decoded],\n",
        "                  name='generator')\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQZS_6AoTCEe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Discriminator Network\n",
        "def build_discriminator():\n",
        "    \"\"\"\n",
        "    Create a discriminator network using the hyperparameter values defined below\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    leakyrelu_alpha = 0.2\n",
        "    momentum = 0.8\n",
        "    input_shape = (256, 256, 3)\n",
        "\n",
        "    input_layer = Input(shape=input_shape)\n",
        "\n",
        "    # Add the first convolution block\n",
        "    dis1 = Conv2D(filters=64, kernel_size=3, strides=1, padding='same')(input_layer)\n",
        "    dis1 = LeakyReLU(alpha=leakyrelu_alpha)(dis1)\n",
        "\n",
        "    # Add the 2nd convolution block\n",
        "    dis2 = Conv2D(filters=64, kernel_size=3, strides=2, padding='same')(dis1)\n",
        "    dis2 = LeakyReLU(alpha=leakyrelu_alpha)(dis2)\n",
        "    dis2 = BatchNormalization(momentum=momentum)(dis2)\n",
        "\n",
        "    # Add the third convolution block\n",
        "    dis3 = Conv2D(filters=128, kernel_size=3, strides=1, padding='same')(dis2)\n",
        "    dis3 = LeakyReLU(alpha=leakyrelu_alpha)(dis3)\n",
        "    dis3 = BatchNormalization(momentum=momentum)(dis3)\n",
        "\n",
        "    # Add the fourth convolution block\n",
        "    dis4 = Conv2D(filters=128, kernel_size=3, strides=2, padding='same')(dis3)\n",
        "    dis4 = LeakyReLU(alpha=leakyrelu_alpha)(dis4)\n",
        "    dis4 = BatchNormalization(momentum=0.8)(dis4)\n",
        "\n",
        "    # Add the fifth convolution block\n",
        "    dis5 = Conv2D(256, kernel_size=3, strides=1, padding='same')(dis4)\n",
        "    dis5 = LeakyReLU(alpha=leakyrelu_alpha)(dis5)\n",
        "    dis5 = BatchNormalization(momentum=momentum)(dis5)\n",
        "\n",
        "    # Add the sixth convolution block\n",
        "    dis6 = Conv2D(filters=256, kernel_size=3, strides=2, padding='same')(dis5)\n",
        "    dis6 = LeakyReLU(alpha=leakyrelu_alpha)(dis6)\n",
        "    dis6 = BatchNormalization(momentum=momentum)(dis6)\n",
        "\n",
        "    # Add the seventh convolution block\n",
        "    dis7 = Conv2D(filters=512, kernel_size=3, strides=1, padding='same')(dis6)\n",
        "    dis7 = LeakyReLU(alpha=leakyrelu_alpha)(dis7)\n",
        "    dis7 = BatchNormalization(momentum=momentum)(dis7)\n",
        "\n",
        "    # Add the eight convolution block\n",
        "    dis8 = Conv2D(filters=512, kernel_size=3, strides=2, padding='same')(dis7)\n",
        "    dis8 = LeakyReLU(alpha=leakyrelu_alpha)(dis8)\n",
        "    dis8 = BatchNormalization(momentum=momentum)(dis8)\n",
        "\n",
        "    # Add a dense layer\n",
        "    dis9 = Dense(units=1024)(dis8)\n",
        "    dis9 = LeakyReLU(alpha=0.2)(dis9)\n",
        "\n",
        "    # Last dense layer - for classification\n",
        "    output_gen = Dense(units=1, activation='sigmoid')(dis9)\n",
        "\n",
        "    model = Model(inputs=[input_layer], outputs=[output_gen], name='discriminator')\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAFaG293TDAD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample_images(data_dir, batch_size, high_resolution_shape, low_resolution_shape):\n",
        "\n",
        "    # Make a list of all images inside the data directory\n",
        "    all_images = data_dir\n",
        "\n",
        "    # Choose a random batch of images\n",
        "    images_batch = np.random.choice(all_images, size=batch_size)\n",
        "\n",
        "    low_resolution_images = []\n",
        "    high_resolution_images = []\n",
        "\n",
        "    for img in images_batch:\n",
        "        # Get an ndarray of the current image\n",
        "        img1 = imread(img, mode='RGB')\n",
        "        img1 = img1.astype(np.float32)\n",
        "\n",
        "        # Resize the image\n",
        "        img1_high_resolution = imresize(img1, high_resolution_shape)\n",
        "        img1_low_resolution = imresize(img1, low_resolution_shape)\n",
        "\n",
        "        # Do a random horizontal flip\n",
        "        if np.random.random() < 0.5:\n",
        "          img1_high_resolution = np.fliplr(img1_high_resolution)\n",
        "          img1_low_resolution = np.fliplr(img1_low_resolution)\n",
        "\n",
        "        high_resolution_images.append(img1_high_resolution)\n",
        "        low_resolution_images.append(img1_low_resolution)\n",
        "\n",
        "    # Convert the lists to Numpy NDArrays\n",
        "    return np.array(high_resolution_images), np.array(low_resolution_images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoak84fTTJ20",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_images(low_resolution_images, high_resolution_images, generated_images, path):\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(1, 3, 1)\n",
        "    ax.imshow(low_resolution_images[0])\n",
        "    ax.axis(\"off\")\n",
        "    ax.set_title(\"Low Resolution\")\n",
        "\n",
        "    ax = fig.add_subplot(1, 3, 2)\n",
        "    ax.imshow(high_resolution_images[0])\n",
        "    ax.axis(\"off\")\n",
        "    ax.set_title(\"Original\")\n",
        "\n",
        "    ax = fig.add_subplot(1, 3, 3)\n",
        "    ax.imshow(generated_images[0])\n",
        "    ax.axis(\"off\")\n",
        "    ax.set_title(\"Generated\")\n",
        "\n",
        "    plt.savefig(path)\n",
        "    plt.clf()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDqDEEAkThLl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def PSNR(true_image, predicted_image):\n",
        "    mse = numpy.mean((true_image - predicted_image) ** 2)\n",
        "    Pixel_max = 1.0\n",
        "    return 20 * math.log10(Pixel_max / math.sqrt(mse))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBrMMq2PThq1",
        "colab_type": "code",
        "outputId": "7a624477-983c-4ed9-a2d9-358c75e4aa0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "filepath = '/content/gdrive/My Drive/Dataset/Saved_Weights/'\n",
        "if __name__ == '__main__':\n",
        "    # Define hyperparameters\n",
        "    data_dir = glob('./Dataset/*')\n",
        "    epochs = 10001\n",
        "    batch_size = 2\n",
        "    lr = 0.0002\n",
        "    mode = 'train'\n",
        "    # Shape of low-resolution and high-resolution images\n",
        "    low_resolution_shape = (64, 64, 3)\n",
        "    high_resolution_shape = (256, 256, 3)\n",
        "\n",
        "    # Common optimizer for all networks\n",
        "    common_optimizer = Adam(lr, 0.9)\n",
        "\n",
        "    # Training the model\n",
        "    if mode == 'train':\n",
        "\n",
        "        # Building and compiling the networks\n",
        "        vgg = build_vgg()\n",
        "        vgg.trainable = False\n",
        "        # print(\"VGG\")\n",
        "        # print(vgg.summary())\n",
        "        vgg.compile(optimizer=common_optimizer, loss='mse', metrics=['accuracy'])\n",
        "\n",
        "        discriminator = build_discriminator()\n",
        "        # print(\"discrminator\")\n",
        "        # print(discriminator.summary())\n",
        "        discriminator.load_weights(\"/content/gdrive/My Drive/Dataset/Saved_Weights/discriminator_imagenet1.hdf5\")\n",
        "        discriminator.compile(optimizer=common_optimizer, loss='mse', metrics=['accuracy'])\n",
        "        print(discriminator.metrics_names)\n",
        "\n",
        "        generator = build_generator()\n",
        "        print(\"generator\")\n",
        "        print(generator.summary())\n",
        "\n",
        "        # Building and compiling the adversarial network\n",
        "        # High and Low resolution inputs to the network\n",
        "        input_high_resolution = Input(shape=high_resolution_shape)\n",
        "        input_low_resolution = Input(shape=low_resolution_shape)\n",
        "\n",
        "        # Generating high resolution images from the generator\n",
        "        generated_high_resolution_images = generator(input_low_resolution)\n",
        "\n",
        "        # Extracting high resolution features using VGG network\n",
        "        features = vgg(generated_high_resolution_images)\n",
        "\n",
        "        # Discriminator model is turned off during adversarial training\n",
        "        discriminator.trainable = False\n",
        "        discriminator.load_weights(\"/content/gdrive/My Drive/Dataset/Saved_Weights/discriminator_imagenet1.hdf5\")\n",
        "        discriminator.compile(optimizer=common_optimizer, loss='mse', metrics=['accuracy'])\n",
        "\n",
        "        # Probability of generated high resolution images\n",
        "        probs = discriminator(generated_high_resolution_images)\n",
        "\n",
        "        # Creating the adversarial model\n",
        "        adversarial_model = Model([input_low_resolution, input_high_resolution], [probs, features])\n",
        "        # print(\"Adversarial\")\n",
        "        # print(adversarial_model.summary())\n",
        "        adversarial_model.load_weights(\"/content/gdrive/My Drive/Dataset/Saved_Weights/adversarial_model_imagenet1.hdf5\")\n",
        "        adversarial_model.compile(optimizer=common_optimizer, loss=['binary_crossentropy', 'mse'],\n",
        "                                  loss_weights=[1e-3, 1])\n",
        "        # print(adversarial_model.metrics_names)\n",
        "\n",
        "        # Add Tensorboard\n",
        "        # tensorboard = TensorBoard(log_dir=\"logs_imagenet_res/\".format(time.time()))\n",
        "        # tensorboard.set_model(generator)\n",
        "        # tensorboard.set_model(discriminator)\n",
        "\n",
        "        # Training\n",
        "        for epoch in range(epochs):\n",
        "            print(\"Epoch :{}\".format(epoch))\n",
        "            # experiment.log_parameter('epoch', epoch)\n",
        "\n",
        "            # Training the discriminator network\n",
        "\n",
        "            high_resolution_images, low_resolution_images = sample_images(data_dir=data_dir, batch_size=batch_size,\n",
        "                                                                          high_resolution_shape=high_resolution_shape,\n",
        "                                                                          low_resolution_shape=low_resolution_shape)\n",
        "            high_resolution_images = high_resolution_images / 255.0\n",
        "            low_resolution_images = low_resolution_images / 255.0\n",
        "\n",
        "            generated_high_resolution_images = generator.predict(low_resolution_images)\n",
        "\n",
        "            # Generating batch of real and fake labels\n",
        "            real_labels = np.ones((batch_size, 16, 16, 1))\n",
        "            fake_labels = np.zeros((batch_size, 16, 16, 1))\n",
        "\n",
        "            d_loss_real = discriminator.train_on_batch(high_resolution_images, real_labels)\n",
        "            d_loss_fake = discriminator.train_on_batch(generated_high_resolution_images, fake_labels)\n",
        "\n",
        "            # write_log(tensorboard, 'd_loss_real', d_loss_real[0], epoch)\n",
        "            # write_log(tensorboard, 'd_loss_real_acc', d_loss_real[1], epoch)\n",
        "            # write_log(tensorboard, 'd_loss_fake', d_loss_fake[0], epoch)\n",
        "            # write_log(tensorboard, 'd_loss_fake_acc', d_loss_fake[1], epoch)\n",
        "\n",
        "            # Data logging to csv\n",
        "            with open('/content/gdrive/My Drive/Dataset/LossAndAccuracy/d_loss_real.csv', 'a', newline='') as myfile:\n",
        "                fileEmpty = os.stat('/content/gdrive/My Drive/Dataset/LossAndAccuracy/d_loss_real.csv').st_size == 0\n",
        "            \n",
        "                wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
        "                headers = ['Loss', 'Acc']\n",
        "                writer = csv.DictWriter(myfile, fieldnames=headers)\n",
        "            \n",
        "                if fileEmpty:\n",
        "                    writer.writeheader()\n",
        "            \n",
        "                wr.writerow(d_loss_real)\n",
        "            \n",
        "            with open('/content/gdrive/My Drive/Dataset/LossAndAccuracy/d_loss_fake.csv', 'a', newline='') as myfile:\n",
        "                fileEmpty = os.stat('/content/gdrive/My Drive/Dataset/LossAndAccuracy/d_loss_fake.csv').st_size == 0\n",
        "            \n",
        "                wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
        "                headers = ['Loss', 'Acc']\n",
        "                writer = csv.DictWriter(myfile, fieldnames=headers)\n",
        "            \n",
        "                if fileEmpty:\n",
        "                    writer.writeheader()\n",
        "            \n",
        "                wr.writerow(d_loss_fake)\n",
        "\n",
        "            # Calculating the discriminator loss\n",
        "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "            print(\"d_loss :\", d_loss)\n",
        "            # print(type(d_loss))\n",
        "\n",
        "            # Data logging to csv\n",
        "            with open('/content/gdrive/My Drive/Dataset/LossAndAccuracy/d_loss.csv', 'a', newline='') as myfile:\n",
        "                fileEmpty = os.stat('/content/gdrive/My Drive/Dataset/LossAndAccuracy/d_loss.csv').st_size == 0\n",
        "                wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
        "                headers = ['Loss', 'Acc']\n",
        "                writer = csv.DictWriter(myfile, fieldnames=headers)\n",
        "            \n",
        "                if fileEmpty:\n",
        "                    writer.writeheader()\n",
        "                wr.writerow(d_loss)\n",
        "\n",
        "            # Training the generator network\n",
        "            high_resolution_images, low_resolution_images = sample_images(data_dir=data_dir, batch_size=batch_size,\n",
        "                                                                          high_resolution_shape=high_resolution_shape,\n",
        "                                                                          low_resolution_shape=low_resolution_shape)\n",
        "\n",
        "            high_resolution_images = high_resolution_images / 255.0\n",
        "            low_resolution_images = low_resolution_images / 255.0\n",
        "\n",
        "            real_labels = np.ones((batch_size, 16, 16, 1))\n",
        "\n",
        "            image_features = vgg.predict(high_resolution_images)\n",
        "\n",
        "            g_loss = adversarial_model.train_on_batch([low_resolution_images, high_resolution_images],\n",
        "                                                      [real_labels, image_features])\n",
        "            print(\"g_loss :\", g_loss)\n",
        "            # print(type(g_loss))\n",
        "\n",
        "            # Data logging to csv\n",
        "            with open('/content/gdrive/My Drive/Dataset/LossAndAccuracy/g_loss.csv', 'a', newline='') as myfile:\n",
        "                fileEmpty = os.stat('/content/gdrive/My Drive/Dataset/LossAndAccuracy/g_loss.csv').st_size == 0\n",
        "                wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
        "                headers = ['Loss', 'Discriminator_loss', 'vgg_loss']\n",
        "                writer = csv.DictWriter(myfile, fieldnames=headers)\n",
        "            \n",
        "                if fileEmpty:\n",
        "                    writer.writeheader()\n",
        "                wr.writerow(g_loss)\n",
        "\n",
        "            # Write the losses to Tensorboard\n",
        "            # write_log(tensorboard, 'g_loss', g_loss[0], epoch)\n",
        "            # write_log(tensorboard, 'discriminator_loss', g_loss[1], epoch)\n",
        "            # write_log(tensorboard, 'ResNet_loss', g_loss[2], epoch)\n",
        "\n",
        "            # write_log(tensorboard, 'd_loss', d_loss[0], epoch)\n",
        "            # write_log(tensorboard, 'd_acc', d_loss[1], epoch)\n",
        "\n",
        "            # Saving images\n",
        "            if epoch % 100 == 0:\n",
        "                high_resolution_images, low_resolution_images = sample_images(data_dir=data_dir, batch_size=batch_size,\n",
        "                                                                              high_resolution_shape=high_resolution_shape,\n",
        "                                                                              low_resolution_shape=low_resolution_shape)\n",
        "                # Normalizing the images\n",
        "                high_resolution_images = high_resolution_images / 255.0\n",
        "                low_resolution_images = low_resolution_images / 255.0\n",
        "\n",
        "                generated_images = generator.predict_on_batch(low_resolution_images)\n",
        "\n",
        "                # low_resolution_images = 0.5 * low_resolution_images + 0.5\n",
        "                # generated_images = 0.5 * generated_images + 0.5\n",
        "                # high_resolution_images = 0.5 * high_resolution_images + 0.5\n",
        "\n",
        "                for index, img in enumerate(generated_images):\n",
        "                    save_images(low_resolution_images, high_resolution_images, generated_images,\n",
        "                                path=\"/content/gdrive/My Drive/Dataset/Epoch_Images/img_{}\".format(epoch))\n",
        "\n",
        "                # Calculating PSNR and SSIM metrics\n",
        "                psnr = PSNR(high_resolution_images[0], generated_images[0])\n",
        "                print(\"PSNR: {}\".format(psnr))\n",
        "                psnr = [float(psnr)]\n",
        "                # with open('PSNR', 'a', newline='') as myfileg:\n",
        "                #     wr = csv.writer(myfileg, quoting=csv.QUOTE_ALL)\n",
        "                #     wr.writerow(psnr)\n",
        "\n",
        "                (score, diff) = compare_ssim(high_resolution_images[0], generated_images[0], full=True,\n",
        "                                             multichannel=True)\n",
        "                print(\"SSIM: {}\".format(score))\n",
        "                score = [float(score)]\n",
        "                # with open('SSIM', 'a', newline='') as myfileg:\n",
        "                #     wr = csv.writer(myfileg, quoting=csv.QUOTE_ALL)\n",
        "                #     wr.writerow(score)\n",
        "\n",
        "            adversarial_model.save_weights(\"/content/gdrive/My Drive/Dataset/Saved_Weights/adversarial_model_imagenet1.hdf5\")\n",
        "            discriminator.save_weights(\"/content/gdrive/My Drive/Dataset/Saved_Weights/discriminator_imagenet1.hdf5\")\n",
        "            generator.save_weights(\"/content/gdrive/My Drive/Dataset/Saved_Weights/generator_imagenet.hdf5\")\n",
        "            vgg.save_weights(\"/content/gdrive/My Drive/Dataset/Saved_Weights/vgg_imagenet.hdf5\")\n",
        "        # Predict Results\n",
        "    if mode == 'Predict':\n",
        "        # Build discriminator and generator\n",
        "        discriminator = build_discriminator()\n",
        "        generator = build_generator()\n",
        "\n",
        "        # Load weights from training\n",
        "        discriminator.load_weights(\"discriminator_imagenet_res.h5\")\n",
        "        generator.load_weights(\"generator_imagenet_res.h5\")\n",
        "\n",
        "        # Load test images\n",
        "        data_dir = glob('./Predict/*')\n",
        "        high_resolution_images, low_resolution_images = sample_images(data_dir=data_dir, batch_size=2,\n",
        "                                                                      high_resolution_shape=high_resolution_shape,\n",
        "                                                                      low_resolution_shape=low_resolution_shape)\n",
        "        # Normalizing the image\n",
        "        high_resolution_images = high_resolution_images / 255.0\n",
        "        low_resolution_images = low_resolution_images / 255.0\n",
        "\n",
        "        generated_images = generator.predict_on_batch(low_resolution_images)\n",
        "\n",
        "        # low_resolution_images = 0.5 * low_resolution_images + 0.5\n",
        "        # generated_images = 0.5 * generated_images + 0.5\n",
        "        # high_resolution_images = 0.5 * high_resolution_images + 0.5\n",
        "\n",
        "        # Calculating PSNR and SSIM of images\n",
        "        psnr1 = PSNR(high_resolution_images[0], generated_images[0])\n",
        "        (score1, diff1) = compare_ssim(high_resolution_images[0], generated_images[0], full=True, multichannel=True)\n",
        "        print(\"PSNR_first_image: {}\".format(psnr1))\n",
        "        print(\"SSIM_first_image: {}\".format(score1))\n",
        "\n",
        "        psnr2 = PSNR(high_resolution_images[1], generated_images[1])\n",
        "        (score2, diff2) = compare_ssim(high_resolution_images[1], generated_images[1], full=True, multichannel=True)\n",
        "        print(\"PSNR_second_image: {}\".format(psnr2))\n",
        "        print(\"SSIM_second_image: {}\".format(score2))\n",
        "\n",
        "        # Saving images\n",
        "        for index, img in enumerate(generated_images):\n",
        "            save_images(low_resolution_images, high_resolution_images, generated_images,\n",
        "                        path=\"results/gen_{}\".format(index))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels.h5\n",
            "574717952/574710816 [==============================] - 35s 0us/step\n",
            "['loss', 'accuracy']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/activations.py:235: UserWarning: Do not pass a layer instance (such as PReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
            "  identifier=identifier.__class__.__name__))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "generator\n",
            "Model: \"generator\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            (None, 64, 64, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 64, 64, 64)   15616       input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 64, 64, 64)   262144      conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 64, 64, 64)   36928       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 64, 64, 64)   262144      conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 64, 64, 64)   256         activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 64, 64, 64)   36928       batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 64, 64, 64)   256         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 64, 64, 64)   0           batch_normalization_9[0][0]      \n",
            "                                                                 activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 64, 64, 64)   36928       add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 64, 64, 64)   262144      conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 64, 64, 64)   256         activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 64, 64, 64)   36928       batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 64, 64, 64)   256         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 64, 64, 64)   0           batch_normalization_11[0][0]     \n",
            "                                                                 add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 64, 64, 64)   36928       add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 64, 64, 64)   262144      conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 64, 64, 64)   256         activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 64, 64, 64)   36928       batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 64, 64, 64)   256         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 64, 64, 64)   0           batch_normalization_13[0][0]     \n",
            "                                                                 add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 64, 64, 64)   36928       add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 64, 64, 64)   262144      conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 64, 64, 64)   256         activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 64, 64, 64)   36928       batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 64, 64, 64)   256         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 64, 64, 64)   0           batch_normalization_15[0][0]     \n",
            "                                                                 add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 64, 64, 64)   36928       add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 64, 64, 64)   262144      conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 64, 64, 64)   256         activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 64, 64, 64)   36928       batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 64, 64, 64)   256         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 64, 64, 64)   0           batch_normalization_17[0][0]     \n",
            "                                                                 add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 64, 64, 64)   36928       add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 64, 64, 64)   262144      conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 64, 64, 64)   256         activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 64, 64, 64)   36928       batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 64, 64, 64)   256         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 64, 64, 64)   0           batch_normalization_19[0][0]     \n",
            "                                                                 add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 64, 64, 64)   36928       add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 64, 64, 64)   262144      conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 64, 64, 64)   256         activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 64, 64, 64)   36928       batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 64, 64, 64)   256         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 64, 64, 64)   0           batch_normalization_21[0][0]     \n",
            "                                                                 add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 64, 64, 64)   36928       add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 64, 64, 64)   262144      conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 64, 64, 64)   256         activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 64, 64, 64)   36928       batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 64, 64, 64)   256         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 64, 64, 64)   0           batch_normalization_23[0][0]     \n",
            "                                                                 add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 64, 64, 64)   36928       add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 64, 64, 64)   262144      conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 64, 64, 64)   256         activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 64, 64, 64)   36928       batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 64, 64, 64)   256         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 64, 64, 64)   0           batch_normalization_25[0][0]     \n",
            "                                                                 add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 64, 64, 64)   36928       add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 64, 64, 64)   262144      conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 64, 64, 64)   256         activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 64, 64, 64)   36928       batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 64, 64, 64)   256         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 64, 64, 64)   0           batch_normalization_27[0][0]     \n",
            "                                                                 add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 64, 64, 64)   36928       add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 64, 64, 64)   262144      conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 64, 64, 64)   256         activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 64, 64, 64)   36928       batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 64, 64, 64)   256         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 64, 64, 64)   0           batch_normalization_29[0][0]     \n",
            "                                                                 add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 64, 64, 64)   36928       add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 64, 64, 64)   262144      conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 64, 64, 64)   256         activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 64, 64, 64)   36928       batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 64, 64, 64)   256         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 64, 64, 64)   0           batch_normalization_31[0][0]     \n",
            "                                                                 add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 64, 64, 64)   36928       add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 64, 64, 64)   262144      conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 64, 64, 64)   256         activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 64, 64, 64)   36928       batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 64, 64, 64)   256         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 64, 64, 64)   0           batch_normalization_33[0][0]     \n",
            "                                                                 add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 64, 64, 64)   36928       add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 64, 64, 64)   262144      conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 64, 64, 64)   256         activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 64, 64, 64)   36928       batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 64, 64, 64)   256         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 64, 64, 64)   0           batch_normalization_35[0][0]     \n",
            "                                                                 add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 64, 64, 64)   36928       add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 64, 64, 64)   262144      conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 64, 64, 64)   256         activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 64, 64, 64)   36928       batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 64, 64, 64)   256         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 64, 64, 64)   0           batch_normalization_37[0][0]     \n",
            "                                                                 add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 64, 64, 64)   36928       add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 64, 64, 64)   262144      conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 64, 64, 64)   256         activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 64, 64, 64)   36928       batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 64, 64, 64)   256         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 64, 64, 64)   0           batch_normalization_39[0][0]     \n",
            "                                                                 add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 64, 64, 64)   36928       add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 64, 64, 64)   256         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "trial (Add)                     (None, 64, 64, 64)   0           batch_normalization_40[0][0]     \n",
            "                                                                 activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, 128, 128, 64) 0           trial[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 128, 128, 256 147712      up_sampling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 128, 128, 256 4194304     conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, 256, 256, 256 0           activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 256, 256, 256 590080      up_sampling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 256, 256, 256 16777216    conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 256, 256, 3)  62211       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 256, 256, 512 14336       conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 512 0           conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 128, 128, 256 1179904     max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 256)  0           conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 64, 64, 256)  590080      max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2D)  (None, 128, 128, 256 0           conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 128, 128, 512 1180160     up_sampling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_4 (UpSampling2D)  (None, 256, 256, 512 0           conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 256, 256, 3)  13827       up_sampling2d_4[0][0]            \n",
            "==================================================================================================\n",
            "Total params: 30,448,966\n",
            "Trainable params: 30,444,742\n",
            "Non-trainable params: 4,224\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Epoch :0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: DeprecationWarning: `imread` is deprecated!\n",
            "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``imageio.imread`` instead.\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: DeprecationWarning: `imresize` is deprecated!\n",
            "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``skimage.transform.resize`` instead.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: DeprecationWarning: `imresize` is deprecated!\n",
            "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``skimage.transform.resize`` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "d_loss : [0.27275056 0.484375  ]\n",
            "g_loss : [0.50739014, 0.8361127, 0.506554]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: DeprecationWarning: `imread` is deprecated!\n",
            "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``imageio.imread`` instead.\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: DeprecationWarning: `imresize` is deprecated!\n",
            "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``skimage.transform.resize`` instead.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: DeprecationWarning: `imresize` is deprecated!\n",
            "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``skimage.transform.resize`` instead.\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:202: UserWarning: DEPRECATED: skimage.measure.compare_ssim has been moved to skimage.metrics.structural_similarity. It will be removed from skimage.measure in version 0.18.\n",
            "/usr/local/lib/python3.6/dist-packages/skimage/metrics/_structural_similarity.py:108: UserWarning: Inputs have mismatched dtype.  Setting data_range based on im1.dtype.\n",
            "  im2[..., ch], **args)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "PSNR: 23.833934280880698\n",
            "SSIM: 0.8909499790088712\n",
            "Epoch :1\n",
            "d_loss : [0.27241898 0.5205078 ]\n",
            "g_loss : [0.6328673, 0.8376199, 0.63202965]\n",
            "Epoch :2\n",
            "d_loss : [0.2770346  0.49609375]\n",
            "g_loss : [0.6708996, 0.84977806, 0.67004985]\n",
            "Epoch :3\n",
            "d_loss : [0.27416676 0.4892578 ]\n",
            "g_loss : [0.5292595, 0.85334516, 0.52840614]\n",
            "Epoch :4\n",
            "d_loss : [0.27394867 0.49121094]\n",
            "g_loss : [0.74185246, 0.83928233, 0.74101317]\n",
            "Epoch :5\n",
            "d_loss : [0.28013086 0.51171875]\n",
            "g_loss : [0.5528078, 0.84650755, 0.5519613]\n",
            "Epoch :6\n",
            "d_loss : [0.27509    0.48828125]\n",
            "g_loss : [0.8282193, 0.85060096, 0.8273687]\n",
            "Epoch :7\n",
            "d_loss : [0.2765807  0.48046875]\n",
            "g_loss : [0.31870145, 0.84074855, 0.3178607]\n",
            "Epoch :8\n",
            "d_loss : [0.27451313 0.4951172 ]\n",
            "g_loss : [0.5602223, 0.8215615, 0.55940074]\n",
            "Epoch :9\n",
            "d_loss : [0.27421662 0.49609375]\n",
            "g_loss : [0.70405024, 0.83582485, 0.7032144]\n",
            "Epoch :10\n",
            "d_loss : [0.27481443 0.5058594 ]\n",
            "g_loss : [0.47430447, 0.83400786, 0.47347045]\n",
            "Epoch :11\n",
            "d_loss : [0.27622887 0.49804688]\n",
            "g_loss : [0.8565399, 0.8342478, 0.8557057]\n",
            "Epoch :12\n",
            "d_loss : [0.2733036 0.5      ]\n",
            "g_loss : [0.4588783, 0.8509486, 0.45802736]\n",
            "Epoch :13\n",
            "d_loss : [0.27660346 0.49902344]\n",
            "g_loss : [0.80601186, 0.82420015, 0.80518764]\n",
            "Epoch :14\n",
            "d_loss : [0.27461916 0.5048828 ]\n",
            "g_loss : [0.37266827, 0.84072125, 0.37182754]\n",
            "Epoch :15\n",
            "d_loss : [0.27755147 0.50097656]\n",
            "g_loss : [0.8113698, 0.849259, 0.8105205]\n",
            "Epoch :16\n",
            "d_loss : [0.27383018 0.484375  ]\n",
            "g_loss : [0.4930601, 0.8402441, 0.49221987]\n",
            "Epoch :17\n",
            "d_loss : [0.27627292 0.4892578 ]\n",
            "g_loss : [0.577709, 0.84010875, 0.5768689]\n",
            "Epoch :18\n",
            "d_loss : [0.27462202 0.49023438]\n",
            "g_loss : [0.772087, 0.8446913, 0.77124226]\n",
            "Epoch :19\n",
            "d_loss : [0.2754646  0.49121094]\n",
            "g_loss : [0.9240039, 0.83618176, 0.9231677]\n",
            "Epoch :20\n",
            "d_loss : [0.27517706 0.48632812]\n",
            "g_loss : [0.65099627, 0.8274672, 0.6501688]\n",
            "Epoch :21\n",
            "d_loss : [0.27370054 0.49609375]\n",
            "g_loss : [0.5941544, 0.8312577, 0.5933232]\n",
            "Epoch :22\n",
            "d_loss : [0.27054846 0.5097656 ]\n",
            "g_loss : [0.5093514, 0.8398402, 0.50851154]\n",
            "Epoch :23\n",
            "d_loss : [0.2761372  0.50683594]\n",
            "g_loss : [0.72942287, 0.8220327, 0.72860086]\n",
            "Epoch :24\n",
            "d_loss : [0.272881   0.50390625]\n",
            "g_loss : [0.6866012, 0.8181112, 0.6857831]\n",
            "Epoch :25\n",
            "d_loss : [0.27809888 0.49414062]\n",
            "g_loss : [0.5381741, 0.83718264, 0.5373369]\n",
            "Epoch :26\n",
            "d_loss : [0.27439857 0.5048828 ]\n",
            "g_loss : [0.6037944, 0.83703387, 0.60295737]\n",
            "Epoch :27\n",
            "d_loss : [0.27451503 0.49414062]\n",
            "g_loss : [0.57185876, 0.84483814, 0.5710139]\n",
            "Epoch :28\n",
            "d_loss : [0.27438158 0.50097656]\n",
            "g_loss : [0.6279772, 0.8382476, 0.627139]\n",
            "Epoch :29\n",
            "d_loss : [0.2756691  0.50683594]\n",
            "g_loss : [0.60906875, 0.84591377, 0.60822284]\n",
            "Epoch :30\n",
            "d_loss : [0.2761485  0.49121094]\n",
            "g_loss : [0.58427346, 0.8157368, 0.5834577]\n",
            "Epoch :31\n",
            "d_loss : [0.2714781 0.515625 ]\n",
            "g_loss : [0.62128043, 0.8491225, 0.6204313]\n",
            "Epoch :32\n",
            "d_loss : [0.27154216 0.5019531 ]\n",
            "g_loss : [0.6190666, 0.829952, 0.61823666]\n",
            "Epoch :33\n",
            "d_loss : [0.27140677 0.51953125]\n",
            "g_loss : [0.5469993, 0.83423924, 0.54616505]\n",
            "Epoch :34\n",
            "d_loss : [0.27879882 0.49902344]\n",
            "g_loss : [0.5268246, 0.85486794, 0.52596974]\n",
            "Epoch :35\n",
            "d_loss : [0.27268386 0.49902344]\n",
            "g_loss : [0.63841254, 0.8466889, 0.63756585]\n",
            "Epoch :36\n",
            "d_loss : [0.2736103 0.5078125]\n",
            "g_loss : [0.8747412, 0.834219, 0.87390697]\n",
            "Epoch :37\n",
            "d_loss : [0.27667397 0.49414062]\n",
            "g_loss : [0.55183125, 0.8440528, 0.5509872]\n",
            "Epoch :38\n",
            "d_loss : [0.27477962 0.5058594 ]\n",
            "g_loss : [0.64880574, 0.845816, 0.64795995]\n",
            "Epoch :39\n",
            "d_loss : [0.27626216 0.5136719 ]\n",
            "g_loss : [0.7431297, 0.8427446, 0.7422869]\n",
            "Epoch :40\n",
            "d_loss : [0.27474695 0.47460938]\n",
            "g_loss : [0.93202317, 0.8302108, 0.93119293]\n",
            "Epoch :41\n",
            "d_loss : [0.27502155 0.5019531 ]\n",
            "g_loss : [0.48068, 0.83008444, 0.4798499]\n",
            "Epoch :42\n",
            "d_loss : [0.2730965  0.49902344]\n",
            "g_loss : [0.5508716, 0.834617, 0.55003697]\n",
            "Epoch :43\n",
            "d_loss : [0.27754313 0.49609375]\n",
            "g_loss : [0.7070638, 0.8382909, 0.7062255]\n",
            "Epoch :44\n",
            "d_loss : [0.27371967 0.50390625]\n",
            "g_loss : [0.6908172, 0.82270396, 0.68999445]\n",
            "Epoch :45\n",
            "d_loss : [0.2708312  0.50683594]\n",
            "g_loss : [0.6769367, 0.82481027, 0.6761119]\n",
            "Epoch :46\n",
            "d_loss : [0.27386642 0.50097656]\n",
            "g_loss : [0.94129056, 0.8442098, 0.9404464]\n",
            "Epoch :47\n",
            "d_loss : [0.27481607 0.48339844]\n",
            "g_loss : [0.70501, 0.84865606, 0.70416135]\n",
            "Epoch :48\n",
            "d_loss : [0.27878374 0.50097656]\n",
            "g_loss : [0.6929317, 0.84023094, 0.69209146]\n",
            "Epoch :49\n",
            "d_loss : [0.2767532 0.5058594]\n",
            "g_loss : [0.8166464, 0.83253664, 0.81581384]\n",
            "Epoch :50\n",
            "d_loss : [0.27419782 0.5       ]\n",
            "g_loss : [0.9225574, 0.8330397, 0.9217244]\n",
            "Epoch :51\n",
            "d_loss : [0.27375764 0.51660156]\n",
            "g_loss : [0.9053663, 0.84876394, 0.90451753]\n",
            "Epoch :52\n",
            "d_loss : [0.27661836 0.5019531 ]\n",
            "g_loss : [0.78285784, 0.8354018, 0.7820224]\n",
            "Epoch :53\n",
            "d_loss : [0.2744434 0.5048828]\n",
            "g_loss : [0.9231058, 0.84013283, 0.92226565]\n",
            "Epoch :54\n",
            "d_loss : [0.2743356  0.49804688]\n",
            "g_loss : [0.74941146, 0.82626116, 0.7485852]\n",
            "Epoch :55\n",
            "d_loss : [0.2753634  0.48828125]\n",
            "g_loss : [0.623168, 0.83936393, 0.62232864]\n",
            "Epoch :56\n",
            "d_loss : [0.2766921  0.48632812]\n",
            "g_loss : [0.68835366, 0.849826, 0.6875038]\n",
            "Epoch :57\n",
            "d_loss : [0.27687693 0.5       ]\n",
            "g_loss : [0.6488415, 0.8187605, 0.6480227]\n",
            "Epoch :58\n",
            "d_loss : [0.27618623 0.50390625]\n",
            "g_loss : [0.567653, 0.84548736, 0.5668075]\n",
            "Epoch :59\n",
            "d_loss : [0.2740146  0.50097656]\n",
            "g_loss : [0.7859622, 0.8408241, 0.7851214]\n",
            "Epoch :60\n",
            "d_loss : [0.27816916 0.4970703 ]\n",
            "g_loss : [0.5575456, 0.84095865, 0.55670464]\n",
            "Epoch :61\n",
            "d_loss : [0.27202398 0.5029297 ]\n",
            "g_loss : [0.67501485, 0.84863, 0.6741662]\n",
            "Epoch :62\n",
            "d_loss : [0.27763674 0.49804688]\n",
            "g_loss : [0.5668675, 0.85474396, 0.56601274]\n",
            "Epoch :63\n",
            "d_loss : [0.2758835  0.48339844]\n",
            "g_loss : [0.7557112, 0.8214021, 0.7548898]\n",
            "Epoch :64\n",
            "d_loss : [0.27603674 0.50097656]\n",
            "g_loss : [0.61313784, 0.8349612, 0.6123029]\n",
            "Epoch :65\n",
            "d_loss : [0.27643234 0.484375  ]\n",
            "g_loss : [0.5974577, 0.84271646, 0.596615]\n",
            "Epoch :66\n",
            "d_loss : [0.27516314 0.4970703 ]\n",
            "g_loss : [0.6947388, 0.8398937, 0.6938989]\n",
            "Epoch :67\n",
            "d_loss : [0.27895963 0.49316406]\n",
            "g_loss : [0.44578996, 0.8530968, 0.44493687]\n",
            "Epoch :68\n",
            "d_loss : [0.27420485 0.5029297 ]\n",
            "g_loss : [0.7557039, 0.8472676, 0.75485665]\n",
            "Epoch :69\n",
            "d_loss : [0.2766535 0.5107422]\n",
            "g_loss : [0.7497056, 0.84113866, 0.7488645]\n",
            "Epoch :70\n",
            "d_loss : [0.27255958 0.4921875 ]\n",
            "g_loss : [1.063196, 0.8189459, 1.062377]\n",
            "Epoch :71\n",
            "d_loss : [0.27538258 0.5058594 ]\n",
            "g_loss : [0.6356579, 0.835317, 0.6348226]\n",
            "Epoch :72\n",
            "d_loss : [0.2728869 0.5097656]\n",
            "g_loss : [0.9127807, 0.84728247, 0.9119334]\n",
            "Epoch :73\n",
            "d_loss : [0.2785028 0.5029297]\n",
            "g_loss : [0.7106675, 0.8289634, 0.7098385]\n",
            "Epoch :74\n",
            "d_loss : [0.27155286 0.5048828 ]\n",
            "g_loss : [0.6339746, 0.8401556, 0.6331345]\n",
            "Epoch :75\n",
            "d_loss : [0.2746294 0.5097656]\n",
            "g_loss : [0.68609005, 0.8501499, 0.6852399]\n",
            "Epoch :76\n",
            "d_loss : [0.27380574 0.50878906]\n",
            "g_loss : [0.6150074, 0.8336952, 0.6141737]\n",
            "Epoch :77\n",
            "d_loss : [0.27704597 0.48339844]\n",
            "g_loss : [0.69630706, 0.8250567, 0.695482]\n",
            "Epoch :78\n",
            "d_loss : [0.2767372  0.48632812]\n",
            "g_loss : [0.551209, 0.83192086, 0.5503771]\n",
            "Epoch :79\n",
            "d_loss : [0.27443266 0.5       ]\n",
            "g_loss : [0.7752081, 0.84936726, 0.77435875]\n",
            "Epoch :80\n",
            "d_loss : [0.27542794 0.5078125 ]\n",
            "g_loss : [0.5484248, 0.8369211, 0.5475879]\n",
            "Epoch :81\n",
            "d_loss : [0.27401906 0.5058594 ]\n",
            "g_loss : [0.5854959, 0.8428509, 0.584653]\n",
            "Epoch :82\n",
            "d_loss : [0.27206022 0.51171875]\n",
            "g_loss : [1.0080901, 0.8431035, 1.0072471]\n",
            "Epoch :83\n",
            "d_loss : [0.27203533 0.50097656]\n",
            "g_loss : [0.4911881, 0.83106965, 0.49035704]\n",
            "Epoch :84\n",
            "d_loss : [0.2765689 0.4873047]\n",
            "g_loss : [0.6078038, 0.8312109, 0.60697263]\n",
            "Epoch :85\n",
            "d_loss : [0.27389014 0.49804688]\n",
            "g_loss : [0.63986075, 0.83003783, 0.6390307]\n",
            "Epoch :86\n",
            "d_loss : [0.2719724 0.5234375]\n",
            "g_loss : [0.6329648, 0.8357364, 0.6321291]\n",
            "Epoch :87\n",
            "d_loss : [0.2730404  0.49316406]\n",
            "g_loss : [0.7846402, 0.83670574, 0.78380346]\n",
            "Epoch :88\n",
            "d_loss : [0.27619618 0.50683594]\n",
            "g_loss : [0.63221055, 0.8514714, 0.6313591]\n",
            "Epoch :89\n",
            "d_loss : [0.27535054 0.49609375]\n",
            "g_loss : [0.8224843, 0.82501805, 0.82165927]\n",
            "Epoch :90\n",
            "d_loss : [0.27437806 0.51171875]\n",
            "g_loss : [0.61119825, 0.8376955, 0.61036056]\n",
            "Epoch :91\n",
            "d_loss : [0.2770236 0.5019531]\n",
            "g_loss : [0.7579172, 0.8225056, 0.75709474]\n",
            "Epoch :92\n",
            "d_loss : [0.272506  0.5029297]\n",
            "g_loss : [0.65783703, 0.82159966, 0.65701544]\n",
            "Epoch :93\n",
            "d_loss : [0.27389568 0.4814453 ]\n",
            "g_loss : [1.0853906, 0.8436227, 1.0845469]\n",
            "Epoch :94\n",
            "d_loss : [0.27332118 0.5136719 ]\n",
            "g_loss : [0.89900774, 0.84021485, 0.89816755]\n",
            "Epoch :95\n",
            "d_loss : [0.2730552  0.50683594]\n",
            "g_loss : [0.6130225, 0.84645045, 0.61217606]\n",
            "Epoch :96\n",
            "d_loss : [0.27561072 0.49414062]\n",
            "g_loss : [0.9991614, 0.8266549, 0.99833477]\n",
            "Epoch :97\n",
            "d_loss : [0.2725296  0.51171875]\n",
            "g_loss : [0.8220497, 0.8371669, 0.82121253]\n",
            "Epoch :98\n",
            "d_loss : [0.2775461 0.5058594]\n",
            "g_loss : [0.7103967, 0.828144, 0.70956856]\n",
            "Epoch :99\n",
            "d_loss : [0.27556166 0.49316406]\n",
            "g_loss : [0.62678784, 0.81974834, 0.6259681]\n",
            "Epoch :100\n",
            "d_loss : [0.27648285 0.5019531 ]\n",
            "g_loss : [0.52508605, 0.8392421, 0.5242468]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "PSNR: 22.5248944980104\n",
            "SSIM: 0.8740870358406972\n",
            "Epoch :101\n",
            "d_loss : [0.27284256 0.50097656]\n",
            "g_loss : [0.5678995, 0.8430872, 0.5670564]\n",
            "Epoch :102\n",
            "d_loss : [0.27364472 0.49902344]\n",
            "g_loss : [1.0976105, 0.84684896, 1.0967636]\n",
            "Epoch :103\n",
            "d_loss : [0.27419007 0.50878906]\n",
            "g_loss : [0.95971644, 0.84413695, 0.9588723]\n",
            "Epoch :104\n",
            "d_loss : [0.2730566  0.50390625]\n",
            "g_loss : [1.0930927, 0.8376749, 1.092255]\n",
            "Epoch :105\n",
            "d_loss : [0.27287272 0.51464844]\n",
            "g_loss : [0.80565727, 0.85044134, 0.8048068]\n",
            "Epoch :106\n",
            "d_loss : [0.2767373  0.49316406]\n",
            "g_loss : [0.9031041, 0.83008206, 0.9022741]\n",
            "Epoch :107\n",
            "d_loss : [0.27231097 0.5029297 ]\n",
            "g_loss : [0.5454674, 0.8514099, 0.544616]\n",
            "Epoch :108\n",
            "d_loss : [0.27552658 0.4892578 ]\n",
            "g_loss : [1.3218637, 0.843606, 1.32102]\n",
            "Epoch :109\n",
            "d_loss : [0.2764052 0.5      ]\n",
            "g_loss : [0.7951811, 0.8388419, 0.7943423]\n",
            "Epoch :110\n",
            "d_loss : [0.27611443 0.50683594]\n",
            "g_loss : [0.6177028, 0.837376, 0.6168654]\n",
            "Epoch :111\n",
            "d_loss : [0.2772045 0.5126953]\n",
            "g_loss : [1.0266602, 0.83561337, 1.0258245]\n",
            "Epoch :112\n",
            "d_loss : [0.27613318 0.4716797 ]\n",
            "g_loss : [0.61918783, 0.8518983, 0.61833596]\n",
            "Epoch :113\n",
            "d_loss : [0.27514347 0.4951172 ]\n",
            "g_loss : [0.8858768, 0.84361184, 0.8850332]\n",
            "Epoch :114\n",
            "d_loss : [0.27424797 0.5048828 ]\n",
            "g_loss : [0.6778595, 0.8471092, 0.6770124]\n",
            "Epoch :115\n",
            "d_loss : [0.275272   0.49121094]\n",
            "g_loss : [0.8233345, 0.8301867, 0.82250434]\n",
            "Epoch :116\n",
            "d_loss : [0.27484745 0.5029297 ]\n",
            "g_loss : [0.93300265, 0.8282665, 0.9321744]\n",
            "Epoch :117\n",
            "d_loss : [0.27506766 0.4873047 ]\n",
            "g_loss : [0.5092995, 0.8343323, 0.5084652]\n",
            "Epoch :118\n",
            "d_loss : [0.27976978 0.4921875 ]\n",
            "g_loss : [0.6491414, 0.8389613, 0.64830244]\n",
            "Epoch :119\n",
            "d_loss : [0.27415946 0.48535156]\n",
            "g_loss : [0.93020403, 0.83632207, 0.9293677]\n",
            "Epoch :120\n",
            "d_loss : [0.2758989  0.48535156]\n",
            "g_loss : [0.59842247, 0.84093606, 0.5975815]\n",
            "Epoch :121\n",
            "d_loss : [0.2726162  0.49902344]\n",
            "g_loss : [0.71612436, 0.8436687, 0.7152807]\n",
            "Epoch :122\n",
            "d_loss : [0.27391544 0.47851562]\n",
            "g_loss : [0.8510819, 0.844769, 0.85023713]\n",
            "Epoch :123\n",
            "d_loss : [0.27207202 0.4970703 ]\n",
            "g_loss : [0.51867986, 0.831233, 0.5178486]\n",
            "Epoch :124\n",
            "d_loss : [0.27272588 0.5078125 ]\n",
            "g_loss : [0.9233602, 0.83100855, 0.9225292]\n",
            "Epoch :125\n",
            "d_loss : [0.2752525 0.4970703]\n",
            "g_loss : [0.7755506, 0.8337714, 0.77471685]\n",
            "Epoch :126\n",
            "d_loss : [0.27350494 0.50097656]\n",
            "g_loss : [0.971031, 0.82662016, 0.9702044]\n",
            "Epoch :127\n",
            "d_loss : [0.27061242 0.50683594]\n",
            "g_loss : [0.4389249, 0.83417106, 0.43809074]\n",
            "Epoch :128\n",
            "d_loss : [0.27352   0.5107422]\n",
            "g_loss : [0.9711008, 0.85796297, 0.97024286]\n",
            "Epoch :129\n",
            "d_loss : [0.27490872 0.49414062]\n",
            "g_loss : [1.1903468, 0.85131276, 1.1894956]\n",
            "Epoch :130\n",
            "d_loss : [0.28066742 0.5       ]\n",
            "g_loss : [1.0064802, 0.8410895, 1.0056391]\n",
            "Epoch :131\n",
            "d_loss : [0.27547294 0.484375  ]\n",
            "g_loss : [1.0904605, 0.8342458, 1.0896263]\n",
            "Epoch :132\n",
            "d_loss : [0.27801138 0.50683594]\n",
            "g_loss : [0.9790829, 0.83080184, 0.97825205]\n",
            "Epoch :133\n",
            "d_loss : [0.27279237 0.50683594]\n",
            "g_loss : [0.76946956, 0.8419405, 0.76862764]\n",
            "Epoch :134\n",
            "d_loss : [0.27515543 0.49316406]\n",
            "g_loss : [1.4703169, 0.82550514, 1.4694914]\n",
            "Epoch :135\n",
            "d_loss : [0.27861118 0.5185547 ]\n",
            "g_loss : [0.9492949, 0.8623503, 0.94843256]\n",
            "Epoch :136\n",
            "d_loss : [0.2777142 0.5107422]\n",
            "g_loss : [1.1960484, 0.83314943, 1.1952152]\n",
            "Epoch :137\n",
            "d_loss : [0.27413732 0.50390625]\n",
            "g_loss : [1.5961033, 0.81717557, 1.5952861]\n",
            "Epoch :138\n",
            "d_loss : [0.27478936 0.5       ]\n",
            "g_loss : [0.75505936, 0.8296503, 0.7542297]\n",
            "Epoch :139\n",
            "d_loss : [0.27324986 0.50878906]\n",
            "g_loss : [1.4570702, 0.84193957, 1.4562283]\n",
            "Epoch :140\n",
            "d_loss : [0.2727687 0.5078125]\n",
            "g_loss : [0.6274202, 0.8494545, 0.62657076]\n",
            "Epoch :141\n",
            "d_loss : [0.2720107 0.515625 ]\n",
            "g_loss : [0.77329063, 0.8337333, 0.7724569]\n",
            "Epoch :142\n",
            "d_loss : [0.2778958 0.4873047]\n",
            "g_loss : [1.0770495, 0.83906686, 1.0762104]\n",
            "Epoch :143\n",
            "d_loss : [0.27724734 0.5107422 ]\n",
            "g_loss : [1.0201449, 0.83120096, 1.0193137]\n",
            "Epoch :144\n",
            "d_loss : [0.27368703 0.48828125]\n",
            "g_loss : [1.0423458, 0.8371261, 1.0415087]\n",
            "Epoch :145\n",
            "d_loss : [0.2746486  0.49609375]\n",
            "g_loss : [0.884734, 0.83212566, 0.88390183]\n",
            "Epoch :146\n",
            "d_loss : [0.27613685 0.5126953 ]\n",
            "g_loss : [0.8498476, 0.8433689, 0.84900427]\n",
            "Epoch :147\n",
            "d_loss : [0.2742748  0.50683594]\n",
            "g_loss : [0.956043, 0.82841915, 0.95521456]\n",
            "Epoch :148\n",
            "d_loss : [0.27365237 0.4970703 ]\n",
            "g_loss : [0.75644976, 0.8438711, 0.7556059]\n",
            "Epoch :149\n",
            "d_loss : [0.2778263  0.49414062]\n",
            "g_loss : [0.80263686, 0.85654, 0.80178034]\n",
            "Epoch :150\n",
            "d_loss : [0.27639928 0.49609375]\n",
            "g_loss : [0.85805017, 0.8303623, 0.8572198]\n",
            "Epoch :151\n",
            "d_loss : [0.27528647 0.5097656 ]\n",
            "g_loss : [1.4353805, 0.83326703, 1.4345472]\n",
            "Epoch :152\n",
            "d_loss : [0.27387482 0.5019531 ]\n",
            "g_loss : [0.7066849, 0.8437965, 0.70584106]\n",
            "Epoch :153\n",
            "d_loss : [0.27492946 0.49902344]\n",
            "g_loss : [1.0661942, 0.82763493, 1.0653665]\n",
            "Epoch :154\n",
            "d_loss : [0.27463895 0.484375  ]\n",
            "g_loss : [1.0041345, 0.8458036, 1.0032887]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-4c2c909bd834>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    207\u001b[0m                 \u001b[0;31m#     wr.writerow(score)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m             \u001b[0madversarial_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/gdrive/My Drive/Dataset/Saved_Weights/adversarial_model_imagenet1.hdf5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m             \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/gdrive/My Drive/Dataset/Saved_Weights/discriminator_imagenet1.hdf5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/gdrive/My Drive/Dataset/Saved_Weights/generator_imagenet.hdf5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36msave_wrapper\u001b[0;34m(obj, filepath, overwrite, *args, **kwargs)\u001b[0m\n\u001b[1;32m    447\u001b[0m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m             \u001b[0msave_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msave_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36msave_weights\u001b[0;34m(self, filepath, overwrite)\u001b[0m\n\u001b[1;32m   1181\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mproceed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m             \u001b[0msaving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights_to_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[1;32m    406\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[1;32m    407\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m                                swmr=swmr)\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_EXCL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_TRUNC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'a'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;31m# Open in append mode (read/write).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.create\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Unable to create file (unable to open file: name = '/content/gdrive/My Drive/Dataset/Saved_Weights/adversarial_model_imagenet1.hdf5', errno = 5, error message = 'Input/output error', flags = 13, o_flags = 242)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxh_Bst-edHq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}