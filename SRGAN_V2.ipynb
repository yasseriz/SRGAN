{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SRGAN V2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOA14cfL4blRj9hPu/f+5O4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OInjcNGHLiFs",
        "colab_type": "code",
        "outputId": "15d47360-709f-404f-aae1-bcd050a3fc29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        }
      },
      "source": [
        "!pip install scipy==1.0.0\n",
        "!pip install numpy==1.17.4\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scipy==1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/5e/caa01ba7be11600b6a9d39265440d7b3be3d69206da887c42bef049521f2/scipy-1.0.0-cp36-cp36m-manylinux1_x86_64.whl (50.0MB)\n",
            "\u001b[K     |████████████████████████████████| 50.0MB 90kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy==1.0.0) (1.18.3)\n",
            "\u001b[31mERROR: tensorflow 2.2.0rc3 has requirement scipy==1.4.1; python_version >= \"3\", but you'll have scipy 1.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: seaborn 0.10.0 has requirement scipy>=1.0.1, but you'll have scipy 1.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: plotnine 0.6.0 has requirement scipy>=1.2.0, but you'll have scipy 1.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: cvxpy 1.0.31 has requirement scipy>=1.1.0, but you'll have scipy 1.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: scipy\n",
            "  Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "Successfully installed scipy-1.0.0\n",
            "Collecting numpy==1.17.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d2/ab/43e678759326f728de861edbef34b8e2ad1b1490505f20e0d1f0716c3bf4/numpy-1.17.4-cp36-cp36m-manylinux1_x86_64.whl (20.0MB)\n",
            "\u001b[K     |████████████████████████████████| 20.0MB 238kB/s \n",
            "\u001b[31mERROR: tensorflow 2.2.0rc3 has requirement scipy==1.4.1; python_version >= \"3\", but you'll have scipy 1.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: seaborn 0.10.0 has requirement scipy>=1.0.1, but you'll have scipy 1.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: plotnine 0.6.0 has requirement scipy>=1.2.0, but you'll have scipy 1.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: cvxpy 1.0.31 has requirement scipy>=1.1.0, but you'll have scipy 1.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Found existing installation: numpy 1.18.3\n",
            "    Uninstalling numpy-1.18.3:\n",
            "      Successfully uninstalled numpy-1.18.3\n",
            "Successfully installed numpy-1.17.4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVJQSW1NNTRm",
        "colab_type": "code",
        "outputId": "d5727bf5-9d02-4135-aa27-4679b7a9b788",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "map2zxKGNVS9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import libraries\n",
        "import time\n",
        "import keras\n",
        "from keras import Input\n",
        "from keras.layers import BatchNormalization, Activation, Add, LeakyReLU, Dense, MaxPooling2D\n",
        "from keras.layers.advanced_activations import PReLU\n",
        "from keras.layers.convolutional import Conv2D, UpSampling2D, Conv2DTranspose\n",
        "from keras.applications import VGG19\n",
        "from keras.applications import ResNet50\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "import glob\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from scipy.misc import imresize, imread\n",
        "from keras import backend as K\n",
        "import math\n",
        "import numpy\n",
        "from skimage.measure import compare_ssim\n",
        "import csv\n",
        "import os.path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6H8ucmwRDF0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_vgg():\n",
        "    \"\"\"\n",
        "    Builds a pre-trained VGG19 model that outputs image features extracted at the\n",
        "    third block of the model\n",
        "    \"\"\"\n",
        "    input_shape = (256, 256, 3)\n",
        "    vgg = VGG19(weights=\"imagenet\")\n",
        "    # Set the outputs to outputs of last conv. layer in block 3\n",
        "    # See architecture at: https://github.com/keras-team/keras/blob/master/keras/applications/vgg19.py\n",
        "    vgg.outputs = [vgg.layers[9].output]\n",
        "\n",
        "    img = Input(shape=input_shape)\n",
        "\n",
        "    # Extract the image features\n",
        "    img_features = vgg(img)\n",
        "\n",
        "    return Model(inputs=[img], outputs=[img_features], name='VGG')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bE6z0oexRWKP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Residual block for generator network\n",
        "def residual_block(x):\n",
        "    \"\"\"\n",
        "    Residual block\n",
        "    \"\"\"\n",
        "    filters = [64, 64]\n",
        "    kernel_size = 3\n",
        "    strides = 1\n",
        "    padding = \"same\"\n",
        "    momentum = 0.8\n",
        "    activation = PReLU()\n",
        "\n",
        "    res = Conv2D(filters=filters[0], kernel_size=kernel_size,\n",
        "                 strides=strides, padding=padding)(x)\n",
        "    res = Activation(activation=activation)(res)\n",
        "    res = BatchNormalization(momentum=momentum)(res)\n",
        "\n",
        "    res = Conv2D(filters=filters[1], kernel_size=kernel_size,\n",
        "                 strides=strides, padding=padding)(res)\n",
        "    res = BatchNormalization(momentum=momentum)(res)\n",
        "\n",
        "    # Add res and x\n",
        "    res = Add()([res, x])\n",
        "    return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMu-ti9ARZmK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_generator():\n",
        "    \"\"\"\n",
        "    Create a generator network using the hyperparameter values defined below\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    residual_blocks = 16\n",
        "    momentum = 0.8\n",
        "    input_shape = (64, 64, 3)\n",
        "    counter = 0\n",
        "\n",
        "    # Input Layer of the generator network\n",
        "    input_layer = Input(shape=input_shape)\n",
        "\n",
        "    # Add the pre-residual block\n",
        "    gen1 = Conv2D(filters=64, kernel_size=9, strides=1, padding='same')(input_layer)\n",
        "    gen1 = Activation(PReLU())(gen1)\n",
        "    # Add 16 residual blocks\n",
        "    res = residual_block(gen1)\n",
        "    for i in range(residual_blocks - 1):\n",
        "        res = residual_block(res)\n",
        "\n",
        "    # Add the post-residual block\n",
        "    gen2 = Conv2D(filters=64, kernel_size=3, strides=1, padding='same')(res)\n",
        "    gen2 = BatchNormalization(momentum=momentum)(gen2)\n",
        "\n",
        "    # Take the sum of the output from the pre-residual block(gen1) and\n",
        "    #  the post-residual block(gen2)\n",
        "    gen3 = Add(name='trial')([gen2, gen1])\n",
        "\n",
        "    # Add an upsampling block\n",
        "    gen4 = UpSampling2D(size=2)(gen3)\n",
        "    # gen4 = Conv2DTranspose(256, kernel_size=3, strides=2, padding='same')(gen3)\n",
        "    gen4 = Conv2D(filters=256, kernel_size=3, strides=1, padding='same')(gen4)\n",
        "    gen4 = Activation(PReLU())(gen4)\n",
        "\n",
        "    # Add another upsampling block\n",
        "    gen5 = UpSampling2D(size=2)(gen4)\n",
        "    # gen5 = Conv2DTranspose(256, kernel_size=3, strides=2, padding='same')(gen4)\n",
        "    gen5 = Conv2D(filters=256, kernel_size=3, strides=1, padding='same')(gen5)\n",
        "    gen5 = Activation(PReLU())(gen5)\n",
        "\n",
        "    # Output convolution layer\n",
        "    gen6 = Conv2D(filters=3, kernel_size=9, strides=1, padding='same', activation='tanh')(gen5)\n",
        "\n",
        "    # Auto-Encoder\n",
        "    x = Conv2D(512, (3, 3), activation='relu', strides=1, padding='same')(gen6)\n",
        "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "    x = Conv2D(256, (3, 3), activation='relu', strides=1, padding='same')(x)\n",
        "    encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "    # at this point the representation is (7, 7, 32)\n",
        "\n",
        "    x = Conv2D(256, (3, 3), activation='relu', strides=1, padding='same')(encoded)\n",
        "    x = UpSampling2D((2, 2))(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', strides=1, padding='same')(x)\n",
        "    x = UpSampling2D((2, 2))(x)\n",
        "    decoded = Conv2D(3, (3, 3), activation='tanh', strides=1, padding='same')(x)\n",
        "    # Keras model\n",
        "    model = Model(inputs=[input_layer], outputs=[decoded],\n",
        "                  name='generator')\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQZS_6AoTCEe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Discriminator Network\n",
        "def build_discriminator():\n",
        "    \"\"\"\n",
        "    Create a discriminator network using the hyperparameter values defined below\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    leakyrelu_alpha = 0.2\n",
        "    momentum = 0.8\n",
        "    input_shape = (256, 256, 3)\n",
        "\n",
        "    input_layer = Input(shape=input_shape)\n",
        "\n",
        "    # Add the first convolution block\n",
        "    dis1 = Conv2D(filters=64, kernel_size=3, strides=1, padding='same')(input_layer)\n",
        "    dis1 = LeakyReLU(alpha=leakyrelu_alpha)(dis1)\n",
        "\n",
        "    # Add the 2nd convolution block\n",
        "    dis2 = Conv2D(filters=64, kernel_size=3, strides=2, padding='same')(dis1)\n",
        "    dis2 = LeakyReLU(alpha=leakyrelu_alpha)(dis2)\n",
        "    dis2 = BatchNormalization(momentum=momentum)(dis2)\n",
        "\n",
        "    # Add the third convolution block\n",
        "    dis3 = Conv2D(filters=128, kernel_size=3, strides=1, padding='same')(dis2)\n",
        "    dis3 = LeakyReLU(alpha=leakyrelu_alpha)(dis3)\n",
        "    dis3 = BatchNormalization(momentum=momentum)(dis3)\n",
        "\n",
        "    # Add the fourth convolution block\n",
        "    dis4 = Conv2D(filters=128, kernel_size=3, strides=2, padding='same')(dis3)\n",
        "    dis4 = LeakyReLU(alpha=leakyrelu_alpha)(dis4)\n",
        "    dis4 = BatchNormalization(momentum=0.8)(dis4)\n",
        "\n",
        "    # Add the fifth convolution block\n",
        "    dis5 = Conv2D(256, kernel_size=3, strides=1, padding='same')(dis4)\n",
        "    dis5 = LeakyReLU(alpha=leakyrelu_alpha)(dis5)\n",
        "    dis5 = BatchNormalization(momentum=momentum)(dis5)\n",
        "\n",
        "    # Add the sixth convolution block\n",
        "    dis6 = Conv2D(filters=256, kernel_size=3, strides=2, padding='same')(dis5)\n",
        "    dis6 = LeakyReLU(alpha=leakyrelu_alpha)(dis6)\n",
        "    dis6 = BatchNormalization(momentum=momentum)(dis6)\n",
        "\n",
        "    # Add the seventh convolution block\n",
        "    dis7 = Conv2D(filters=512, kernel_size=3, strides=1, padding='same')(dis6)\n",
        "    dis7 = LeakyReLU(alpha=leakyrelu_alpha)(dis7)\n",
        "    dis7 = BatchNormalization(momentum=momentum)(dis7)\n",
        "\n",
        "    # Add the eight convolution block\n",
        "    dis8 = Conv2D(filters=512, kernel_size=3, strides=2, padding='same')(dis7)\n",
        "    dis8 = LeakyReLU(alpha=leakyrelu_alpha)(dis8)\n",
        "    dis8 = BatchNormalization(momentum=momentum)(dis8)\n",
        "\n",
        "    # Add a dense layer\n",
        "    dis9 = Dense(units=1024)(dis8)\n",
        "    dis9 = LeakyReLU(alpha=0.2)(dis9)\n",
        "\n",
        "    # Last dense layer - for classification\n",
        "    output_gen = Dense(units=1, activation='sigmoid')(dis9)\n",
        "\n",
        "    model = Model(inputs=[input_layer], outputs=[output_gen], name='discriminator')\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAFaG293TDAD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample_images(data_dir, batch_size, high_resolution_shape, low_resolution_shape):\n",
        "\n",
        "    # Make a list of all images inside the data directory\n",
        "    all_images = data_dir\n",
        "\n",
        "    # Choose a random batch of images\n",
        "    images_batch = np.random.choice(all_images, size=batch_size)\n",
        "\n",
        "    low_resolution_images = []\n",
        "    high_resolution_images = []\n",
        "\n",
        "    for img in images_batch:\n",
        "        # Get an ndarray of the current image\n",
        "        img1 = imread(img, mode='RGB')\n",
        "        img1 = img1.astype(np.float32)\n",
        "\n",
        "        # Resize the image\n",
        "        img1_high_resolution = imresize(img1, high_resolution_shape)\n",
        "        img1_low_resolution = imresize(img1, low_resolution_shape)\n",
        "\n",
        "        # Do a random horizontal flip\n",
        "        if np.random.random() < 0.5:\n",
        "          img1_high_resolution = np.fliplr(img1_high_resolution)\n",
        "          img1_low_resolution = np.fliplr(img1_low_resolution)\n",
        "\n",
        "        high_resolution_images.append(img1_high_resolution)\n",
        "        low_resolution_images.append(img1_low_resolution)\n",
        "\n",
        "    # Convert the lists to Numpy NDArrays\n",
        "    return np.array(high_resolution_images), np.array(low_resolution_images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoak84fTTJ20",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_images(low_resolution_images, high_resolution_images, generated_images, path):\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(1, 3, 1)\n",
        "    ax.imshow(low_resolution_images[0])\n",
        "    ax.axis(\"off\")\n",
        "    ax.set_title(\"Low Resolution\")\n",
        "\n",
        "    ax = fig.add_subplot(1, 3, 2)\n",
        "    ax.imshow(high_resolution_images[0])\n",
        "    ax.axis(\"off\")\n",
        "    ax.set_title(\"Original\")\n",
        "\n",
        "    ax = fig.add_subplot(1, 3, 3)\n",
        "    ax.imshow(generated_images[0])\n",
        "    ax.axis(\"off\")\n",
        "    ax.set_title(\"Generated\")\n",
        "\n",
        "    plt.savefig(path)\n",
        "    plt.clf()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDqDEEAkThLl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def PSNR(true_image, predicted_image):\n",
        "    mse = numpy.mean((true_image - predicted_image) ** 2)\n",
        "    Pixel_max = 1.0\n",
        "    return 20 * math.log10(Pixel_max / math.sqrt(mse))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBrMMq2PThq1",
        "colab_type": "code",
        "outputId": "698a2a82-ad6e-482b-fc95-7a84f57fb619",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    # Define hyperparameters\n",
        "    data_dir = glob('./Dataset/*')\n",
        "    epochs = 10001\n",
        "    batch_size = 2\n",
        "    lr = 0.0002\n",
        "    mode = 'train'\n",
        "    # Shape of low-resolution and high-resolution images\n",
        "    low_resolution_shape = (64, 64, 3)\n",
        "    high_resolution_shape = (256, 256, 3)\n",
        "\n",
        "    # Common optimizer for all networks\n",
        "    common_optimizer = Adam(lr, 0.9)\n",
        "\n",
        "    # Training the model\n",
        "    if mode == 'train':\n",
        "\n",
        "        # Building and compiling the networks\n",
        "        vgg = build_vgg()\n",
        "        vgg.trainable = False\n",
        "        # print(\"VGG\")\n",
        "        # print(vgg.summary())\n",
        "        vgg.compile(optimizer=common_optimizer, loss='mse', metrics=['accuracy'])\n",
        "\n",
        "        discriminator = build_discriminator()\n",
        "        # print(\"discrminator\")\n",
        "        # print(discriminator.summary())\n",
        "        discriminator.compile(optimizer=common_optimizer, loss='mse', metrics=['accuracy'])\n",
        "        print(discriminator.metrics_names)\n",
        "\n",
        "        generator = build_generator()\n",
        "        print(\"generator\")\n",
        "        print(generator.summary())\n",
        "\n",
        "        # Building and compiling the adversarial network\n",
        "        # High and Low resolution inputs to the network\n",
        "        input_high_resolution = Input(shape=high_resolution_shape)\n",
        "        input_low_resolution = Input(shape=low_resolution_shape)\n",
        "\n",
        "        # Generating high resolution images from the generator\n",
        "        generated_high_resolution_images = generator(input_low_resolution)\n",
        "\n",
        "        # Extracting high resolution features using VGG network\n",
        "        features = vgg(generated_high_resolution_images)\n",
        "\n",
        "        # Discriminator model is turned off during adversarial training\n",
        "        discriminator.trainable = False\n",
        "        discriminator.compile(optimizer=common_optimizer, loss='mse', metrics=['accuracy'])\n",
        "\n",
        "        # Probability of generated high resolution images\n",
        "        probs = discriminator(generated_high_resolution_images)\n",
        "\n",
        "        # Creating the adversarial model\n",
        "        adversarial_model = Model([input_low_resolution, input_high_resolution], [probs, features])\n",
        "        # print(\"Adversarial\")\n",
        "        # print(adversarial_model.summary())\n",
        "        adversarial_model.compile(optimizer=common_optimizer, loss=['binary_crossentropy', 'mse'],\n",
        "                                  loss_weights=[1e-3, 1])\n",
        "        # print(adversarial_model.metrics_names)\n",
        "\n",
        "        # Add Tensorboard\n",
        "        # tensorboard = TensorBoard(log_dir=\"logs_imagenet_res/\".format(time.time()))\n",
        "        # tensorboard.set_model(generator)\n",
        "        # tensorboard.set_model(discriminator)\n",
        "\n",
        "        # Training\n",
        "        for epoch in range(epochs):\n",
        "            print(\"Epoch :{}\".format(epoch))\n",
        "            # experiment.log_parameter('epoch', epoch)\n",
        "\n",
        "            # Training the discriminator network\n",
        "\n",
        "            high_resolution_images, low_resolution_images = sample_images(data_dir=data_dir, batch_size=batch_size,\n",
        "                                                                          high_resolution_shape=high_resolution_shape,\n",
        "                                                                          low_resolution_shape=low_resolution_shape)\n",
        "            high_resolution_images = high_resolution_images / 255.0\n",
        "            low_resolution_images = low_resolution_images / 255.0\n",
        "\n",
        "            generated_high_resolution_images = generator.predict(low_resolution_images)\n",
        "\n",
        "            # Generating batch of real and fake labels\n",
        "            real_labels = np.ones((batch_size, 16, 16, 1))\n",
        "            fake_labels = np.zeros((batch_size, 16, 16, 1))\n",
        "\n",
        "            d_loss_real = discriminator.train_on_batch(high_resolution_images, real_labels)\n",
        "            d_loss_fake = discriminator.train_on_batch(generated_high_resolution_images, fake_labels)\n",
        "\n",
        "            # write_log(tensorboard, 'd_loss_real', d_loss_real[0], epoch)\n",
        "            # write_log(tensorboard, 'd_loss_real_acc', d_loss_real[1], epoch)\n",
        "            # write_log(tensorboard, 'd_loss_fake', d_loss_fake[0], epoch)\n",
        "            # write_log(tensorboard, 'd_loss_fake_acc', d_loss_fake[1], epoch)\n",
        "\n",
        "            # Data logging to csv\n",
        "            with open('d_loss_real', 'a', newline='') as myfile:\n",
        "                fileEmpty = os.stat('d_loss_real').st_size == 0\n",
        "            \n",
        "                wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
        "                headers = ['Loss', 'Acc']\n",
        "                writer = csv.DictWriter(myfile, fieldnames=headers)\n",
        "            \n",
        "                if fileEmpty:\n",
        "                    writer.writeheader()\n",
        "            \n",
        "                wr.writerow(d_loss_real)\n",
        "            \n",
        "            with open('d_loss_fake', 'a', newline='') as myfile:\n",
        "                fileEmpty = os.stat('d_loss_fake').st_size == 0\n",
        "            \n",
        "                wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
        "                headers = ['Loss', 'Acc']\n",
        "                writer = csv.DictWriter(myfile, fieldnames=headers)\n",
        "            \n",
        "                if fileEmpty:\n",
        "                    writer.writeheader()\n",
        "            \n",
        "                wr.writerow(d_loss_fake)\n",
        "\n",
        "            # Calculating the discriminator loss\n",
        "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "            print(\"d_loss :\", d_loss)\n",
        "            # print(type(d_loss))\n",
        "\n",
        "            # Data logging to csv\n",
        "            with open('d_loss', 'a', newline='') as myfile:\n",
        "                fileEmpty = os.stat('d_loss').st_size == 0\n",
        "                wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
        "                headers = ['Loss', 'Acc']\n",
        "                writer = csv.DictWriter(myfile, fieldnames=headers)\n",
        "            \n",
        "                if fileEmpty:\n",
        "                    writer.writeheader()\n",
        "                wr.writerow(d_loss)\n",
        "\n",
        "            # Training the generator network\n",
        "            high_resolution_images, low_resolution_images = sample_images(data_dir=data_dir, batch_size=batch_size,\n",
        "                                                                          high_resolution_shape=high_resolution_shape,\n",
        "                                                                          low_resolution_shape=low_resolution_shape)\n",
        "\n",
        "            high_resolution_images = high_resolution_images / 255.0\n",
        "            low_resolution_images = low_resolution_images / 255.0\n",
        "\n",
        "            real_labels = np.ones((batch_size, 16, 16, 1))\n",
        "\n",
        "            image_features = vgg.predict(high_resolution_images)\n",
        "\n",
        "            g_loss = adversarial_model.train_on_batch([low_resolution_images, high_resolution_images],\n",
        "                                                      [real_labels, image_features])\n",
        "            print(\"g_loss :\", g_loss)\n",
        "            # print(type(g_loss))\n",
        "\n",
        "            # Data logging to csv\n",
        "            with open('g_loss', 'a', newline='') as myfile:\n",
        "                fileEmpty = os.stat('g_loss').st_size == 0\n",
        "                wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
        "                headers = ['Loss', 'Discriminator_loss', 'vgg_loss']\n",
        "                writer = csv.DictWriter(myfile, fieldnames=headers)\n",
        "            \n",
        "                if fileEmpty:\n",
        "                    writer.writeheader()\n",
        "                wr.writerow(g_loss)\n",
        "\n",
        "            # Write the losses to Tensorboard\n",
        "            # write_log(tensorboard, 'g_loss', g_loss[0], epoch)\n",
        "            # write_log(tensorboard, 'discriminator_loss', g_loss[1], epoch)\n",
        "            # write_log(tensorboard, 'ResNet_loss', g_loss[2], epoch)\n",
        "\n",
        "            # write_log(tensorboard, 'd_loss', d_loss[0], epoch)\n",
        "            # write_log(tensorboard, 'd_acc', d_loss[1], epoch)\n",
        "\n",
        "            # Saving images\n",
        "            if epoch % 100 == 0:\n",
        "                high_resolution_images, low_resolution_images = sample_images(data_dir=data_dir, batch_size=batch_size,\n",
        "                                                                              high_resolution_shape=high_resolution_shape,\n",
        "                                                                              low_resolution_shape=low_resolution_shape)\n",
        "                # Normalizing the images\n",
        "                high_resolution_images = high_resolution_images / 255.0\n",
        "                low_resolution_images = low_resolution_images / 255.0\n",
        "\n",
        "                generated_images = generator.predict_on_batch(low_resolution_images)\n",
        "\n",
        "                # low_resolution_images = 0.5 * low_resolution_images + 0.5\n",
        "                # generated_images = 0.5 * generated_images + 0.5\n",
        "                # high_resolution_images = 0.5 * high_resolution_images + 0.5\n",
        "\n",
        "                for index, img in enumerate(generated_images):\n",
        "                    save_images(low_resolution_images, high_resolution_images, generated_images,\n",
        "                                path=\"Results/img_{}\".format(epoch))\n",
        "\n",
        "                # Calculating PSNR and SSIM metrics\n",
        "                psnr = PSNR(high_resolution_images[0], generated_images[0])\n",
        "                print(\"PSNR: {}\".format(psnr))\n",
        "                psnr = [float(psnr)]\n",
        "                # with open('PSNR', 'a', newline='') as myfileg:\n",
        "                #     wr = csv.writer(myfileg, quoting=csv.QUOTE_ALL)\n",
        "                #     wr.writerow(psnr)\n",
        "\n",
        "                (score, diff) = compare_ssim(high_resolution_images[0], generated_images[0], full=True,\n",
        "                                             multichannel=True)\n",
        "                print(\"SSIM: {}\".format(score))\n",
        "                score = [float(score)]\n",
        "                # with open('SSIM', 'a', newline='') as myfileg:\n",
        "                #     wr = csv.writer(myfileg, quoting=csv.QUOTE_ALL)\n",
        "                #     wr.writerow(score)\n",
        "\n",
        "        # generator.save_weights(\"generator_imagenet_res.h5\")\n",
        "        # discriminator.save_weights(\"discriminator_imagenet_res.h5\")\n",
        "\n",
        "        # Predict Results\n",
        "    if mode == 'Predict':\n",
        "        # Build discriminator and generator\n",
        "        discriminator = build_discriminator()\n",
        "        generator = build_generator()\n",
        "\n",
        "        # Load weights from training\n",
        "        discriminator.load_weights(\"discriminator_imagenet_res.h5\")\n",
        "        generator.load_weights(\"generator_imagenet_res.h5\")\n",
        "\n",
        "        # Load test images\n",
        "        data_dir = glob('./Predict/*')\n",
        "        high_resolution_images, low_resolution_images = sample_images(data_dir=data_dir, batch_size=2,\n",
        "                                                                      high_resolution_shape=high_resolution_shape,\n",
        "                                                                      low_resolution_shape=low_resolution_shape)\n",
        "        # Normalizing the image\n",
        "        high_resolution_images = high_resolution_images / 255.0\n",
        "        low_resolution_images = low_resolution_images / 255.0\n",
        "\n",
        "        generated_images = generator.predict_on_batch(low_resolution_images)\n",
        "\n",
        "        # low_resolution_images = 0.5 * low_resolution_images + 0.5\n",
        "        # generated_images = 0.5 * generated_images + 0.5\n",
        "        # high_resolution_images = 0.5 * high_resolution_images + 0.5\n",
        "\n",
        "        # Calculating PSNR and SSIM of images\n",
        "        psnr1 = PSNR(high_resolution_images[0], generated_images[0])\n",
        "        (score1, diff1) = compare_ssim(high_resolution_images[0], generated_images[0], full=True, multichannel=True)\n",
        "        print(\"PSNR_first_image: {}\".format(psnr1))\n",
        "        print(\"SSIM_first_image: {}\".format(score1))\n",
        "\n",
        "        psnr2 = PSNR(high_resolution_images[1], generated_images[1])\n",
        "        (score2, diff2) = compare_ssim(high_resolution_images[1], generated_images[1], full=True, multichannel=True)\n",
        "        print(\"PSNR_second_image: {}\".format(psnr2))\n",
        "        print(\"SSIM_second_image: {}\".format(score2))\n",
        "\n",
        "        # Saving images\n",
        "        for index, img in enumerate(generated_images):\n",
        "            save_images(low_resolution_images, high_resolution_images, generated_images,\n",
        "                        path=\"results/gen_{}\".format(index))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['loss', 'accuracy']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/activations.py:235: UserWarning: Do not pass a layer instance (such as PReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
            "  identifier=identifier.__class__.__name__))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "generator\n",
            "Model: \"generator\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_8 (InputLayer)            (None, 64, 64, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 64, 64, 64)   15616       input_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 64, 64, 64)   262144      conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 64, 64, 64)   36928       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 64, 64, 64)   262144      conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 64, 64, 64)   256         activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 64, 64, 64)   36928       batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 64, 64, 64)   256         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, 64, 64, 64)   0           batch_normalization_49[0][0]     \n",
            "                                                                 activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 64, 64, 64)   36928       add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 64, 64, 64)   262144      conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 64, 64, 64)   256         activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 64, 64, 64)   36928       batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 64, 64, 64)   256         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, 64, 64, 64)   0           batch_normalization_51[0][0]     \n",
            "                                                                 add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 64, 64, 64)   36928       add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 64, 64, 64)   262144      conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 64, 64, 64)   256         activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 64, 64, 64)   36928       batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 64, 64, 64)   256         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, 64, 64, 64)   0           batch_normalization_53[0][0]     \n",
            "                                                                 add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 64, 64, 64)   36928       add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 64, 64, 64)   262144      conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 64, 64, 64)   256         activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 64, 64, 64)   36928       batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 64, 64, 64)   256         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_20 (Add)                    (None, 64, 64, 64)   0           batch_normalization_55[0][0]     \n",
            "                                                                 add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 64, 64, 64)   36928       add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 64, 64, 64)   262144      conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 64, 64, 64)   256         activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 64, 64, 64)   36928       batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 64, 64, 64)   256         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_21 (Add)                    (None, 64, 64, 64)   0           batch_normalization_57[0][0]     \n",
            "                                                                 add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 64, 64, 64)   36928       add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 64, 64, 64)   262144      conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 64, 64, 64)   256         activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 64, 64, 64)   36928       batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 64, 64, 64)   256         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_22 (Add)                    (None, 64, 64, 64)   0           batch_normalization_59[0][0]     \n",
            "                                                                 add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 64, 64, 64)   36928       add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 64, 64, 64)   262144      conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 64, 64, 64)   256         activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 64, 64, 64)   36928       batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 64, 64, 64)   256         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_23 (Add)                    (None, 64, 64, 64)   0           batch_normalization_61[0][0]     \n",
            "                                                                 add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 64, 64, 64)   36928       add_23[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 64, 64, 64)   262144      conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 64, 64, 64)   256         activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 64, 64, 64)   36928       batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 64, 64, 64)   256         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_24 (Add)                    (None, 64, 64, 64)   0           batch_normalization_63[0][0]     \n",
            "                                                                 add_23[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 64, 64, 64)   36928       add_24[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 64, 64, 64)   262144      conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 64, 64, 64)   256         activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 64, 64, 64)   36928       batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 64, 64, 64)   256         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_25 (Add)                    (None, 64, 64, 64)   0           batch_normalization_65[0][0]     \n",
            "                                                                 add_24[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 64, 64, 64)   36928       add_25[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 64, 64, 64)   262144      conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 64, 64, 64)   256         activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 64, 64, 64)   36928       batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 64, 64, 64)   256         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_26 (Add)                    (None, 64, 64, 64)   0           batch_normalization_67[0][0]     \n",
            "                                                                 add_25[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 64, 64, 64)   36928       add_26[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 64, 64, 64)   262144      conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 64, 64, 64)   256         activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 64, 64, 64)   36928       batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 64, 64, 64)   256         conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_27 (Add)                    (None, 64, 64, 64)   0           batch_normalization_69[0][0]     \n",
            "                                                                 add_26[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 64, 64, 64)   36928       add_27[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 64, 64, 64)   262144      conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 64, 64, 64)   256         activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 64, 64, 64)   36928       batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 64, 64, 64)   256         conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_28 (Add)                    (None, 64, 64, 64)   0           batch_normalization_71[0][0]     \n",
            "                                                                 add_27[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 64, 64, 64)   36928       add_28[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 64, 64, 64)   262144      conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 64, 64, 64)   256         activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 64, 64, 64)   36928       batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 64, 64, 64)   256         conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_29 (Add)                    (None, 64, 64, 64)   0           batch_normalization_73[0][0]     \n",
            "                                                                 add_28[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 64, 64, 64)   36928       add_29[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 64, 64, 64)   262144      conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 64, 64, 64)   256         activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 64, 64, 64)   36928       batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 64, 64, 64)   256         conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_30 (Add)                    (None, 64, 64, 64)   0           batch_normalization_75[0][0]     \n",
            "                                                                 add_29[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 64, 64, 64)   36928       add_30[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 64, 64, 64)   262144      conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 64, 64, 64)   256         activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 64, 64, 64)   36928       batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 64, 64, 64)   256         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_31 (Add)                    (None, 64, 64, 64)   0           batch_normalization_77[0][0]     \n",
            "                                                                 add_30[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 64, 64, 64)   36928       add_31[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 64, 64, 64)   262144      conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 64, 64, 64)   256         activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 64, 64, 64)   36928       batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 64, 64, 64)   256         conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_32 (Add)                    (None, 64, 64, 64)   0           batch_normalization_79[0][0]     \n",
            "                                                                 add_31[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 64, 64, 64)   36928       add_32[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 64, 64, 64)   256         conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "trial (Add)                     (None, 64, 64, 64)   0           batch_normalization_80[0][0]     \n",
            "                                                                 activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2D)  (None, 128, 128, 64) 0           trial[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 128, 128, 256 147712      up_sampling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 128, 128, 256 4194304     conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_4 (UpSampling2D)  (None, 256, 256, 256 0           activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 256, 256, 256 590080      up_sampling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 256, 256, 256 16777216    conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 256, 256, 3)  62211       activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 256, 256, 512 14336       conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 512 0           conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 128, 128, 256 1179904     max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 256)  0           conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, 64, 64, 256)  590080      max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_5 (UpSampling2D)  (None, 128, 128, 256 0           conv2d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_95 (Conv2D)              (None, 128, 128, 512 1180160     up_sampling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_6 (UpSampling2D)  (None, 256, 256, 512 0           conv2d_95[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_96 (Conv2D)              (None, 256, 256, 3)  13827       up_sampling2d_6[0][0]            \n",
            "==================================================================================================\n",
            "Total params: 30,448,966\n",
            "Trainable params: 30,444,742\n",
            "Non-trainable params: 4,224\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Epoch :0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: DeprecationWarning: `imread` is deprecated!\n",
            "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``imageio.imread`` instead.\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: DeprecationWarning: `imresize` is deprecated!\n",
            "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``skimage.transform.resize`` instead.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: DeprecationWarning: `imresize` is deprecated!\n",
            "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``skimage.transform.resize`` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "d_loss : [0.2839967 0.5097656]\n",
            "g_loss : [33.698208, 1.1369637, 33.69707]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: DeprecationWarning: `imread` is deprecated!\n",
            "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``imageio.imread`` instead.\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: DeprecationWarning: `imresize` is deprecated!\n",
            "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``skimage.transform.resize`` instead.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: DeprecationWarning: `imresize` is deprecated!\n",
            "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``skimage.transform.resize`` instead.\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:198: UserWarning: DEPRECATED: skimage.measure.compare_ssim has been moved to skimage.metrics.structural_similarity. It will be removed from skimage.measure in version 0.18.\n",
            "/usr/local/lib/python3.6/dist-packages/skimage/metrics/_structural_similarity.py:108: UserWarning: Inputs have mismatched dtype.  Setting data_range based on im1.dtype.\n",
            "  im2[..., ch], **args)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "PSNR: 6.401325430813795\n",
            "SSIM: 0.018735469134789934\n",
            "Epoch :1\n",
            "d_loss : [0.28730935 0.5048828 ]\n",
            "g_loss : [34.597378, 1.1482307, 34.59623]\n",
            "Epoch :2\n",
            "d_loss : [0.28681377 0.5097656 ]\n",
            "g_loss : [33.244278, 1.1306552, 33.24315]\n",
            "Epoch :3\n",
            "d_loss : [0.28870136 0.51953125]\n",
            "g_loss : [36.10668, 1.1293892, 36.105553]\n",
            "Epoch :4\n",
            "d_loss : [0.28800833 0.5126953 ]\n",
            "g_loss : [28.864487, 1.132729, 28.863354]\n",
            "Epoch :5\n",
            "d_loss : [0.28720692 0.5097656 ]\n",
            "g_loss : [19.439455, 1.1310763, 19.438324]\n",
            "Epoch :6\n",
            "d_loss : [0.2937041  0.48828125]\n",
            "g_loss : [35.260048, 1.1233128, 35.258926]\n",
            "Epoch :7\n",
            "d_loss : [0.29773477 0.4794922 ]\n",
            "g_loss : [25.827274, 1.1210134, 25.826153]\n",
            "Epoch :8\n",
            "d_loss : [0.2885071 0.5371094]\n",
            "g_loss : [23.976862, 1.1439753, 23.975718]\n",
            "Epoch :9\n",
            "d_loss : [0.28503683 0.54003906]\n",
            "g_loss : [25.14455, 1.1473093, 25.143402]\n",
            "Epoch :10\n",
            "d_loss : [0.27602094 0.5263672 ]\n",
            "g_loss : [34.43229, 1.1251483, 34.431164]\n",
            "Epoch :11\n",
            "d_loss : [0.2865821  0.51171875]\n",
            "g_loss : [18.621365, 1.1147851, 18.62025]\n",
            "Epoch :12\n",
            "d_loss : [0.2912882  0.50097656]\n",
            "g_loss : [39.184666, 1.118254, 39.183548]\n",
            "Epoch :13\n",
            "d_loss : [0.2894972 0.5205078]\n",
            "g_loss : [28.014894, 1.1131507, 28.01378]\n",
            "Epoch :14\n",
            "d_loss : [0.28783706 0.5175781 ]\n",
            "g_loss : [23.672201, 1.1355414, 23.671066]\n",
            "Epoch :15\n",
            "d_loss : [0.28916734 0.5097656 ]\n",
            "g_loss : [16.85677, 1.1273184, 16.855642]\n",
            "Epoch :16\n",
            "d_loss : [0.29068685 0.5097656 ]\n",
            "g_loss : [28.373747, 1.109113, 28.372639]\n",
            "Epoch :17\n",
            "d_loss : [0.29579747 0.49316406]\n",
            "g_loss : [22.189238, 1.1302601, 22.188107]\n",
            "Epoch :18\n",
            "d_loss : [0.29464936 0.49316406]\n",
            "g_loss : [22.820671, 1.1253511, 22.819546]\n",
            "Epoch :19\n",
            "d_loss : [0.29126504 0.51171875]\n",
            "g_loss : [27.507025, 1.1159191, 27.505909]\n",
            "Epoch :20\n",
            "d_loss : [0.2931052  0.48828125]\n",
            "g_loss : [27.400604, 1.1437743, 27.39946]\n",
            "Epoch :21\n",
            "d_loss : [0.2930818  0.50390625]\n",
            "g_loss : [14.0439415, 1.12875, 14.042812]\n",
            "Epoch :22\n",
            "d_loss : [0.29022756 0.50097656]\n",
            "g_loss : [34.92289, 1.1507199, 34.921738]\n",
            "Epoch :23\n",
            "d_loss : [0.28933385 0.5126953 ]\n",
            "g_loss : [20.925383, 1.1163926, 20.924267]\n",
            "Epoch :24\n",
            "d_loss : [0.29174754 0.5019531 ]\n",
            "g_loss : [14.361456, 1.1429732, 14.360313]\n",
            "Epoch :25\n",
            "d_loss : [0.2927961 0.5019531]\n",
            "g_loss : [24.414194, 1.126293, 24.413067]\n",
            "Epoch :26\n",
            "d_loss : [0.29993412 0.484375  ]\n",
            "g_loss : [31.879616, 1.1220036, 31.878494]\n",
            "Epoch :27\n",
            "d_loss : [0.29331225 0.49414062]\n",
            "g_loss : [15.815186, 1.1200471, 15.814066]\n",
            "Epoch :28\n",
            "d_loss : [0.288617   0.48046875]\n",
            "g_loss : [25.865316, 1.1237957, 25.864193]\n",
            "Epoch :29\n",
            "d_loss : [0.28801063 0.4892578 ]\n",
            "g_loss : [12.824603, 1.1242809, 12.823479]\n",
            "Epoch :30\n",
            "d_loss : [0.28694135 0.52441406]\n",
            "g_loss : [19.010052, 1.1385419, 19.008913]\n",
            "Epoch :31\n",
            "d_loss : [0.29412618 0.5       ]\n",
            "g_loss : [24.728785, 1.134274, 24.72765]\n",
            "Epoch :32\n",
            "d_loss : [0.29477078 0.4892578 ]\n",
            "g_loss : [18.79453, 1.1343558, 18.793396]\n",
            "Epoch :33\n",
            "d_loss : [0.29238772 0.5097656 ]\n",
            "g_loss : [18.76743, 1.1513331, 18.766277]\n",
            "Epoch :34\n",
            "d_loss : [0.2928217 0.5097656]\n",
            "g_loss : [17.766352, 1.14257, 17.76521]\n",
            "Epoch :35\n",
            "d_loss : [0.2877651  0.50390625]\n",
            "g_loss : [28.902887, 1.1657301, 28.901722]\n",
            "Epoch :36\n",
            "d_loss : [0.28912252 0.5029297 ]\n",
            "g_loss : [20.896517, 1.1506717, 20.895367]\n",
            "Epoch :37\n",
            "d_loss : [0.2957883  0.48828125]\n",
            "g_loss : [14.749208, 1.1214725, 14.748087]\n",
            "Epoch :38\n",
            "d_loss : [0.29076293 0.5214844 ]\n",
            "g_loss : [16.317362, 1.1324912, 16.316229]\n",
            "Epoch :39\n",
            "d_loss : [0.2920343  0.49023438]\n",
            "g_loss : [28.910973, 1.1564386, 28.909817]\n",
            "Epoch :40\n",
            "d_loss : [0.29085565 0.50390625]\n",
            "g_loss : [14.325073, 1.1212964, 14.323952]\n",
            "Epoch :41\n",
            "d_loss : [0.2939895  0.48632812]\n",
            "g_loss : [16.792019, 1.1484928, 16.79087]\n",
            "Epoch :42\n",
            "d_loss : [0.2942826 0.5029297]\n",
            "g_loss : [11.337191, 1.1576688, 11.336033]\n",
            "Epoch :43\n",
            "d_loss : [0.2922495 0.5029297]\n",
            "g_loss : [21.605284, 1.142829, 21.604141]\n",
            "Epoch :44\n",
            "d_loss : [0.29249692 0.50390625]\n",
            "g_loss : [16.93334, 1.1451377, 16.932196]\n",
            "Epoch :45\n",
            "d_loss : [0.29032975 0.5       ]\n",
            "g_loss : [15.525223, 1.1434867, 15.524079]\n",
            "Epoch :46\n",
            "d_loss : [0.2961035  0.49023438]\n",
            "g_loss : [18.915459, 1.1380672, 18.91432]\n",
            "Epoch :47\n",
            "d_loss : [0.2958786 0.4873047]\n",
            "g_loss : [16.057102, 1.1309372, 16.055971]\n",
            "Epoch :48\n",
            "d_loss : [0.28984326 0.4892578 ]\n",
            "g_loss : [21.385218, 1.1317022, 21.384087]\n",
            "Epoch :49\n",
            "d_loss : [0.28957456 0.49414062]\n",
            "g_loss : [20.534986, 1.1271974, 20.53386]\n",
            "Epoch :50\n",
            "d_loss : [0.28723818 0.5058594 ]\n",
            "g_loss : [13.289603, 1.1207483, 13.288483]\n",
            "Epoch :51\n",
            "d_loss : [0.29632133 0.48828125]\n",
            "g_loss : [19.36138, 1.1404797, 19.360239]\n",
            "Epoch :52\n",
            "d_loss : [0.28060836 0.515625  ]\n",
            "g_loss : [9.799419, 1.1394982, 9.79828]\n",
            "Epoch :53\n",
            "d_loss : [0.28332394 0.5205078 ]\n",
            "g_loss : [16.385693, 1.1495821, 16.384542]\n",
            "Epoch :54\n",
            "d_loss : [0.2927756 0.5019531]\n",
            "g_loss : [23.168068, 1.1502328, 23.166918]\n",
            "Epoch :55\n",
            "d_loss : [0.28787902 0.4951172 ]\n",
            "g_loss : [13.327725, 1.1680236, 13.326557]\n",
            "Epoch :56\n",
            "d_loss : [0.29012382 0.5097656 ]\n",
            "g_loss : [14.029476, 1.1429157, 14.028334]\n",
            "Epoch :57\n",
            "d_loss : [0.2941789  0.48242188]\n",
            "g_loss : [20.828829, 1.1466694, 20.827682]\n",
            "Epoch :58\n",
            "d_loss : [0.29051057 0.49902344]\n",
            "g_loss : [19.187136, 1.1454735, 19.18599]\n",
            "Epoch :59\n",
            "d_loss : [0.2957555  0.48046875]\n",
            "g_loss : [24.532404, 1.1512765, 24.531252]\n",
            "Epoch :60\n",
            "d_loss : [0.28814232 0.49414062]\n",
            "g_loss : [21.290508, 1.1491404, 21.28936]\n",
            "Epoch :61\n",
            "d_loss : [0.28969973 0.48242188]\n",
            "g_loss : [17.921288, 1.1368128, 17.92015]\n",
            "Epoch :62\n",
            "d_loss : [0.28865844 0.5078125 ]\n",
            "g_loss : [17.232992, 1.1294237, 17.231863]\n",
            "Epoch :63\n",
            "d_loss : [0.2965268  0.48339844]\n",
            "g_loss : [20.159126, 1.1348662, 20.157991]\n",
            "Epoch :64\n",
            "d_loss : [0.2918076 0.4921875]\n",
            "g_loss : [13.873091, 1.1396067, 13.871951]\n",
            "Epoch :65\n",
            "d_loss : [0.28811997 0.4921875 ]\n",
            "g_loss : [13.045836, 1.1355382, 13.044701]\n",
            "Epoch :66\n",
            "d_loss : [0.2955287  0.48339844]\n",
            "g_loss : [19.359486, 1.1337626, 19.358353]\n",
            "Epoch :67\n",
            "d_loss : [0.2862214  0.49804688]\n",
            "g_loss : [23.122557, 1.1494577, 23.121407]\n",
            "Epoch :68\n",
            "d_loss : [0.2837446 0.53125  ]\n",
            "g_loss : [14.005164, 1.1298627, 14.004034]\n",
            "Epoch :69\n",
            "d_loss : [0.28969988 0.50097656]\n",
            "g_loss : [26.095036, 1.1505435, 26.093885]\n",
            "Epoch :70\n",
            "d_loss : [0.29033488 0.5048828 ]\n",
            "g_loss : [15.150251, 1.1393989, 15.149112]\n",
            "Epoch :71\n",
            "d_loss : [0.29059404 0.49804688]\n",
            "g_loss : [19.666971, 1.159758, 19.665812]\n",
            "Epoch :72\n",
            "d_loss : [0.2916695  0.50390625]\n",
            "g_loss : [12.046681, 1.1265659, 12.045555]\n",
            "Epoch :73\n",
            "d_loss : [0.28782076 0.49609375]\n",
            "g_loss : [14.016895, 1.1344035, 14.01576]\n",
            "Epoch :74\n",
            "d_loss : [0.28999203 0.51660156]\n",
            "g_loss : [16.791058, 1.1436868, 16.789913]\n",
            "Epoch :75\n",
            "d_loss : [0.29068163 0.5107422 ]\n",
            "g_loss : [10.14169, 1.1362345, 10.140554]\n",
            "Epoch :76\n",
            "d_loss : [0.29369402 0.49316406]\n",
            "g_loss : [15.509691, 1.1382926, 15.508553]\n",
            "Epoch :77\n",
            "d_loss : [0.29686567 0.4921875 ]\n",
            "g_loss : [9.039683, 1.1351244, 9.038548]\n",
            "Epoch :78\n",
            "d_loss : [0.2914667 0.4873047]\n",
            "g_loss : [12.157638, 1.1430057, 12.156494]\n",
            "Epoch :79\n",
            "d_loss : [0.29549837 0.4951172 ]\n",
            "g_loss : [17.29132, 1.1525533, 17.290169]\n",
            "Epoch :80\n",
            "d_loss : [0.28674203 0.49121094]\n",
            "g_loss : [10.608856, 1.1308765, 10.607725]\n",
            "Epoch :81\n",
            "d_loss : [0.2936844 0.4951172]\n",
            "g_loss : [19.700203, 1.1452943, 19.699059]\n",
            "Epoch :82\n",
            "d_loss : [0.2889613  0.50097656]\n",
            "g_loss : [17.174343, 1.1549838, 17.173187]\n",
            "Epoch :83\n",
            "d_loss : [0.29243332 0.5136719 ]\n",
            "g_loss : [17.531841, 1.145402, 17.530695]\n",
            "Epoch :84\n",
            "d_loss : [0.29528967 0.48632812]\n",
            "g_loss : [18.009521, 1.1392663, 18.008383]\n",
            "Epoch :85\n",
            "d_loss : [0.2860094 0.5048828]\n",
            "g_loss : [10.211512, 1.1365762, 10.210375]\n",
            "Epoch :86\n",
            "d_loss : [0.2899114  0.50683594]\n",
            "g_loss : [13.079742, 1.1332946, 13.078609]\n",
            "Epoch :87\n",
            "d_loss : [0.29388997 0.49902344]\n",
            "g_loss : [17.511286, 1.1288567, 17.510157]\n",
            "Epoch :88\n",
            "d_loss : [0.28991073 0.5097656 ]\n",
            "g_loss : [15.342779, 1.1199467, 15.34166]\n",
            "Epoch :89\n",
            "d_loss : [0.28855273 0.49609375]\n",
            "g_loss : [15.504895, 1.1183941, 15.503777]\n",
            "Epoch :90\n",
            "d_loss : [0.2937414  0.49804688]\n",
            "g_loss : [12.027389, 1.1550395, 12.026234]\n",
            "Epoch :91\n",
            "d_loss : [0.28572407 0.5097656 ]\n",
            "g_loss : [15.2290945, 1.141388, 15.227953]\n",
            "Epoch :92\n",
            "d_loss : [0.29253945 0.4814453 ]\n",
            "g_loss : [14.923291, 1.1415219, 14.92215]\n",
            "Epoch :93\n",
            "d_loss : [0.28928667 0.5078125 ]\n",
            "g_loss : [19.878199, 1.1525184, 19.877047]\n",
            "Epoch :94\n",
            "d_loss : [0.29244518 0.5048828 ]\n",
            "g_loss : [13.415665, 1.1346688, 13.41453]\n",
            "Epoch :95\n",
            "d_loss : [0.28930733 0.51660156]\n",
            "g_loss : [17.977068, 1.1232419, 17.975945]\n",
            "Epoch :96\n",
            "d_loss : [0.29350817 0.50097656]\n",
            "g_loss : [13.169489, 1.1103925, 13.168379]\n",
            "Epoch :97\n",
            "d_loss : [0.2913962 0.4921875]\n",
            "g_loss : [18.276562, 1.1360506, 18.275425]\n",
            "Epoch :98\n",
            "d_loss : [0.2920344 0.5058594]\n",
            "g_loss : [9.593457, 1.1470602, 9.59231]\n",
            "Epoch :99\n",
            "d_loss : [0.28757155 0.5136719 ]\n",
            "g_loss : [21.19046, 1.1483641, 21.189312]\n",
            "Epoch :100\n",
            "d_loss : [0.29128236 0.5029297 ]\n",
            "g_loss : [10.78175, 1.1402951, 10.780609]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "PSNR: 16.0896355057363\n",
            "SSIM: 0.6731255269108992\n",
            "Epoch :101\n",
            "d_loss : [0.2905727  0.49804688]\n",
            "g_loss : [10.922667, 1.1147785, 10.921552]\n",
            "Epoch :102\n",
            "d_loss : [0.2885214 0.5263672]\n",
            "g_loss : [8.733689, 1.145961, 8.732543]\n",
            "Epoch :103\n",
            "d_loss : [0.28894848 0.50390625]\n",
            "g_loss : [13.721336, 1.1502028, 13.720186]\n",
            "Epoch :104\n",
            "d_loss : [0.2842244 0.5078125]\n",
            "g_loss : [14.512736, 1.1423552, 14.511594]\n",
            "Epoch :105\n",
            "d_loss : [0.2906915  0.50683594]\n",
            "g_loss : [13.090442, 1.1335996, 13.089308]\n",
            "Epoch :106\n",
            "d_loss : [0.29425657 0.4873047 ]\n",
            "g_loss : [14.604533, 1.1410129, 14.603393]\n",
            "Epoch :107\n",
            "d_loss : [0.29169327 0.5019531 ]\n",
            "g_loss : [12.628216, 1.1348649, 12.627081]\n",
            "Epoch :108\n",
            "d_loss : [0.29330555 0.5078125 ]\n",
            "g_loss : [9.571173, 1.1373115, 9.570035]\n",
            "Epoch :109\n",
            "d_loss : [0.287417   0.50878906]\n",
            "g_loss : [11.873871, 1.1366613, 11.872734]\n",
            "Epoch :110\n",
            "d_loss : [0.28798142 0.5029297 ]\n",
            "g_loss : [15.529302, 1.1418424, 15.52816]\n",
            "Epoch :111\n",
            "d_loss : [0.28993732 0.50878906]\n",
            "g_loss : [12.272944, 1.1244006, 12.27182]\n",
            "Epoch :112\n",
            "d_loss : [0.292419  0.5048828]\n",
            "g_loss : [13.091771, 1.1209434, 13.090651]\n",
            "Epoch :113\n",
            "d_loss : [0.29498532 0.47558594]\n",
            "g_loss : [11.205063, 1.1442382, 11.203918]\n",
            "Epoch :114\n",
            "d_loss : [0.28975207 0.49023438]\n",
            "g_loss : [9.271925, 1.1357982, 9.270789]\n",
            "Epoch :115\n",
            "d_loss : [0.29323485 0.4951172 ]\n",
            "g_loss : [9.811294, 1.1664813, 9.810127]\n",
            "Epoch :116\n",
            "d_loss : [0.28528258 0.5136719 ]\n",
            "g_loss : [13.322317, 1.156645, 13.32116]\n",
            "Epoch :117\n",
            "d_loss : [0.2903695 0.5185547]\n",
            "g_loss : [10.3952055, 1.1367977, 10.394069]\n",
            "Epoch :118\n",
            "d_loss : [0.28821963 0.5019531 ]\n",
            "g_loss : [10.245813, 1.1481605, 10.244665]\n",
            "Epoch :119\n",
            "d_loss : [0.2882164 0.5058594]\n",
            "g_loss : [9.770001, 1.1337548, 9.7688675]\n",
            "Epoch :120\n",
            "d_loss : [0.29536155 0.49316406]\n",
            "g_loss : [10.218218, 1.1117175, 10.217106]\n",
            "Epoch :121\n",
            "d_loss : [0.28574166 0.5234375 ]\n",
            "g_loss : [11.407705, 1.1391302, 11.406567]\n",
            "Epoch :122\n",
            "d_loss : [0.29332513 0.49023438]\n",
            "g_loss : [17.633274, 1.1329583, 17.632141]\n",
            "Epoch :123\n",
            "d_loss : [0.29419392 0.49609375]\n",
            "g_loss : [17.74039, 1.1310914, 17.73926]\n",
            "Epoch :124\n",
            "d_loss : [0.29539356 0.484375  ]\n",
            "g_loss : [11.252788, 1.1502159, 11.251637]\n",
            "Epoch :125\n",
            "d_loss : [0.29198927 0.50878906]\n",
            "g_loss : [11.745933, 1.143768, 11.744789]\n",
            "Epoch :126\n",
            "d_loss : [0.28905457 0.50097656]\n",
            "g_loss : [6.5955195, 1.1278908, 6.594392]\n",
            "Epoch :127\n",
            "d_loss : [0.2936308 0.4892578]\n",
            "g_loss : [13.1901865, 1.1394253, 13.189047]\n",
            "Epoch :128\n",
            "d_loss : [0.29078612 0.4951172 ]\n",
            "g_loss : [10.066444, 1.153862, 10.06529]\n",
            "Epoch :129\n",
            "d_loss : [0.28901157 0.49609375]\n",
            "g_loss : [11.78426, 1.1310742, 11.783129]\n",
            "Epoch :130\n",
            "d_loss : [0.2857059  0.50878906]\n",
            "g_loss : [17.825016, 1.1465715, 17.82387]\n",
            "Epoch :131\n",
            "d_loss : [0.2889824  0.51171875]\n",
            "g_loss : [9.584305, 1.1458086, 9.583159]\n",
            "Epoch :132\n",
            "d_loss : [0.289012  0.5214844]\n",
            "g_loss : [11.110261, 1.1418285, 11.109119]\n",
            "Epoch :133\n",
            "d_loss : [0.29231435 0.48828125]\n",
            "g_loss : [11.054023, 1.1262571, 11.0528965]\n",
            "Epoch :134\n",
            "d_loss : [0.291919   0.49804688]\n",
            "g_loss : [10.455288, 1.1347631, 10.454153]\n",
            "Epoch :135\n",
            "d_loss : [0.29038596 0.50683594]\n",
            "g_loss : [6.754191, 1.1344907, 6.7530565]\n",
            "Epoch :136\n",
            "d_loss : [0.2861144  0.51464844]\n",
            "g_loss : [8.135327, 1.1475115, 8.13418]\n",
            "Epoch :137\n",
            "d_loss : [0.2876023  0.48535156]\n",
            "g_loss : [12.536109, 1.1323261, 12.534977]\n",
            "Epoch :138\n",
            "d_loss : [0.2881831 0.5107422]\n",
            "g_loss : [10.926395, 1.1292721, 10.925266]\n",
            "Epoch :139\n",
            "d_loss : [0.29004458 0.51464844]\n",
            "g_loss : [10.717054, 1.1287692, 10.715925]\n",
            "Epoch :140\n",
            "d_loss : [0.28785157 0.49414062]\n",
            "g_loss : [14.030724, 1.1519605, 14.029572]\n",
            "Epoch :141\n",
            "d_loss : [0.29498005 0.49804688]\n",
            "g_loss : [12.3304825, 1.1466783, 12.329336]\n",
            "Epoch :142\n",
            "d_loss : [0.29291528 0.49414062]\n",
            "g_loss : [17.5217, 1.1495075, 17.52055]\n",
            "Epoch :143\n",
            "d_loss : [0.28798997 0.5107422 ]\n",
            "g_loss : [20.605844, 1.1433761, 20.604702]\n",
            "Epoch :144\n",
            "d_loss : [0.2942208 0.4892578]\n",
            "g_loss : [13.553084, 1.136071, 13.551949]\n",
            "Epoch :145\n",
            "d_loss : [0.29089722 0.50878906]\n",
            "g_loss : [13.244732, 1.1595129, 13.243572]\n",
            "Epoch :146\n",
            "d_loss : [0.29010022 0.4970703 ]\n",
            "g_loss : [9.134356, 1.1289811, 9.133226]\n",
            "Epoch :147\n",
            "d_loss : [0.2885883  0.50390625]\n",
            "g_loss : [15.217046, 1.1534253, 15.215893]\n",
            "Epoch :148\n",
            "d_loss : [0.28758505 0.52734375]\n",
            "g_loss : [12.976346, 1.150729, 12.975195]\n",
            "Epoch :149\n",
            "d_loss : [0.28703588 0.4970703 ]\n",
            "g_loss : [10.744769, 1.1387905, 10.74363]\n",
            "Epoch :150\n",
            "d_loss : [0.29193026 0.4794922 ]\n",
            "g_loss : [19.445694, 1.1494759, 19.444544]\n",
            "Epoch :151\n",
            "d_loss : [0.29034123 0.50878906]\n",
            "g_loss : [11.982087, 1.1281596, 11.980959]\n",
            "Epoch :152\n",
            "d_loss : [0.285879   0.49023438]\n",
            "g_loss : [14.748404, 1.155999, 14.747248]\n",
            "Epoch :153\n",
            "d_loss : [0.28666642 0.50683594]\n",
            "g_loss : [11.74226, 1.138499, 11.741121]\n",
            "Epoch :154\n",
            "d_loss : [0.29449117 0.49609375]\n",
            "g_loss : [11.440761, 1.1320729, 11.439629]\n",
            "Epoch :155\n",
            "d_loss : [0.29050666 0.49902344]\n",
            "g_loss : [8.139624, 1.1390433, 8.138485]\n",
            "Epoch :156\n",
            "d_loss : [0.29339668 0.4765625 ]\n",
            "g_loss : [12.590152, 1.1225384, 12.589029]\n",
            "Epoch :157\n",
            "d_loss : [0.29325852 0.4921875 ]\n",
            "g_loss : [5.8183517, 1.1413257, 5.81721]\n",
            "Epoch :158\n",
            "d_loss : [0.28909725 0.5048828 ]\n",
            "g_loss : [8.662103, 1.1247497, 8.660978]\n",
            "Epoch :159\n",
            "d_loss : [0.2874776  0.51464844]\n",
            "g_loss : [15.856034, 1.1413829, 15.854893]\n",
            "Epoch :160\n",
            "d_loss : [0.29236892 0.4892578 ]\n",
            "g_loss : [14.352639, 1.1268042, 14.351512]\n",
            "Epoch :161\n",
            "d_loss : [0.29344025 0.49902344]\n",
            "g_loss : [20.159185, 1.1573939, 20.158028]\n",
            "Epoch :162\n",
            "d_loss : [0.2939112  0.50390625]\n",
            "g_loss : [10.535674, 1.1209693, 10.534554]\n",
            "Epoch :163\n",
            "d_loss : [0.29548243 0.5029297 ]\n",
            "g_loss : [6.156791, 1.110195, 6.155681]\n",
            "Epoch :164\n",
            "d_loss : [0.29282957 0.50878906]\n",
            "g_loss : [14.721061, 1.1503701, 14.719911]\n",
            "Epoch :165\n",
            "d_loss : [0.29317608 0.5029297 ]\n",
            "g_loss : [14.970785, 1.1590608, 14.969626]\n",
            "Epoch :166\n",
            "d_loss : [0.29467544 0.49023438]\n",
            "g_loss : [13.414868, 1.1185418, 13.41375]\n",
            "Epoch :167\n",
            "d_loss : [0.29491872 0.49023438]\n",
            "g_loss : [9.06991, 1.1293383, 9.068781]\n",
            "Epoch :168\n",
            "d_loss : [0.2922783 0.4951172]\n",
            "g_loss : [8.921189, 1.1463282, 8.920043]\n",
            "Epoch :169\n",
            "d_loss : [0.29239336 0.4970703 ]\n",
            "g_loss : [9.303724, 1.1369665, 9.3025875]\n",
            "Epoch :170\n",
            "d_loss : [0.29469097 0.49804688]\n",
            "g_loss : [7.4152527, 1.1283915, 7.4141245]\n",
            "Epoch :171\n",
            "d_loss : [0.28951707 0.50390625]\n",
            "g_loss : [10.791921, 1.1263928, 10.790794]\n",
            "Epoch :172\n",
            "d_loss : [0.29125983 0.5078125 ]\n",
            "g_loss : [12.236057, 1.137474, 12.23492]\n",
            "Epoch :173\n",
            "d_loss : [0.29362267 0.49023438]\n",
            "g_loss : [8.571383, 1.1258861, 8.570257]\n",
            "Epoch :174\n",
            "d_loss : [0.28747517 0.50878906]\n",
            "g_loss : [9.191528, 1.1222502, 9.190406]\n",
            "Epoch :175\n",
            "d_loss : [0.29457965 0.49414062]\n",
            "g_loss : [12.900276, 1.1290292, 12.899147]\n",
            "Epoch :176\n",
            "d_loss : [0.29139316 0.5058594 ]\n",
            "g_loss : [5.2614856, 1.1484778, 5.260337]\n",
            "Epoch :177\n",
            "d_loss : [0.28937    0.50683594]\n",
            "g_loss : [11.385749, 1.1378381, 11.384611]\n",
            "Epoch :178\n",
            "d_loss : [0.28450704 0.51953125]\n",
            "g_loss : [9.767345, 1.1466678, 9.766199]\n",
            "Epoch :179\n",
            "d_loss : [0.293406   0.49804688]\n",
            "g_loss : [6.8657722, 1.1495814, 6.8646226]\n",
            "Epoch :180\n",
            "d_loss : [0.28877085 0.515625  ]\n",
            "g_loss : [11.839971, 1.1381598, 11.838833]\n",
            "Epoch :181\n",
            "d_loss : [0.28967825 0.50878906]\n",
            "g_loss : [9.124192, 1.1357466, 9.123056]\n",
            "Epoch :182\n",
            "d_loss : [0.28997436 0.5136719 ]\n",
            "g_loss : [10.352615, 1.1423306, 10.351473]\n",
            "Epoch :183\n",
            "d_loss : [0.29562646 0.4970703 ]\n",
            "g_loss : [10.623911, 1.1467927, 10.622765]\n",
            "Epoch :184\n",
            "d_loss : [0.2927685  0.49023438]\n",
            "g_loss : [10.990196, 1.1237458, 10.989073]\n",
            "Epoch :185\n",
            "d_loss : [0.28965998 0.5058594 ]\n",
            "g_loss : [13.267832, 1.1353388, 13.266697]\n",
            "Epoch :186\n",
            "d_loss : [0.28746247 0.49316406]\n",
            "g_loss : [11.972463, 1.1275175, 11.971335]\n",
            "Epoch :187\n",
            "d_loss : [0.29537815 0.4814453 ]\n",
            "g_loss : [12.862722, 1.1427563, 12.86158]\n",
            "Epoch :188\n",
            "d_loss : [0.2915789  0.51171875]\n",
            "g_loss : [10.696432, 1.1396289, 10.695292]\n",
            "Epoch :189\n",
            "d_loss : [0.2918355  0.50097656]\n",
            "g_loss : [12.439346, 1.143354, 12.438203]\n",
            "Epoch :190\n",
            "d_loss : [0.29411185 0.50683594]\n",
            "g_loss : [12.165526, 1.1416667, 12.164385]\n",
            "Epoch :191\n",
            "d_loss : [0.29057097 0.49902344]\n",
            "g_loss : [7.506139, 1.1270955, 7.5050116]\n",
            "Epoch :192\n",
            "d_loss : [0.2918793 0.4873047]\n",
            "g_loss : [10.54658, 1.1374307, 10.545443]\n",
            "Epoch :193\n",
            "d_loss : [0.29187125 0.50097656]\n",
            "g_loss : [5.440597, 1.1363792, 5.4394608]\n",
            "Epoch :194\n",
            "d_loss : [0.2887421 0.515625 ]\n",
            "g_loss : [11.752377, 1.1422491, 11.751234]\n",
            "Epoch :195\n",
            "d_loss : [0.28749874 0.5253906 ]\n",
            "g_loss : [8.2796335, 1.1564299, 8.278477]\n",
            "Epoch :196\n",
            "d_loss : [0.29117435 0.5029297 ]\n",
            "g_loss : [10.602939, 1.1137475, 10.601825]\n",
            "Epoch :197\n",
            "d_loss : [0.28661278 0.50878906]\n",
            "g_loss : [14.175509, 1.1605893, 14.174349]\n",
            "Epoch :198\n",
            "d_loss : [0.29379916 0.5078125 ]\n",
            "g_loss : [11.740763, 1.1541516, 11.739609]\n",
            "Epoch :199\n",
            "d_loss : [0.29284    0.49023438]\n",
            "g_loss : [10.003045, 1.1572812, 10.001888]\n",
            "Epoch :200\n",
            "d_loss : [0.29442388 0.4814453 ]\n",
            "g_loss : [10.537387, 1.1025424, 10.536284]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "PSNR: 19.315045199662382\n",
            "SSIM: 0.6792591134341328\n",
            "Epoch :201\n",
            "d_loss : [0.29168016 0.49609375]\n",
            "g_loss : [8.195609, 1.1309881, 8.194478]\n",
            "Epoch :202\n",
            "d_loss : [0.29004198 0.5126953 ]\n",
            "g_loss : [8.331889, 1.1492319, 8.33074]\n",
            "Epoch :203\n",
            "d_loss : [0.28808665 0.49414062]\n",
            "g_loss : [9.679746, 1.112941, 9.678633]\n",
            "Epoch :204\n",
            "d_loss : [0.29184204 0.5107422 ]\n",
            "g_loss : [9.107692, 1.1342088, 9.106558]\n",
            "Epoch :205\n",
            "d_loss : [0.2915191  0.50390625]\n",
            "g_loss : [6.831046, 1.1522076, 6.829894]\n",
            "Epoch :206\n",
            "d_loss : [0.28673688 0.5029297 ]\n",
            "g_loss : [13.197972, 1.1445093, 13.196828]\n",
            "Epoch :207\n",
            "d_loss : [0.293535   0.49316406]\n",
            "g_loss : [16.751408, 1.1419942, 16.750265]\n",
            "Epoch :208\n",
            "d_loss : [0.28823757 0.5214844 ]\n",
            "g_loss : [9.064117, 1.1578543, 9.06296]\n",
            "Epoch :209\n",
            "d_loss : [0.2858308 0.5126953]\n",
            "g_loss : [7.9491177, 1.1240894, 7.9479938]\n",
            "Epoch :210\n",
            "d_loss : [0.29357067 0.51464844]\n",
            "g_loss : [10.695905, 1.1400809, 10.694765]\n",
            "Epoch :211\n",
            "d_loss : [0.28781956 0.49609375]\n",
            "g_loss : [17.525604, 1.1234559, 17.52448]\n",
            "Epoch :212\n",
            "d_loss : [0.28848135 0.5185547 ]\n",
            "g_loss : [11.932118, 1.1222992, 11.930996]\n",
            "Epoch :213\n",
            "d_loss : [0.28866926 0.4892578 ]\n",
            "g_loss : [10.302666, 1.1352022, 10.301531]\n",
            "Epoch :214\n",
            "d_loss : [0.29172164 0.5019531 ]\n",
            "g_loss : [10.835665, 1.1249882, 10.834539]\n",
            "Epoch :215\n",
            "d_loss : [0.2901752  0.51171875]\n",
            "g_loss : [10.163766, 1.131793, 10.162634]\n",
            "Epoch :216\n",
            "d_loss : [0.28783    0.49804688]\n",
            "g_loss : [10.280213, 1.1204584, 10.279093]\n",
            "Epoch :217\n",
            "d_loss : [0.29056215 0.49316406]\n",
            "g_loss : [9.488172, 1.1271958, 9.487044]\n",
            "Epoch :218\n",
            "d_loss : [0.29017794 0.51171875]\n",
            "g_loss : [11.43965, 1.1463101, 11.438503]\n",
            "Epoch :219\n",
            "d_loss : [0.29642585 0.4794922 ]\n",
            "g_loss : [10.542618, 1.144876, 10.541473]\n",
            "Epoch :220\n",
            "d_loss : [0.29463735 0.5205078 ]\n",
            "g_loss : [14.376468, 1.1325859, 14.375335]\n",
            "Epoch :221\n",
            "d_loss : [0.28871837 0.5097656 ]\n",
            "g_loss : [7.1641464, 1.1477401, 7.1629987]\n",
            "Epoch :222\n",
            "d_loss : [0.2941928 0.4951172]\n",
            "g_loss : [10.708672, 1.1474538, 10.707524]\n",
            "Epoch :223\n",
            "d_loss : [0.2896541  0.49316406]\n",
            "g_loss : [11.168927, 1.1526537, 11.167774]\n",
            "Epoch :224\n",
            "d_loss : [0.29348522 0.49023438]\n",
            "g_loss : [7.035006, 1.1290282, 7.033877]\n",
            "Epoch :225\n",
            "d_loss : [0.2885226 0.4794922]\n",
            "g_loss : [10.01772, 1.1426241, 10.016578]\n",
            "Epoch :226\n",
            "d_loss : [0.28757134 0.49414062]\n",
            "g_loss : [10.161247, 1.1475041, 10.1601]\n",
            "Epoch :227\n",
            "d_loss : [0.29333112 0.5078125 ]\n",
            "g_loss : [5.8426294, 1.1260865, 5.841503]\n",
            "Epoch :228\n",
            "d_loss : [0.2904651  0.50878906]\n",
            "g_loss : [9.62961, 1.1409447, 9.628469]\n",
            "Epoch :229\n",
            "d_loss : [0.29177523 0.49902344]\n",
            "g_loss : [12.694617, 1.1227838, 12.693495]\n",
            "Epoch :230\n",
            "d_loss : [0.28991205 0.515625  ]\n",
            "g_loss : [10.731914, 1.1398895, 10.730774]\n",
            "Epoch :231\n",
            "d_loss : [0.2895346 0.5029297]\n",
            "g_loss : [13.300448, 1.1563795, 13.299292]\n",
            "Epoch :232\n",
            "d_loss : [0.2907796  0.51660156]\n",
            "g_loss : [9.294309, 1.1432655, 9.293165]\n",
            "Epoch :233\n",
            "d_loss : [0.29125464 0.49609375]\n",
            "g_loss : [13.001056, 1.1587255, 12.999897]\n",
            "Epoch :234\n",
            "d_loss : [0.29362333 0.4921875 ]\n",
            "g_loss : [11.021229, 1.142125, 11.020086]\n",
            "Epoch :235\n",
            "d_loss : [0.29061785 0.5       ]\n",
            "g_loss : [7.83492, 1.1320181, 7.833788]\n",
            "Epoch :236\n",
            "d_loss : [0.28826016 0.5097656 ]\n",
            "g_loss : [7.1839046, 1.1370885, 7.1827674]\n",
            "Epoch :237\n",
            "d_loss : [0.2877997 0.5019531]\n",
            "g_loss : [8.972219, 1.1578205, 8.971062]\n",
            "Epoch :238\n",
            "d_loss : [0.2918337  0.49121094]\n",
            "g_loss : [10.152345, 1.1316597, 10.151213]\n",
            "Epoch :239\n",
            "d_loss : [0.28443834 0.51464844]\n",
            "g_loss : [9.485061, 1.1228979, 9.483938]\n",
            "Epoch :240\n",
            "d_loss : [0.2915527  0.49023438]\n",
            "g_loss : [5.923843, 1.1332369, 5.9227095]\n",
            "Epoch :241\n",
            "d_loss : [0.28973418 0.4921875 ]\n",
            "g_loss : [12.211101, 1.1167705, 12.209984]\n",
            "Epoch :242\n",
            "d_loss : [0.29354572 0.49609375]\n",
            "g_loss : [6.9021096, 1.1404886, 6.900969]\n",
            "Epoch :243\n",
            "d_loss : [0.2927735  0.48828125]\n",
            "g_loss : [10.062361, 1.1189228, 10.061242]\n",
            "Epoch :244\n",
            "d_loss : [0.29586953 0.49804688]\n",
            "g_loss : [7.6905894, 1.1211454, 7.6894684]\n",
            "Epoch :245\n",
            "d_loss : [0.29536045 0.4814453 ]\n",
            "g_loss : [7.8645196, 1.1333383, 7.863386]\n",
            "Epoch :246\n",
            "d_loss : [0.29371095 0.5078125 ]\n",
            "g_loss : [11.035081, 1.1657966, 11.0339155]\n",
            "Epoch :247\n",
            "d_loss : [0.2940846  0.48046875]\n",
            "g_loss : [8.664447, 1.1320058, 8.663315]\n",
            "Epoch :248\n",
            "d_loss : [0.2916977 0.4892578]\n",
            "g_loss : [8.64929, 1.1580188, 8.648132]\n",
            "Epoch :249\n",
            "d_loss : [0.29492295 0.5       ]\n",
            "g_loss : [6.211128, 1.1444926, 6.209984]\n",
            "Epoch :250\n",
            "d_loss : [0.29018015 0.4921875 ]\n",
            "g_loss : [5.821829, 1.1132758, 5.8207154]\n",
            "Epoch :251\n",
            "d_loss : [0.2883132 0.5078125]\n",
            "g_loss : [8.37431, 1.1391232, 8.373171]\n",
            "Epoch :252\n",
            "d_loss : [0.29063913 0.4892578 ]\n",
            "g_loss : [10.271208, 1.1349018, 10.270073]\n",
            "Epoch :253\n",
            "d_loss : [0.29122078 0.48828125]\n",
            "g_loss : [4.299832, 1.1505759, 4.2986813]\n",
            "Epoch :254\n",
            "d_loss : [0.29351002 0.5029297 ]\n",
            "g_loss : [10.320129, 1.1274729, 10.319002]\n",
            "Epoch :255\n",
            "d_loss : [0.2887737 0.5048828]\n",
            "g_loss : [7.785187, 1.1527987, 7.784034]\n",
            "Epoch :256\n",
            "d_loss : [0.29254425 0.51660156]\n",
            "g_loss : [7.8048525, 1.1328661, 7.8037195]\n",
            "Epoch :257\n",
            "d_loss : [0.29133567 0.5048828 ]\n",
            "g_loss : [4.965311, 1.1508167, 4.9641604]\n",
            "Epoch :258\n",
            "d_loss : [0.28823164 0.515625  ]\n",
            "g_loss : [10.446915, 1.1477482, 10.445766]\n",
            "Epoch :259\n",
            "d_loss : [0.29315543 0.49804688]\n",
            "g_loss : [10.389083, 1.1375368, 10.387945]\n",
            "Epoch :260\n",
            "d_loss : [0.29557002 0.48535156]\n",
            "g_loss : [4.519033, 1.1380491, 4.5178947]\n",
            "Epoch :261\n",
            "d_loss : [0.28799245 0.49902344]\n",
            "g_loss : [7.1602035, 1.1441662, 7.1590595]\n",
            "Epoch :262\n",
            "d_loss : [0.2920155  0.48828125]\n",
            "g_loss : [7.5877776, 1.1051645, 7.5866723]\n",
            "Epoch :263\n",
            "d_loss : [0.28923962 0.51464844]\n",
            "g_loss : [7.9789567, 1.1402378, 7.9778166]\n",
            "Epoch :264\n",
            "d_loss : [0.29145285 0.5126953 ]\n",
            "g_loss : [12.286167, 1.1371362, 12.28503]\n",
            "Epoch :265\n",
            "d_loss : [0.29137594 0.50683594]\n",
            "g_loss : [6.726512, 1.123595, 6.7253885]\n",
            "Epoch :266\n",
            "d_loss : [0.2883528 0.5107422]\n",
            "g_loss : [10.766022, 1.1562703, 10.764866]\n",
            "Epoch :267\n",
            "d_loss : [0.29115552 0.48828125]\n",
            "g_loss : [5.7359014, 1.126952, 5.7347746]\n",
            "Epoch :268\n",
            "d_loss : [0.29015934 0.49414062]\n",
            "g_loss : [7.875501, 1.1313248, 7.8743696]\n",
            "Epoch :269\n",
            "d_loss : [0.29639646 0.5175781 ]\n",
            "g_loss : [7.8664536, 1.1361682, 7.8653173]\n",
            "Epoch :270\n",
            "d_loss : [0.2897823  0.52441406]\n",
            "g_loss : [9.144338, 1.1339002, 9.143204]\n",
            "Epoch :271\n",
            "d_loss : [0.29348952 0.50683594]\n",
            "g_loss : [8.842492, 1.1537378, 8.841338]\n",
            "Epoch :272\n",
            "d_loss : [0.29413486 0.4951172 ]\n",
            "g_loss : [7.2281513, 1.1368554, 7.2270145]\n",
            "Epoch :273\n",
            "d_loss : [0.29044965 0.5019531 ]\n",
            "g_loss : [8.913231, 1.1287658, 8.912102]\n",
            "Epoch :274\n",
            "d_loss : [0.29275244 0.50097656]\n",
            "g_loss : [8.865372, 1.1365238, 8.864235]\n",
            "Epoch :275\n",
            "d_loss : [0.2931713 0.5019531]\n",
            "g_loss : [8.881779, 1.1382229, 8.88064]\n",
            "Epoch :276\n",
            "d_loss : [0.29354283 0.5253906 ]\n",
            "g_loss : [5.9412394, 1.1404676, 5.940099]\n",
            "Epoch :277\n",
            "d_loss : [0.2915784 0.5048828]\n",
            "g_loss : [6.340022, 1.1318521, 6.33889]\n",
            "Epoch :278\n",
            "d_loss : [0.29118383 0.5078125 ]\n",
            "g_loss : [5.7431564, 1.1349169, 5.7420216]\n",
            "Epoch :279\n",
            "d_loss : [0.2945879 0.4892578]\n",
            "g_loss : [7.137125, 1.1351529, 7.1359897]\n",
            "Epoch :280\n",
            "d_loss : [0.292195  0.5078125]\n",
            "g_loss : [3.763077, 1.1554079, 3.7619216]\n",
            "Epoch :281\n",
            "d_loss : [0.28599375 0.5048828 ]\n",
            "g_loss : [4.5121856, 1.1516771, 4.511034]\n",
            "Epoch :282\n",
            "d_loss : [0.29276612 0.49804688]\n",
            "g_loss : [9.58805, 1.1360853, 9.586914]\n",
            "Epoch :283\n",
            "d_loss : [0.290727   0.51464844]\n",
            "g_loss : [4.7411776, 1.1616373, 4.740016]\n",
            "Epoch :284\n",
            "d_loss : [0.29189578 0.50683594]\n",
            "g_loss : [13.393703, 1.1540389, 13.3925495]\n",
            "Epoch :285\n",
            "d_loss : [0.28814888 0.5029297 ]\n",
            "g_loss : [6.6229277, 1.1282761, 6.6217995]\n",
            "Epoch :286\n",
            "d_loss : [0.2931136  0.50390625]\n",
            "g_loss : [9.541196, 1.1090662, 9.540087]\n",
            "Epoch :287\n",
            "d_loss : [0.29073423 0.51171875]\n",
            "g_loss : [6.1726274, 1.1432804, 6.171484]\n",
            "Epoch :288\n",
            "d_loss : [0.28924346 0.49121094]\n",
            "g_loss : [6.4206104, 1.1166434, 6.4194937]\n",
            "Epoch :289\n",
            "d_loss : [0.28769672 0.50390625]\n",
            "g_loss : [7.203951, 1.1495035, 7.202801]\n",
            "Epoch :290\n",
            "d_loss : [0.29440212 0.49609375]\n",
            "g_loss : [7.0017056, 1.1240928, 7.0005817]\n",
            "Epoch :291\n",
            "d_loss : [0.29652822 0.4873047 ]\n",
            "g_loss : [10.188368, 1.1544125, 10.187214]\n",
            "Epoch :292\n",
            "d_loss : [0.2900192 0.4970703]\n",
            "g_loss : [8.520226, 1.1367908, 8.519089]\n",
            "Epoch :293\n",
            "d_loss : [0.29697257 0.5097656 ]\n",
            "g_loss : [7.9164824, 1.144496, 7.915338]\n",
            "Epoch :294\n",
            "d_loss : [0.29360762 0.50097656]\n",
            "g_loss : [9.595466, 1.1422536, 9.594323]\n",
            "Epoch :295\n",
            "d_loss : [0.29165924 0.51464844]\n",
            "g_loss : [7.074046, 1.1216731, 7.0729246]\n",
            "Epoch :296\n",
            "d_loss : [0.29036266 0.4970703 ]\n",
            "g_loss : [8.363117, 1.1482685, 8.361969]\n",
            "Epoch :297\n",
            "d_loss : [0.2878337  0.51171875]\n",
            "g_loss : [10.362291, 1.1022687, 10.361189]\n",
            "Epoch :298\n",
            "d_loss : [0.28969145 0.5136719 ]\n",
            "g_loss : [5.116677, 1.1217833, 5.115555]\n",
            "Epoch :299\n",
            "d_loss : [0.2900657 0.4873047]\n",
            "g_loss : [7.4028964, 1.1528363, 7.4017434]\n",
            "Epoch :300\n",
            "d_loss : [0.289321   0.49609375]\n",
            "g_loss : [9.976158, 1.1498053, 9.975008]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "PSNR: 15.720764775069629\n",
            "SSIM: 0.63492060103846\n",
            "Epoch :301\n",
            "d_loss : [0.29654568 0.515625  ]\n",
            "g_loss : [5.873206, 1.154223, 5.8720517]\n",
            "Epoch :302\n",
            "d_loss : [0.28757265 0.50683594]\n",
            "g_loss : [4.634005, 1.1361485, 4.632869]\n",
            "Epoch :303\n",
            "d_loss : [0.28915954 0.5019531 ]\n",
            "g_loss : [8.476239, 1.1617887, 8.475078]\n",
            "Epoch :304\n",
            "d_loss : [0.28773877 0.5205078 ]\n",
            "g_loss : [8.358559, 1.1084578, 8.3574505]\n",
            "Epoch :305\n",
            "d_loss : [0.2846297 0.5214844]\n",
            "g_loss : [9.181454, 1.1479905, 9.1803055]\n",
            "Epoch :306\n",
            "d_loss : [0.28886092 0.5058594 ]\n",
            "g_loss : [5.2319536, 1.1367428, 5.230817]\n",
            "Epoch :307\n",
            "d_loss : [0.28900436 0.50390625]\n",
            "g_loss : [8.366958, 1.1416655, 8.365816]\n",
            "Epoch :308\n",
            "d_loss : [0.28760424 0.48828125]\n",
            "g_loss : [8.984462, 1.1263748, 8.9833355]\n",
            "Epoch :309\n",
            "d_loss : [0.29264176 0.48242188]\n",
            "g_loss : [7.761076, 1.1285571, 7.7599473]\n",
            "Epoch :310\n",
            "d_loss : [0.2921304 0.5019531]\n",
            "g_loss : [10.01635, 1.1383057, 10.015211]\n",
            "Epoch :311\n",
            "d_loss : [0.2876145  0.51171875]\n",
            "g_loss : [9.05246, 1.1454644, 9.051314]\n",
            "Epoch :312\n",
            "d_loss : [0.29108024 0.49609375]\n",
            "g_loss : [7.9623094, 1.151429, 7.961158]\n",
            "Epoch :313\n",
            "d_loss : [0.29146564 0.5       ]\n",
            "g_loss : [5.357646, 1.141703, 5.3565044]\n",
            "Epoch :314\n",
            "d_loss : [0.2899136  0.50097656]\n",
            "g_loss : [7.060153, 1.125633, 7.059027]\n",
            "Epoch :315\n",
            "d_loss : [0.29479545 0.4970703 ]\n",
            "g_loss : [6.04534, 1.132542, 6.0442076]\n",
            "Epoch :316\n",
            "d_loss : [0.28534174 0.52441406]\n",
            "g_loss : [7.5515766, 1.1053908, 7.5504713]\n",
            "Epoch :317\n",
            "d_loss : [0.2922235 0.5058594]\n",
            "g_loss : [10.098599, 1.1422819, 10.097457]\n",
            "Epoch :318\n",
            "d_loss : [0.29141563 0.50683594]\n",
            "g_loss : [7.194704, 1.128036, 7.193576]\n",
            "Epoch :319\n",
            "d_loss : [0.2899372 0.5107422]\n",
            "g_loss : [8.246251, 1.1469626, 8.245104]\n",
            "Epoch :320\n",
            "d_loss : [0.2851727 0.5126953]\n",
            "g_loss : [5.4009595, 1.1237845, 5.3998356]\n",
            "Epoch :321\n",
            "d_loss : [0.287749 0.515625]\n",
            "g_loss : [7.2330203, 1.135668, 7.2318845]\n",
            "Epoch :322\n",
            "d_loss : [0.2902559 0.5175781]\n",
            "g_loss : [5.6479588, 1.1328897, 5.646826]\n",
            "Epoch :323\n",
            "d_loss : [0.28872132 0.5234375 ]\n",
            "g_loss : [7.9686546, 1.1343644, 7.96752]\n",
            "Epoch :324\n",
            "d_loss : [0.2904142 0.4970703]\n",
            "g_loss : [4.629238, 1.1205677, 4.6281176]\n",
            "Epoch :325\n",
            "d_loss : [0.29108283 0.5048828 ]\n",
            "g_loss : [5.432158, 1.131753, 5.4310265]\n",
            "Epoch :326\n",
            "d_loss : [0.28918633 0.51953125]\n",
            "g_loss : [5.3820734, 1.1291397, 5.3809443]\n",
            "Epoch :327\n",
            "d_loss : [0.29175594 0.5019531 ]\n",
            "g_loss : [5.369353, 1.1380296, 5.3682146]\n",
            "Epoch :328\n",
            "d_loss : [0.29061562 0.50097656]\n",
            "g_loss : [10.008714, 1.1334503, 10.00758]\n",
            "Epoch :329\n",
            "d_loss : [0.29034662 0.50683594]\n",
            "g_loss : [6.579376, 1.155129, 6.5782213]\n",
            "Epoch :330\n",
            "d_loss : [0.28788915 0.4951172 ]\n",
            "g_loss : [6.6919127, 1.1376112, 6.690775]\n",
            "Epoch :331\n",
            "d_loss : [0.2904356 0.5107422]\n",
            "g_loss : [5.6956344, 1.1220537, 5.6945124]\n",
            "Epoch :332\n",
            "d_loss : [0.2865411  0.49804688]\n",
            "g_loss : [6.3888497, 1.1417961, 6.3877077]\n",
            "Epoch :333\n",
            "d_loss : [0.29281038 0.49804688]\n",
            "g_loss : [7.9884343, 1.1347635, 7.9872994]\n",
            "Epoch :334\n",
            "d_loss : [0.2928887  0.49902344]\n",
            "g_loss : [4.029091, 1.1498966, 4.0279408]\n",
            "Epoch :335\n",
            "d_loss : [0.28792796 0.50878906]\n",
            "g_loss : [6.6619825, 1.1150688, 6.6608677]\n",
            "Epoch :336\n",
            "d_loss : [0.29367486 0.49316406]\n",
            "g_loss : [4.919345, 1.1540132, 4.918191]\n",
            "Epoch :337\n",
            "d_loss : [0.29409328 0.484375  ]\n",
            "g_loss : [5.0054345, 1.1143323, 5.00432]\n",
            "Epoch :338\n",
            "d_loss : [0.28829825 0.49902344]\n",
            "g_loss : [7.371039, 1.1481992, 7.3698907]\n",
            "Epoch :339\n",
            "d_loss : [0.29184765 0.50390625]\n",
            "g_loss : [5.778216, 1.1250801, 5.777091]\n",
            "Epoch :340\n",
            "d_loss : [0.29081517 0.50683594]\n",
            "g_loss : [4.5300264, 1.1397698, 4.528887]\n",
            "Epoch :341\n",
            "d_loss : [0.2895065  0.49902344]\n",
            "g_loss : [6.1377525, 1.1158106, 6.1366367]\n",
            "Epoch :342\n",
            "d_loss : [0.29351136 0.49121094]\n",
            "g_loss : [9.56143, 1.1466448, 9.560284]\n",
            "Epoch :343\n",
            "d_loss : [0.29408193 0.5019531 ]\n",
            "g_loss : [7.8801208, 1.1388865, 7.878982]\n",
            "Epoch :344\n",
            "d_loss : [0.29113463 0.48632812]\n",
            "g_loss : [7.1754007, 1.1376504, 7.174263]\n",
            "Epoch :345\n",
            "d_loss : [0.29124805 0.4951172 ]\n",
            "g_loss : [4.475861, 1.1441636, 4.474717]\n",
            "Epoch :346\n",
            "d_loss : [0.288782  0.5019531]\n",
            "g_loss : [7.476768, 1.1347554, 7.475633]\n",
            "Epoch :347\n",
            "d_loss : [0.29126292 0.5078125 ]\n",
            "g_loss : [7.944805, 1.148215, 7.943657]\n",
            "Epoch :348\n",
            "d_loss : [0.29283637 0.49414062]\n",
            "g_loss : [7.878685, 1.1062636, 7.8775787]\n",
            "Epoch :349\n",
            "d_loss : [0.2885446  0.51660156]\n",
            "g_loss : [7.735961, 1.1027112, 7.734858]\n",
            "Epoch :350\n",
            "d_loss : [0.2920991 0.5058594]\n",
            "g_loss : [7.9898586, 1.1396178, 7.988719]\n",
            "Epoch :351\n",
            "d_loss : [0.2927612 0.5058594]\n",
            "g_loss : [6.5872054, 1.136466, 6.586069]\n",
            "Epoch :352\n",
            "d_loss : [0.29386312 0.50878906]\n",
            "g_loss : [4.6105123, 1.1248549, 4.6093874]\n",
            "Epoch :353\n",
            "d_loss : [0.2876602 0.515625 ]\n",
            "g_loss : [6.1652284, 1.148931, 6.1640797]\n",
            "Epoch :354\n",
            "d_loss : [0.2872362 0.5078125]\n",
            "g_loss : [7.5302496, 1.1454842, 7.529104]\n",
            "Epoch :355\n",
            "d_loss : [0.2898525 0.4970703]\n",
            "g_loss : [7.0488, 1.1479645, 7.0476522]\n",
            "Epoch :356\n",
            "d_loss : [0.28897846 0.5       ]\n",
            "g_loss : [6.607556, 1.13358, 6.6064224]\n",
            "Epoch :357\n",
            "d_loss : [0.28998694 0.5234375 ]\n",
            "g_loss : [5.6062956, 1.1309996, 5.6051645]\n",
            "Epoch :358\n",
            "d_loss : [0.2955711  0.48828125]\n",
            "g_loss : [5.635798, 1.1431046, 5.634655]\n",
            "Epoch :359\n",
            "d_loss : [0.2922768 0.4951172]\n",
            "g_loss : [8.962577, 1.1214355, 8.961455]\n",
            "Epoch :360\n",
            "d_loss : [0.2908541  0.49902344]\n",
            "g_loss : [5.5558033, 1.1492522, 5.554654]\n",
            "Epoch :361\n",
            "d_loss : [0.2936291  0.49804688]\n",
            "g_loss : [5.5251207, 1.1036043, 5.5240173]\n",
            "Epoch :362\n",
            "d_loss : [0.29362682 0.49121094]\n",
            "g_loss : [6.242265, 1.1231902, 6.241142]\n",
            "Epoch :363\n",
            "d_loss : [0.2911135 0.5175781]\n",
            "g_loss : [4.8685737, 1.136154, 4.8674374]\n",
            "Epoch :364\n",
            "d_loss : [0.29316995 0.50390625]\n",
            "g_loss : [3.425648, 1.1520996, 3.424496]\n",
            "Epoch :365\n",
            "d_loss : [0.29213163 0.5       ]\n",
            "g_loss : [2.9913373, 1.144067, 2.9901931]\n",
            "Epoch :366\n",
            "d_loss : [0.2881953  0.51660156]\n",
            "g_loss : [6.520026, 1.1223382, 6.5189037]\n",
            "Epoch :367\n",
            "d_loss : [0.29246816 0.48046875]\n",
            "g_loss : [5.8325586, 1.1340938, 5.8314247]\n",
            "Epoch :368\n",
            "d_loss : [0.29345298 0.5107422 ]\n",
            "g_loss : [4.649364, 1.1210535, 4.648243]\n",
            "Epoch :369\n",
            "d_loss : [0.28984442 0.5097656 ]\n",
            "g_loss : [7.8059564, 1.1240058, 7.8048325]\n",
            "Epoch :370\n",
            "d_loss : [0.2878593 0.5029297]\n",
            "g_loss : [5.577303, 1.1140778, 5.576189]\n",
            "Epoch :371\n",
            "d_loss : [0.2905358 0.5048828]\n",
            "g_loss : [2.649801, 1.1541126, 2.6486468]\n",
            "Epoch :372\n",
            "d_loss : [0.2919302 0.5      ]\n",
            "g_loss : [4.5288496, 1.1345968, 4.527715]\n",
            "Epoch :373\n",
            "d_loss : [0.288569  0.5019531]\n",
            "g_loss : [3.335267, 1.1459136, 3.3341212]\n",
            "Epoch :374\n",
            "d_loss : [0.28588265 0.51660156]\n",
            "g_loss : [2.6089075, 1.1539767, 2.6077535]\n",
            "Epoch :375\n",
            "d_loss : [0.2943739 0.5097656]\n",
            "g_loss : [6.2776356, 1.136665, 6.276499]\n",
            "Epoch :376\n",
            "d_loss : [0.292341  0.5078125]\n",
            "g_loss : [6.674711, 1.1422911, 6.6735687]\n",
            "Epoch :377\n",
            "d_loss : [0.2941672 0.5019531]\n",
            "g_loss : [7.0782523, 1.1513422, 7.0771008]\n",
            "Epoch :378\n",
            "d_loss : [0.289591  0.4921875]\n",
            "g_loss : [6.0100703, 1.1429689, 6.0089273]\n",
            "Epoch :379\n",
            "d_loss : [0.29592124 0.48632812]\n",
            "g_loss : [7.3231363, 1.1094029, 7.3220267]\n",
            "Epoch :380\n",
            "d_loss : [0.29083192 0.49121094]\n",
            "g_loss : [5.3719215, 1.1301275, 5.3707914]\n",
            "Epoch :381\n",
            "d_loss : [0.28996214 0.50390625]\n",
            "g_loss : [4.7349005, 1.1263806, 4.733774]\n",
            "Epoch :382\n",
            "d_loss : [0.29017547 0.49023438]\n",
            "g_loss : [7.783037, 1.1438165, 7.7818933]\n",
            "Epoch :383\n",
            "d_loss : [0.293104  0.5048828]\n",
            "g_loss : [8.176298, 1.1204903, 8.175178]\n",
            "Epoch :384\n",
            "d_loss : [0.28969136 0.5019531 ]\n",
            "g_loss : [5.17374, 1.1460267, 5.172594]\n",
            "Epoch :385\n",
            "d_loss : [0.2925554 0.5      ]\n",
            "g_loss : [5.3300056, 1.1457793, 5.32886]\n",
            "Epoch :386\n",
            "d_loss : [0.29540646 0.49902344]\n",
            "g_loss : [2.728711, 1.1499019, 2.727561]\n",
            "Epoch :387\n",
            "d_loss : [0.28326565 0.5078125 ]\n",
            "g_loss : [3.2270372, 1.1455959, 3.2258916]\n",
            "Epoch :388\n",
            "d_loss : [0.2918991 0.5029297]\n",
            "g_loss : [5.436246, 1.1340642, 5.435112]\n",
            "Epoch :389\n",
            "d_loss : [0.2895963 0.5136719]\n",
            "g_loss : [4.5048866, 1.1430316, 4.5037436]\n",
            "Epoch :390\n",
            "d_loss : [0.28754252 0.5097656 ]\n",
            "g_loss : [3.3648448, 1.1171751, 3.3637276]\n",
            "Epoch :391\n",
            "d_loss : [0.29079777 0.50390625]\n",
            "g_loss : [4.6184835, 1.1394503, 4.617344]\n",
            "Epoch :392\n",
            "d_loss : [0.28728312 0.51953125]\n",
            "g_loss : [8.0568, 1.1608232, 8.055639]\n",
            "Epoch :393\n",
            "d_loss : [0.29194033 0.48339844]\n",
            "g_loss : [5.3181424, 1.1475136, 5.3169947]\n",
            "Epoch :394\n",
            "d_loss : [0.29195604 0.4951172 ]\n",
            "g_loss : [6.583563, 1.127236, 6.5824356]\n",
            "Epoch :395\n",
            "d_loss : [0.29603073 0.5058594 ]\n",
            "g_loss : [4.698486, 1.1326032, 4.6973534]\n",
            "Epoch :396\n",
            "d_loss : [0.28781122 0.5136719 ]\n",
            "g_loss : [4.9288254, 1.1121882, 4.9277134]\n",
            "Epoch :397\n",
            "d_loss : [0.2893083 0.5019531]\n",
            "g_loss : [7.14586, 1.1516018, 7.1447086]\n",
            "Epoch :398\n",
            "d_loss : [0.28826728 0.49316406]\n",
            "g_loss : [3.7111003, 1.136506, 3.7099638]\n",
            "Epoch :399\n",
            "d_loss : [0.29197994 0.50097656]\n",
            "g_loss : [6.306159, 1.138835, 6.3050203]\n",
            "Epoch :400\n",
            "d_loss : [0.29275495 0.5029297 ]\n",
            "g_loss : [4.482837, 1.1285329, 4.4817085]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "PSNR: 13.808197754318975\n",
            "SSIM: 0.7335207876036319\n",
            "Epoch :401\n",
            "d_loss : [0.29211816 0.4814453 ]\n",
            "g_loss : [5.218499, 1.1642889, 5.2173347]\n",
            "Epoch :402\n",
            "d_loss : [0.29075527 0.5       ]\n",
            "g_loss : [6.681939, 1.154084, 6.680785]\n",
            "Epoch :403\n",
            "d_loss : [0.2924909 0.5048828]\n",
            "g_loss : [3.9728427, 1.127702, 3.971715]\n",
            "Epoch :404\n",
            "d_loss : [0.2879662  0.51953125]\n",
            "g_loss : [6.3087616, 1.1454229, 6.307616]\n",
            "Epoch :405\n",
            "d_loss : [0.29223943 0.50683594]\n",
            "g_loss : [6.1227384, 1.1432179, 6.121595]\n",
            "Epoch :406\n",
            "d_loss : [0.2845615 0.5214844]\n",
            "g_loss : [4.6194177, 1.1177161, 4.6183]\n",
            "Epoch :407\n",
            "d_loss : [0.29432887 0.51660156]\n",
            "g_loss : [5.967022, 1.133769, 5.965888]\n",
            "Epoch :408\n",
            "d_loss : [0.28930423 0.50390625]\n",
            "g_loss : [4.00648, 1.1318748, 4.005348]\n",
            "Epoch :409\n",
            "d_loss : [0.29031104 0.5048828 ]\n",
            "g_loss : [3.4714894, 1.136143, 3.4703534]\n",
            "Epoch :410\n",
            "d_loss : [0.28922617 0.49121094]\n",
            "g_loss : [5.482087, 1.1358056, 5.4809513]\n",
            "Epoch :411\n",
            "d_loss : [0.2931068 0.5058594]\n",
            "g_loss : [6.2222953, 1.1572748, 6.221138]\n",
            "Epoch :412\n",
            "d_loss : [0.29069784 0.5019531 ]\n",
            "g_loss : [3.655999, 1.1208826, 3.6548781]\n",
            "Epoch :413\n",
            "d_loss : [0.29310146 0.49023438]\n",
            "g_loss : [5.9685674, 1.133553, 5.967434]\n",
            "Epoch :414\n",
            "d_loss : [0.29212767 0.5       ]\n",
            "g_loss : [6.9202266, 1.146898, 6.91908]\n",
            "Epoch :415\n",
            "d_loss : [0.28793025 0.5253906 ]\n",
            "g_loss : [7.0337143, 1.1455178, 7.032569]\n",
            "Epoch :416\n",
            "d_loss : [0.28971264 0.5263672 ]\n",
            "g_loss : [4.0400825, 1.1034613, 4.038979]\n",
            "Epoch :417\n",
            "d_loss : [0.2895085 0.5048828]\n",
            "g_loss : [3.8728435, 1.1242816, 3.8717191]\n",
            "Epoch :418\n",
            "d_loss : [0.29144144 0.5029297 ]\n",
            "g_loss : [5.4214334, 1.1365097, 5.420297]\n",
            "Epoch :419\n",
            "d_loss : [0.29082748 0.5019531 ]\n",
            "g_loss : [4.4930844, 1.1212679, 4.4919634]\n",
            "Epoch :420\n",
            "d_loss : [0.29488963 0.5048828 ]\n",
            "g_loss : [5.2372847, 1.1205072, 5.236164]\n",
            "Epoch :421\n",
            "d_loss : [0.2882582 0.5      ]\n",
            "g_loss : [7.3146057, 1.149703, 7.313456]\n",
            "Epoch :422\n",
            "d_loss : [0.28991878 0.49902344]\n",
            "g_loss : [5.1904454, 1.1467633, 5.1892986]\n",
            "Epoch :423\n",
            "d_loss : [0.2953537  0.48828125]\n",
            "g_loss : [4.164011, 1.1523058, 4.1628585]\n",
            "Epoch :424\n",
            "d_loss : [0.28729337 0.5058594 ]\n",
            "g_loss : [4.134253, 1.1415348, 4.1331115]\n",
            "Epoch :425\n",
            "d_loss : [0.2920376  0.50097656]\n",
            "g_loss : [4.0573325, 1.1388651, 4.056194]\n",
            "Epoch :426\n",
            "d_loss : [0.2919225  0.50878906]\n",
            "g_loss : [3.2002294, 1.1518209, 3.1990776]\n",
            "Epoch :427\n",
            "d_loss : [0.29368645 0.4951172 ]\n",
            "g_loss : [3.786818, 1.1471955, 3.7856708]\n",
            "Epoch :428\n",
            "d_loss : [0.2900902 0.5019531]\n",
            "g_loss : [3.43602, 1.1207018, 3.434899]\n",
            "Epoch :429\n",
            "d_loss : [0.28983986 0.50878906]\n",
            "g_loss : [4.7056417, 1.1263077, 4.7045155]\n",
            "Epoch :430\n",
            "d_loss : [0.29212648 0.4892578 ]\n",
            "g_loss : [3.877722, 1.1378562, 3.876584]\n",
            "Epoch :431\n",
            "d_loss : [0.29252416 0.4970703 ]\n",
            "g_loss : [3.8998575, 1.141966, 3.8987155]\n",
            "Epoch :432\n",
            "d_loss : [0.29351962 0.48632812]\n",
            "g_loss : [3.8602176, 1.1329174, 3.8590846]\n",
            "Epoch :433\n",
            "d_loss : [0.29388243 0.5058594 ]\n",
            "g_loss : [7.0093927, 1.0911305, 7.0083017]\n",
            "Epoch :434\n",
            "d_loss : [0.29643103 0.49316406]\n",
            "g_loss : [4.9748645, 1.1302516, 4.9737344]\n",
            "Epoch :435\n",
            "d_loss : [0.2938158 0.4892578]\n",
            "g_loss : [2.823017, 1.1354578, 2.8218815]\n",
            "Epoch :436\n",
            "d_loss : [0.2869115 0.515625 ]\n",
            "g_loss : [4.9871626, 1.127183, 4.9860353]\n",
            "Epoch :437\n",
            "d_loss : [0.2918417 0.5107422]\n",
            "g_loss : [3.8508146, 1.1546092, 3.84966]\n",
            "Epoch :438\n",
            "d_loss : [0.2920586 0.4921875]\n",
            "g_loss : [2.7693274, 1.1165459, 2.768211]\n",
            "Epoch :439\n",
            "d_loss : [0.29043406 0.49121094]\n",
            "g_loss : [5.690471, 1.1402081, 5.689331]\n",
            "Epoch :440\n",
            "d_loss : [0.29593408 0.48632812]\n",
            "g_loss : [4.148983, 1.1315278, 4.1478515]\n",
            "Epoch :441\n",
            "d_loss : [0.29150304 0.4970703 ]\n",
            "g_loss : [3.89185, 1.1249216, 3.8907251]\n",
            "Epoch :442\n",
            "d_loss : [0.2913563 0.5058594]\n",
            "g_loss : [5.907852, 1.1551185, 5.9066973]\n",
            "Epoch :443\n",
            "d_loss : [0.29459453 0.50878906]\n",
            "g_loss : [4.6933293, 1.1392095, 4.69219]\n",
            "Epoch :444\n",
            "d_loss : [0.29260692 0.49023438]\n",
            "g_loss : [2.9307632, 1.1329464, 2.9296303]\n",
            "Epoch :445\n",
            "d_loss : [0.29130745 0.47265625]\n",
            "g_loss : [4.23971, 1.1367055, 4.238573]\n",
            "Epoch :446\n",
            "d_loss : [0.28905544 0.50683594]\n",
            "g_loss : [4.7426186, 1.1373748, 4.7414813]\n",
            "Epoch :447\n",
            "d_loss : [0.28879833 0.49316406]\n",
            "g_loss : [6.1749115, 1.095536, 6.1738157]\n",
            "Epoch :448\n",
            "d_loss : [0.29148823 0.49902344]\n",
            "g_loss : [4.463652, 1.1479782, 4.4625044]\n",
            "Epoch :449\n",
            "d_loss : [0.29492474 0.48242188]\n",
            "g_loss : [2.4752977, 1.1550113, 2.4741428]\n",
            "Epoch :450\n",
            "d_loss : [0.29318392 0.5107422 ]\n",
            "g_loss : [4.8861437, 1.1258605, 4.885018]\n",
            "Epoch :451\n",
            "d_loss : [0.2948122 0.5058594]\n",
            "g_loss : [5.38293, 1.1338797, 5.381796]\n",
            "Epoch :452\n",
            "d_loss : [0.28982645 0.49609375]\n",
            "g_loss : [5.1531105, 1.1377094, 5.151973]\n",
            "Epoch :453\n",
            "d_loss : [0.29196274 0.5058594 ]\n",
            "g_loss : [2.621895, 1.1375307, 2.6207576]\n",
            "Epoch :454\n",
            "d_loss : [0.293818  0.5019531]\n",
            "g_loss : [2.8451898, 1.1203579, 2.8440695]\n",
            "Epoch :455\n",
            "d_loss : [0.29225242 0.4970703 ]\n",
            "g_loss : [4.2083325, 1.1438358, 4.2071886]\n",
            "Epoch :456\n",
            "d_loss : [0.28566307 0.5048828 ]\n",
            "g_loss : [2.3007646, 1.1486957, 2.2996159]\n",
            "Epoch :457\n",
            "d_loss : [0.29007518 0.5029297 ]\n",
            "g_loss : [2.590766, 1.1370882, 2.589629]\n",
            "Epoch :458\n",
            "d_loss : [0.2864716 0.5126953]\n",
            "g_loss : [2.4535794, 1.1514508, 2.4524279]\n",
            "Epoch :459\n",
            "d_loss : [0.2888073 0.5029297]\n",
            "g_loss : [3.6147826, 1.1312761, 3.6136513]\n",
            "Epoch :460\n",
            "d_loss : [0.29148585 0.5019531 ]\n",
            "g_loss : [3.1444082, 1.1093917, 3.1432989]\n",
            "Epoch :461\n",
            "d_loss : [0.29460564 0.49316406]\n",
            "g_loss : [5.0227995, 1.152787, 5.0216465]\n",
            "Epoch :462\n",
            "d_loss : [0.28882307 0.50097656]\n",
            "g_loss : [2.874382, 1.1516566, 2.8732305]\n",
            "Epoch :463\n",
            "d_loss : [0.2912534 0.5078125]\n",
            "g_loss : [5.9696827, 1.1233164, 5.9685593]\n",
            "Epoch :464\n",
            "d_loss : [0.29112133 0.5029297 ]\n",
            "g_loss : [7.173891, 1.1477855, 7.1727433]\n",
            "Epoch :465\n",
            "d_loss : [0.2903755  0.49804688]\n",
            "g_loss : [3.254406, 1.1213074, 3.2532847]\n",
            "Epoch :466\n",
            "d_loss : [0.29083925 0.49316406]\n",
            "g_loss : [5.080433, 1.137957, 5.079295]\n",
            "Epoch :467\n",
            "d_loss : [0.29043797 0.5136719 ]\n",
            "g_loss : [3.5388796, 1.136064, 3.5377436]\n",
            "Epoch :468\n",
            "d_loss : [0.28957212 0.51464844]\n",
            "g_loss : [4.0051804, 1.1312332, 4.0040493]\n",
            "Epoch :469\n",
            "d_loss : [0.2917844  0.49121094]\n",
            "g_loss : [6.3094125, 1.1576738, 6.3082547]\n",
            "Epoch :470\n",
            "d_loss : [0.29433388 0.5029297 ]\n",
            "g_loss : [5.276532, 1.1309776, 5.275401]\n",
            "Epoch :471\n",
            "d_loss : [0.28890976 0.5234375 ]\n",
            "g_loss : [3.8087413, 1.145608, 3.8075957]\n",
            "Epoch :472\n",
            "d_loss : [0.2936143  0.49609375]\n",
            "g_loss : [3.7660468, 1.119294, 3.7649274]\n",
            "Epoch :473\n",
            "d_loss : [0.28754222 0.5107422 ]\n",
            "g_loss : [6.228551, 1.1400003, 6.227411]\n",
            "Epoch :474\n",
            "d_loss : [0.29256424 0.50097656]\n",
            "g_loss : [3.691122, 1.1352981, 3.6899867]\n",
            "Epoch :475\n",
            "d_loss : [0.2946752 0.4951172]\n",
            "g_loss : [4.022102, 1.131448, 4.0209703]\n",
            "Epoch :476\n",
            "d_loss : [0.29128376 0.5078125 ]\n",
            "g_loss : [4.4144835, 1.1336176, 4.41335]\n",
            "Epoch :477\n",
            "d_loss : [0.2864555  0.50097656]\n",
            "g_loss : [3.7432976, 1.1337717, 3.742164]\n",
            "Epoch :478\n",
            "d_loss : [0.29111302 0.5185547 ]\n",
            "g_loss : [2.789055, 1.141679, 2.7879133]\n",
            "Epoch :479\n",
            "d_loss : [0.29402488 0.4970703 ]\n",
            "g_loss : [3.3469548, 1.1113727, 3.3458436]\n",
            "Epoch :480\n",
            "d_loss : [0.28963435 0.5097656 ]\n",
            "g_loss : [5.4820995, 1.1345575, 5.480965]\n",
            "Epoch :481\n",
            "d_loss : [0.29169053 0.48046875]\n",
            "g_loss : [2.5928493, 1.1462762, 2.591703]\n",
            "Epoch :482\n",
            "d_loss : [0.28994167 0.49609375]\n",
            "g_loss : [5.0086837, 1.1414318, 5.007542]\n",
            "Epoch :483\n",
            "d_loss : [0.28844348 0.5019531 ]\n",
            "g_loss : [2.888918, 1.1377423, 2.8877802]\n",
            "Epoch :484\n",
            "d_loss : [0.2897961 0.5029297]\n",
            "g_loss : [5.77358, 1.1446828, 5.772435]\n",
            "Epoch :485\n",
            "d_loss : [0.28791088 0.49902344]\n",
            "g_loss : [2.7752151, 1.146378, 2.7740688]\n",
            "Epoch :486\n",
            "d_loss : [0.2896542 0.5      ]\n",
            "g_loss : [4.3867764, 1.1381669, 4.385638]\n",
            "Epoch :487\n",
            "d_loss : [0.29464757 0.4951172 ]\n",
            "g_loss : [2.2494395, 1.1571493, 2.2482824]\n",
            "Epoch :488\n",
            "d_loss : [0.2872527  0.49902344]\n",
            "g_loss : [3.1589966, 1.1268694, 3.1578698]\n",
            "Epoch :489\n",
            "d_loss : [0.29373482 0.5097656 ]\n",
            "g_loss : [4.389244, 1.1342604, 4.3881097]\n",
            "Epoch :490\n",
            "d_loss : [0.29067624 0.49316406]\n",
            "g_loss : [5.281277, 1.1600754, 5.280117]\n",
            "Epoch :491\n",
            "d_loss : [0.2928725 0.5      ]\n",
            "g_loss : [4.727053, 1.133656, 4.7259197]\n",
            "Epoch :492\n",
            "d_loss : [0.28985   0.5097656]\n",
            "g_loss : [3.4099538, 1.1412807, 3.4088125]\n",
            "Epoch :493\n",
            "d_loss : [0.29178372 0.50878906]\n",
            "g_loss : [5.2981224, 1.1407235, 5.296982]\n",
            "Epoch :494\n",
            "d_loss : [0.29178765 0.5097656 ]\n",
            "g_loss : [4.5754313, 1.1336219, 4.574298]\n",
            "Epoch :495\n",
            "d_loss : [0.2917861 0.4921875]\n",
            "g_loss : [5.538859, 1.1126146, 5.5377464]\n",
            "Epoch :496\n",
            "d_loss : [0.29246894 0.49902344]\n",
            "g_loss : [5.4786377, 1.1568508, 5.477481]\n",
            "Epoch :497\n",
            "d_loss : [0.29216093 0.49121094]\n",
            "g_loss : [5.832597, 1.0889406, 5.8315077]\n",
            "Epoch :498\n",
            "d_loss : [0.2943619 0.4951172]\n",
            "g_loss : [3.7386007, 1.1211417, 3.7374797]\n",
            "Epoch :499\n",
            "d_loss : [0.2932992  0.48339844]\n",
            "g_loss : [2.681469, 1.1364172, 2.6803327]\n",
            "Epoch :500\n",
            "d_loss : [0.29290196 0.4873047 ]\n",
            "g_loss : [4.7314296, 1.1352177, 4.730294]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "PSNR: 23.250661002049352\n",
            "SSIM: 0.7551098780442858\n",
            "Epoch :501\n",
            "d_loss : [0.29060936 0.4892578 ]\n",
            "g_loss : [5.577711, 1.1522884, 5.5765586]\n",
            "Epoch :502\n",
            "d_loss : [0.29272085 0.5048828 ]\n",
            "g_loss : [3.1903427, 1.1081367, 3.1892345]\n",
            "Epoch :503\n",
            "d_loss : [0.29030913 0.5019531 ]\n",
            "g_loss : [3.086351, 1.1250408, 3.0852258]\n",
            "Epoch :504\n",
            "d_loss : [0.28943267 0.5019531 ]\n",
            "g_loss : [7.490705, 1.1010172, 7.489604]\n",
            "Epoch :505\n",
            "d_loss : [0.2902798  0.49804688]\n",
            "g_loss : [4.4508615, 1.0924909, 4.449769]\n",
            "Epoch :506\n",
            "d_loss : [0.2843806  0.50097656]\n",
            "g_loss : [3.5075462, 1.0990262, 3.506447]\n",
            "Epoch :507\n",
            "d_loss : [0.28870392 0.49414062]\n",
            "g_loss : [4.801218, 1.1263156, 4.8000917]\n",
            "Epoch :508\n",
            "d_loss : [0.2880109  0.51464844]\n",
            "g_loss : [4.1827054, 1.1377227, 4.1815677]\n",
            "Epoch :509\n",
            "d_loss : [0.29449242 0.50390625]\n",
            "g_loss : [4.129472, 1.1184801, 4.128353]\n",
            "Epoch :510\n",
            "d_loss : [0.29514268 0.4892578 ]\n",
            "g_loss : [4.107769, 1.0928155, 4.106676]\n",
            "Epoch :511\n",
            "d_loss : [0.28872466 0.5136719 ]\n",
            "g_loss : [5.0868244, 1.1146255, 5.0857096]\n",
            "Epoch :512\n",
            "d_loss : [0.29242617 0.5048828 ]\n",
            "g_loss : [4.6289954, 1.136795, 4.6278586]\n",
            "Epoch :513\n",
            "d_loss : [0.2937743  0.50097656]\n",
            "g_loss : [3.942902, 1.1108084, 3.9417913]\n",
            "Epoch :514\n",
            "d_loss : [0.28926033 0.5048828 ]\n",
            "g_loss : [3.2139995, 1.1473297, 3.2128522]\n",
            "Epoch :515\n",
            "d_loss : [0.29194835 0.5097656 ]\n",
            "g_loss : [4.152919, 1.1168846, 4.151802]\n",
            "Epoch :516\n",
            "d_loss : [0.29238516 0.5       ]\n",
            "g_loss : [3.4621444, 1.1147708, 3.4610295]\n",
            "Epoch :517\n",
            "d_loss : [0.29048127 0.48632812]\n",
            "g_loss : [4.2192316, 1.122453, 4.218109]\n",
            "Epoch :518\n",
            "d_loss : [0.29129955 0.5078125 ]\n",
            "g_loss : [5.127971, 1.1288011, 5.1268425]\n",
            "Epoch :519\n",
            "d_loss : [0.29591614 0.49316406]\n",
            "g_loss : [3.7128165, 1.1368973, 3.7116797]\n",
            "Epoch :520\n",
            "d_loss : [0.28412342 0.5097656 ]\n",
            "g_loss : [3.985147, 1.1206229, 3.9840264]\n",
            "Epoch :521\n",
            "d_loss : [0.2920331 0.5058594]\n",
            "g_loss : [3.8294106, 1.1353805, 3.8282752]\n",
            "Epoch :522\n",
            "d_loss : [0.29110384 0.5058594 ]\n",
            "g_loss : [2.4667943, 1.1678246, 2.4656265]\n",
            "Epoch :523\n",
            "d_loss : [0.2897703  0.49609375]\n",
            "g_loss : [5.738224, 1.1458302, 5.737078]\n",
            "Epoch :524\n",
            "d_loss : [0.289724 0.5     ]\n",
            "g_loss : [3.0352542, 1.1374695, 3.0341167]\n",
            "Epoch :525\n",
            "d_loss : [0.28737372 0.50097656]\n",
            "g_loss : [4.797276, 1.097108, 4.796179]\n",
            "Epoch :526\n",
            "d_loss : [0.29119807 0.49902344]\n",
            "g_loss : [4.8936315, 1.1215589, 4.89251]\n",
            "Epoch :527\n",
            "d_loss : [0.29463625 0.5       ]\n",
            "g_loss : [2.5419824, 1.1422553, 2.5408401]\n",
            "Epoch :528\n",
            "d_loss : [0.29057294 0.4921875 ]\n",
            "g_loss : [1.922531, 1.1571426, 1.9213738]\n",
            "Epoch :529\n",
            "d_loss : [0.2902637 0.5029297]\n",
            "g_loss : [5.3893766, 1.1305106, 5.388246]\n",
            "Epoch :530\n",
            "d_loss : [0.29090893 0.50878906]\n",
            "g_loss : [3.1669848, 1.1352929, 3.1658494]\n",
            "Epoch :531\n",
            "d_loss : [0.2901744 0.4951172]\n",
            "g_loss : [4.396798, 1.103173, 4.3956947]\n",
            "Epoch :532\n",
            "d_loss : [0.28980005 0.5136719 ]\n",
            "g_loss : [3.779192, 1.1041429, 3.7780879]\n",
            "Epoch :533\n",
            "d_loss : [0.29148957 0.50390625]\n",
            "g_loss : [5.2157984, 1.1121073, 5.2146864]\n",
            "Epoch :534\n",
            "d_loss : [0.29121935 0.5048828 ]\n",
            "g_loss : [3.0012634, 1.1616092, 3.0001018]\n",
            "Epoch :535\n",
            "d_loss : [0.29271895 0.49902344]\n",
            "g_loss : [4.5695767, 1.130451, 4.568446]\n",
            "Epoch :536\n",
            "d_loss : [0.289701   0.50390625]\n",
            "g_loss : [4.681333, 1.1173756, 4.680216]\n",
            "Epoch :537\n",
            "d_loss : [0.2923089 0.5136719]\n",
            "g_loss : [4.4738884, 1.1119981, 4.4727764]\n",
            "Epoch :538\n",
            "d_loss : [0.2936574  0.51171875]\n",
            "g_loss : [2.8170795, 1.1381085, 2.8159413]\n",
            "Epoch :539\n",
            "d_loss : [0.29104692 0.49902344]\n",
            "g_loss : [3.3503141, 1.1357601, 3.3491783]\n",
            "Epoch :540\n",
            "d_loss : [0.29300654 0.5136719 ]\n",
            "g_loss : [3.444645, 1.140768, 3.443504]\n",
            "Epoch :541\n",
            "d_loss : [0.29182753 0.5019531 ]\n",
            "g_loss : [3.240715, 1.1238959, 3.2395911]\n",
            "Epoch :542\n",
            "d_loss : [0.2910527 0.5078125]\n",
            "g_loss : [3.594367, 1.1362715, 3.5932307]\n",
            "Epoch :543\n",
            "d_loss : [0.28501955 0.50683594]\n",
            "g_loss : [3.6167183, 1.1095355, 3.6156087]\n",
            "Epoch :544\n",
            "d_loss : [0.29601753 0.5019531 ]\n",
            "g_loss : [3.3078995, 1.1339947, 3.3067656]\n",
            "Epoch :545\n",
            "d_loss : [0.29308146 0.49609375]\n",
            "g_loss : [3.1812038, 1.1138201, 3.18009]\n",
            "Epoch :546\n",
            "d_loss : [0.29260623 0.4814453 ]\n",
            "g_loss : [2.9875896, 1.1328883, 2.9864566]\n",
            "Epoch :547\n",
            "d_loss : [0.2919399  0.50390625]\n",
            "g_loss : [4.160424, 1.1253155, 4.159299]\n",
            "Epoch :548\n",
            "d_loss : [0.2943201  0.48828125]\n",
            "g_loss : [4.2206774, 1.1411349, 4.2195363]\n",
            "Epoch :549\n",
            "d_loss : [0.29120907 0.49902344]\n",
            "g_loss : [3.3680336, 1.123097, 3.3669105]\n",
            "Epoch :550\n",
            "d_loss : [0.29477417 0.49609375]\n",
            "g_loss : [3.175646, 1.1146792, 3.1745315]\n",
            "Epoch :551\n",
            "d_loss : [0.2876401 0.4951172]\n",
            "g_loss : [3.9192493, 1.1483021, 3.918101]\n",
            "Epoch :552\n",
            "d_loss : [0.29080504 0.48632812]\n",
            "g_loss : [4.3677063, 1.0961715, 4.36661]\n",
            "Epoch :553\n",
            "d_loss : [0.29059052 0.52246094]\n",
            "g_loss : [2.2231507, 1.1416037, 2.2220092]\n",
            "Epoch :554\n",
            "d_loss : [0.29336545 0.5107422 ]\n",
            "g_loss : [5.466024, 1.1468441, 5.464877]\n",
            "Epoch :555\n",
            "d_loss : [0.2942503  0.49609375]\n",
            "g_loss : [3.9687264, 1.1322081, 3.9675941]\n",
            "Epoch :556\n",
            "d_loss : [0.2923122 0.5175781]\n",
            "g_loss : [3.8997304, 1.1378725, 3.8985925]\n",
            "Epoch :557\n",
            "d_loss : [0.29184118 0.5107422 ]\n",
            "g_loss : [4.291044, 1.1405783, 4.2899036]\n",
            "Epoch :558\n",
            "d_loss : [0.2895731  0.50097656]\n",
            "g_loss : [4.717844, 1.1557802, 4.716688]\n",
            "Epoch :559\n",
            "d_loss : [0.29446584 0.48828125]\n",
            "g_loss : [4.2608337, 1.0993817, 4.259734]\n",
            "Epoch :560\n",
            "d_loss : [0.2845786  0.49609375]\n",
            "g_loss : [2.601941, 1.1368098, 2.6008043]\n",
            "Epoch :561\n",
            "d_loss : [0.2933386 0.4951172]\n",
            "g_loss : [3.8751166, 1.129354, 3.8739872]\n",
            "Epoch :562\n",
            "d_loss : [0.291341  0.5019531]\n",
            "g_loss : [3.8745852, 1.113851, 3.8734713]\n",
            "Epoch :563\n",
            "d_loss : [0.29368064 0.5048828 ]\n",
            "g_loss : [2.0309165, 1.1441064, 2.0297723]\n",
            "Epoch :564\n",
            "d_loss : [0.2922579  0.47753906]\n",
            "g_loss : [2.5438635, 1.1300818, 2.5427334]\n",
            "Epoch :565\n",
            "d_loss : [0.2943989 0.5078125]\n",
            "g_loss : [3.3862226, 1.1266688, 3.3850958]\n",
            "Epoch :566\n",
            "d_loss : [0.28871644 0.50878906]\n",
            "g_loss : [4.378169, 1.1026287, 4.3770666]\n",
            "Epoch :567\n",
            "d_loss : [0.29023406 0.5       ]\n",
            "g_loss : [4.9421473, 1.1490339, 4.940998]\n",
            "Epoch :568\n",
            "d_loss : [0.2880078  0.49902344]\n",
            "g_loss : [3.4221127, 1.1493375, 3.4209633]\n",
            "Epoch :569\n",
            "d_loss : [0.2930672 0.5      ]\n",
            "g_loss : [3.3315709, 1.1154919, 3.3304553]\n",
            "Epoch :570\n",
            "d_loss : [0.28934908 0.49414062]\n",
            "g_loss : [2.6271708, 1.1203802, 2.6260505]\n",
            "Epoch :571\n",
            "d_loss : [0.29091674 0.49414062]\n",
            "g_loss : [3.6664522, 1.1337972, 3.6653185]\n",
            "Epoch :572\n",
            "d_loss : [0.29140735 0.4892578 ]\n",
            "g_loss : [5.5497274, 1.1431278, 5.5485845]\n",
            "Epoch :573\n",
            "d_loss : [0.29037863 0.50390625]\n",
            "g_loss : [3.2218962, 1.1206665, 3.2207756]\n",
            "Epoch :574\n",
            "d_loss : [0.2904592  0.50390625]\n",
            "g_loss : [4.442827, 1.1289034, 4.4416986]\n",
            "Epoch :575\n",
            "d_loss : [0.29077595 0.49902344]\n",
            "g_loss : [4.424522, 1.1315603, 4.4233904]\n",
            "Epoch :576\n",
            "d_loss : [0.29069436 0.50683594]\n",
            "g_loss : [4.4968753, 1.151103, 4.495724]\n",
            "Epoch :577\n",
            "d_loss : [0.2888565 0.5097656]\n",
            "g_loss : [4.3103676, 1.1079637, 4.3092594]\n",
            "Epoch :578\n",
            "d_loss : [0.2905745  0.50390625]\n",
            "g_loss : [2.888323, 1.125636, 2.8871975]\n",
            "Epoch :579\n",
            "d_loss : [0.29024112 0.49609375]\n",
            "g_loss : [3.2958915, 1.1416792, 3.2947497]\n",
            "Epoch :580\n",
            "d_loss : [0.29056144 0.5097656 ]\n",
            "g_loss : [1.6490337, 1.1390121, 1.6478946]\n",
            "Epoch :581\n",
            "d_loss : [0.2934    0.5029297]\n",
            "g_loss : [3.1996217, 1.113549, 3.198508]\n",
            "Epoch :582\n",
            "d_loss : [0.2917728 0.5107422]\n",
            "g_loss : [4.023235, 1.1159556, 4.022119]\n",
            "Epoch :583\n",
            "d_loss : [0.2955814 0.4921875]\n",
            "g_loss : [4.4456267, 1.129466, 4.444497]\n",
            "Epoch :584\n",
            "d_loss : [0.29238415 0.49902344]\n",
            "g_loss : [4.2969894, 1.1217109, 4.295868]\n",
            "Epoch :585\n",
            "d_loss : [0.29326314 0.48242188]\n",
            "g_loss : [3.7927501, 1.1108137, 3.7916393]\n",
            "Epoch :586\n",
            "d_loss : [0.29384723 0.49414062]\n",
            "g_loss : [5.1756935, 1.1503246, 5.1745434]\n",
            "Epoch :587\n",
            "d_loss : [0.29192385 0.5078125 ]\n",
            "g_loss : [3.9642727, 1.154001, 3.9631188]\n",
            "Epoch :588\n",
            "d_loss : [0.29151952 0.5019531 ]\n",
            "g_loss : [3.5762727, 1.1108303, 3.575162]\n",
            "Epoch :589\n",
            "d_loss : [0.29135543 0.4951172 ]\n",
            "g_loss : [2.5007095, 1.1334448, 2.499576]\n",
            "Epoch :590\n",
            "d_loss : [0.29229614 0.50097656]\n",
            "g_loss : [3.6215105, 1.118708, 3.6203918]\n",
            "Epoch :591\n",
            "d_loss : [0.29163045 0.50683594]\n",
            "g_loss : [3.3418012, 1.1041698, 3.340697]\n",
            "Epoch :592\n",
            "d_loss : [0.28702304 0.515625  ]\n",
            "g_loss : [3.8452253, 1.1286316, 3.8440967]\n",
            "Epoch :593\n",
            "d_loss : [0.28995168 0.49121094]\n",
            "g_loss : [2.65017, 1.1213301, 2.6490488]\n",
            "Epoch :594\n",
            "d_loss : [0.29489198 0.49609375]\n",
            "g_loss : [2.1687727, 1.1297461, 2.167643]\n",
            "Epoch :595\n",
            "d_loss : [0.29150128 0.5048828 ]\n",
            "g_loss : [5.549678, 1.1840706, 5.548494]\n",
            "Epoch :596\n",
            "d_loss : [0.29053926 0.49609375]\n",
            "g_loss : [4.332641, 1.1660851, 4.3314753]\n",
            "Epoch :597\n",
            "d_loss : [0.28913468 0.5058594 ]\n",
            "g_loss : [4.3872533, 1.1064366, 4.386147]\n",
            "Epoch :598\n",
            "d_loss : [0.29163098 0.51171875]\n",
            "g_loss : [3.8788893, 1.1374322, 3.8777518]\n",
            "Epoch :599\n",
            "d_loss : [0.29120478 0.5       ]\n",
            "g_loss : [2.6036432, 1.1470591, 2.6024961]\n",
            "Epoch :600\n",
            "d_loss : [0.2908455  0.50683594]\n",
            "g_loss : [4.1141677, 1.1132998, 4.1130543]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "PSNR: 15.063342475551451\n",
            "SSIM: 0.7589682738947238\n",
            "Epoch :601\n",
            "d_loss : [0.29201502 0.50390625]\n",
            "g_loss : [2.4794903, 1.1316533, 2.4783587]\n",
            "Epoch :602\n",
            "d_loss : [0.28924882 0.4921875 ]\n",
            "g_loss : [3.4171388, 1.1094689, 3.4160295]\n",
            "Epoch :603\n",
            "d_loss : [0.29367453 0.51171875]\n",
            "g_loss : [4.900921, 1.1430151, 4.899778]\n",
            "Epoch :604\n",
            "d_loss : [0.29284635 0.49414062]\n",
            "g_loss : [1.7168965, 1.1229653, 1.7157736]\n",
            "Epoch :605\n",
            "d_loss : [0.28886485 0.5078125 ]\n",
            "g_loss : [4.064486, 1.1537285, 4.063332]\n",
            "Epoch :606\n",
            "d_loss : [0.29305047 0.49414062]\n",
            "g_loss : [4.1946144, 1.1261795, 4.193488]\n",
            "Epoch :607\n",
            "d_loss : [0.2963866  0.49609375]\n",
            "g_loss : [3.6571784, 1.1308317, 3.6560476]\n",
            "Epoch :608\n",
            "d_loss : [0.2912601  0.50878906]\n",
            "g_loss : [3.5494483, 1.1208477, 3.5483274]\n",
            "Epoch :609\n",
            "d_loss : [0.2925499  0.50878906]\n",
            "g_loss : [3.1997414, 1.1138487, 3.1986275]\n",
            "Epoch :610\n",
            "d_loss : [0.29182452 0.4970703 ]\n",
            "g_loss : [2.671751, 1.119623, 2.6706314]\n",
            "Epoch :611\n",
            "d_loss : [0.2928106  0.50878906]\n",
            "g_loss : [3.742563, 1.1431495, 3.7414198]\n",
            "Epoch :612\n",
            "d_loss : [0.28831777 0.4970703 ]\n",
            "g_loss : [2.832153, 1.1252079, 2.831028]\n",
            "Epoch :613\n",
            "d_loss : [0.2885819 0.5048828]\n",
            "g_loss : [2.7958403, 1.1286327, 2.7947116]\n",
            "Epoch :614\n",
            "d_loss : [0.28511196 0.48632812]\n",
            "g_loss : [2.3769863, 1.1410389, 2.3758452]\n",
            "Epoch :615\n",
            "d_loss : [0.2925671 0.5058594]\n",
            "g_loss : [2.4684472, 1.1129425, 2.4673343]\n",
            "Epoch :616\n",
            "d_loss : [0.29252276 0.49121094]\n",
            "g_loss : [2.2204044, 1.1349974, 2.2192693]\n",
            "Epoch :617\n",
            "d_loss : [0.28870708 0.5029297 ]\n",
            "g_loss : [3.1379373, 1.0954835, 3.1368418]\n",
            "Epoch :618\n",
            "d_loss : [0.29141364 0.49023438]\n",
            "g_loss : [5.1708035, 1.1559114, 5.1696477]\n",
            "Epoch :619\n",
            "d_loss : [0.2908853  0.49902344]\n",
            "g_loss : [3.5105648, 1.1576009, 3.5094073]\n",
            "Epoch :620\n",
            "d_loss : [0.29252446 0.48828125]\n",
            "g_loss : [3.656531, 1.1128852, 3.6554182]\n",
            "Epoch :621\n",
            "d_loss : [0.29108098 0.5019531 ]\n",
            "g_loss : [4.3251114, 1.1111724, 4.3240004]\n",
            "Epoch :622\n",
            "d_loss : [0.2921776 0.4794922]\n",
            "g_loss : [3.0455637, 1.1263516, 3.0444374]\n",
            "Epoch :623\n",
            "d_loss : [0.2880444  0.50683594]\n",
            "g_loss : [3.1446514, 1.1257052, 3.1435256]\n",
            "Epoch :624\n",
            "d_loss : [0.2906205 0.4921875]\n",
            "g_loss : [2.3057334, 1.1328558, 2.3046005]\n",
            "Epoch :625\n",
            "d_loss : [0.28852993 0.5078125 ]\n",
            "g_loss : [2.3544471, 1.1259091, 2.3533213]\n",
            "Epoch :626\n",
            "d_loss : [0.29190668 0.4951172 ]\n",
            "g_loss : [2.9457762, 1.1389081, 2.9446373]\n",
            "Epoch :627\n",
            "d_loss : [0.29100674 0.5078125 ]\n",
            "g_loss : [3.5150936, 1.1264526, 3.513967]\n",
            "Epoch :628\n",
            "d_loss : [0.292245  0.4951172]\n",
            "g_loss : [3.6046872, 1.1442964, 3.6035428]\n",
            "Epoch :629\n",
            "d_loss : [0.29300773 0.51660156]\n",
            "g_loss : [2.9211996, 1.1460931, 2.9200535]\n",
            "Epoch :630\n",
            "d_loss : [0.28385976 0.50390625]\n",
            "g_loss : [2.352201, 1.1387177, 2.3510623]\n",
            "Epoch :631\n",
            "d_loss : [0.28705508 0.50390625]\n",
            "g_loss : [3.0834808, 1.1301408, 3.0823507]\n",
            "Epoch :632\n",
            "d_loss : [0.2911355  0.50683594]\n",
            "g_loss : [3.8191626, 1.1039994, 3.8180585]\n",
            "Epoch :633\n",
            "d_loss : [0.2939437 0.5029297]\n",
            "g_loss : [2.3932567, 1.1065276, 2.3921502]\n",
            "Epoch :634\n",
            "d_loss : [0.28978032 0.50878906]\n",
            "g_loss : [2.4006898, 1.1241622, 2.3995657]\n",
            "Epoch :635\n",
            "d_loss : [0.28528184 0.4970703 ]\n",
            "g_loss : [3.5550747, 1.1285644, 3.553946]\n",
            "Epoch :636\n",
            "d_loss : [0.29014885 0.50683594]\n",
            "g_loss : [2.9638903, 1.1272473, 2.962763]\n",
            "Epoch :637\n",
            "d_loss : [0.2892324  0.50683594]\n",
            "g_loss : [2.2517169, 1.143653, 2.2505732]\n",
            "Epoch :638\n",
            "d_loss : [0.28932583 0.50878906]\n",
            "g_loss : [2.8099248, 1.1189868, 2.808806]\n",
            "Epoch :639\n",
            "d_loss : [0.29376748 0.49804688]\n",
            "g_loss : [2.6082623, 1.1122129, 2.60715]\n",
            "Epoch :640\n",
            "d_loss : [0.29113537 0.5078125 ]\n",
            "g_loss : [3.1577854, 1.133352, 3.156652]\n",
            "Epoch :641\n",
            "d_loss : [0.29261133 0.49316406]\n",
            "g_loss : [2.731777, 1.1227785, 2.7306542]\n",
            "Epoch :642\n",
            "d_loss : [0.2948393 0.5      ]\n",
            "g_loss : [3.493942, 1.167241, 3.4927747]\n",
            "Epoch :643\n",
            "d_loss : [0.28978446 0.50683594]\n",
            "g_loss : [3.7352161, 1.1391011, 3.734077]\n",
            "Epoch :644\n",
            "d_loss : [0.29187647 0.5048828 ]\n",
            "g_loss : [3.0650842, 1.1069704, 3.0639772]\n",
            "Epoch :645\n",
            "d_loss : [0.2922176  0.50097656]\n",
            "g_loss : [3.753272, 1.1238506, 3.7521482]\n",
            "Epoch :646\n",
            "d_loss : [0.2951221  0.50878906]\n",
            "g_loss : [3.1530204, 1.1206151, 3.1518998]\n",
            "Epoch :647\n",
            "d_loss : [0.2886132 0.5048828]\n",
            "g_loss : [3.5667448, 1.1157146, 3.565629]\n",
            "Epoch :648\n",
            "d_loss : [0.290685   0.51464844]\n",
            "g_loss : [2.6722987, 1.1289936, 2.6711698]\n",
            "Epoch :649\n",
            "d_loss : [0.29108918 0.5126953 ]\n",
            "g_loss : [2.7084732, 1.1390231, 2.7073343]\n",
            "Epoch :650\n",
            "d_loss : [0.29344177 0.49902344]\n",
            "g_loss : [2.5785477, 1.1412349, 2.5774064]\n",
            "Epoch :651\n",
            "d_loss : [0.28916383 0.5048828 ]\n",
            "g_loss : [3.1627421, 1.1272848, 3.161615]\n",
            "Epoch :652\n",
            "d_loss : [0.29326445 0.5048828 ]\n",
            "g_loss : [3.0635457, 1.1145892, 3.062431]\n",
            "Epoch :653\n",
            "d_loss : [0.29214382 0.49414062]\n",
            "g_loss : [2.091345, 1.1498135, 2.0901952]\n",
            "Epoch :654\n",
            "d_loss : [0.29372036 0.49804688]\n",
            "g_loss : [2.268033, 1.1263133, 2.2669067]\n",
            "Epoch :655\n",
            "d_loss : [0.29168993 0.50390625]\n",
            "g_loss : [1.9415716, 1.1593586, 1.9404123]\n",
            "Epoch :656\n",
            "d_loss : [0.29081905 0.5019531 ]\n",
            "g_loss : [3.1313756, 1.1204331, 3.1302552]\n",
            "Epoch :657\n",
            "d_loss : [0.29126114 0.5126953 ]\n",
            "g_loss : [4.122747, 1.0847898, 4.121662]\n",
            "Epoch :658\n",
            "d_loss : [0.2921387 0.5097656]\n",
            "g_loss : [3.80442, 1.1372813, 3.8032827]\n",
            "Epoch :659\n",
            "d_loss : [0.29412016 0.48242188]\n",
            "g_loss : [3.0787587, 1.136794, 3.077622]\n",
            "Epoch :660\n",
            "d_loss : [0.29366428 0.49414062]\n",
            "g_loss : [3.4253495, 1.1260822, 3.4242234]\n",
            "Epoch :661\n",
            "d_loss : [0.29378933 0.50683594]\n",
            "g_loss : [3.2264533, 1.1524601, 3.2253008]\n",
            "Epoch :662\n",
            "d_loss : [0.29246634 0.5078125 ]\n",
            "g_loss : [3.3806527, 1.1383941, 3.3795142]\n",
            "Epoch :663\n",
            "d_loss : [0.29181767 0.49902344]\n",
            "g_loss : [1.3091005, 1.1561685, 1.3079443]\n",
            "Epoch :664\n",
            "d_loss : [0.29441336 0.49902344]\n",
            "g_loss : [2.761204, 1.1056038, 2.7600985]\n",
            "Epoch :665\n",
            "d_loss : [0.2908008 0.5097656]\n",
            "g_loss : [2.439438, 1.1226013, 2.4383154]\n",
            "Epoch :666\n",
            "d_loss : [0.29166824 0.4951172 ]\n",
            "g_loss : [3.7103674, 1.0753989, 3.709292]\n",
            "Epoch :667\n",
            "d_loss : [0.28909242 0.50097656]\n",
            "g_loss : [2.9286354, 1.132324, 2.927503]\n",
            "Epoch :668\n",
            "d_loss : [0.29116774 0.5078125 ]\n",
            "g_loss : [1.9113839, 1.1422036, 1.9102417]\n",
            "Epoch :669\n",
            "d_loss : [0.2865829 0.4951172]\n",
            "g_loss : [3.5394464, 1.1511219, 3.5382953]\n",
            "Epoch :670\n",
            "d_loss : [0.2907595  0.50390625]\n",
            "g_loss : [3.069869, 1.1378143, 3.0687313]\n",
            "Epoch :671\n",
            "d_loss : [0.2894014 0.5058594]\n",
            "g_loss : [2.9248428, 1.1439478, 2.923699]\n",
            "Epoch :672\n",
            "d_loss : [0.29159087 0.5058594 ]\n",
            "g_loss : [2.5715516, 1.1189375, 2.5704327]\n",
            "Epoch :673\n",
            "d_loss : [0.28911102 0.5078125 ]\n",
            "g_loss : [3.0419292, 1.1178215, 3.0408115]\n",
            "Epoch :674\n",
            "d_loss : [0.29449868 0.4892578 ]\n",
            "g_loss : [2.7238655, 1.142062, 2.7227235]\n",
            "Epoch :675\n",
            "d_loss : [0.2927336 0.4970703]\n",
            "g_loss : [2.1831565, 1.1243362, 2.182032]\n",
            "Epoch :676\n",
            "d_loss : [0.29094592 0.49414062]\n",
            "g_loss : [3.0429733, 1.1391486, 3.041834]\n",
            "Epoch :677\n",
            "d_loss : [0.29458094 0.5097656 ]\n",
            "g_loss : [3.024217, 1.1220365, 3.023095]\n",
            "Epoch :678\n",
            "d_loss : [0.29653186 0.49316406]\n",
            "g_loss : [3.759098, 1.1533287, 3.7579448]\n",
            "Epoch :679\n",
            "d_loss : [0.29207948 0.49414062]\n",
            "g_loss : [3.217172, 1.139916, 3.216032]\n",
            "Epoch :680\n",
            "d_loss : [0.29431954 0.49414062]\n",
            "g_loss : [2.8640506, 1.1201408, 2.8629305]\n",
            "Epoch :681\n",
            "d_loss : [0.2947443 0.4970703]\n",
            "g_loss : [3.2392333, 1.1195346, 3.2381136]\n",
            "Epoch :682\n",
            "d_loss : [0.29106104 0.49316406]\n",
            "g_loss : [1.6060622, 1.1477525, 1.6049144]\n",
            "Epoch :683\n",
            "d_loss : [0.29341808 0.50097656]\n",
            "g_loss : [2.018583, 1.1421826, 2.0174408]\n",
            "Epoch :684\n",
            "d_loss : [0.2899378  0.51171875]\n",
            "g_loss : [1.852594, 1.1557214, 1.8514383]\n",
            "Epoch :685\n",
            "d_loss : [0.28787994 0.5126953 ]\n",
            "g_loss : [4.2561455, 1.1365798, 4.2550087]\n",
            "Epoch :686\n",
            "d_loss : [0.29344502 0.51464844]\n",
            "g_loss : [2.916667, 1.1085343, 2.9155583]\n",
            "Epoch :687\n",
            "d_loss : [0.29403841 0.50097656]\n",
            "g_loss : [3.7678869, 1.1233656, 3.7667634]\n",
            "Epoch :688\n",
            "d_loss : [0.29196072 0.49609375]\n",
            "g_loss : [3.3152242, 1.1353498, 3.3140888]\n",
            "Epoch :689\n",
            "d_loss : [0.2916561  0.51464844]\n",
            "g_loss : [2.6228423, 1.1461867, 2.6216962]\n",
            "Epoch :690\n",
            "d_loss : [0.29186666 0.5058594 ]\n",
            "g_loss : [3.198093, 1.105346, 3.1969876]\n",
            "Epoch :691\n",
            "d_loss : [0.2906944 0.4951172]\n",
            "g_loss : [1.5590335, 1.1387106, 1.5578948]\n",
            "Epoch :692\n",
            "d_loss : [0.29082748 0.4951172 ]\n",
            "g_loss : [4.1957736, 1.1313748, 4.194642]\n",
            "Epoch :693\n",
            "d_loss : [0.28954867 0.5126953 ]\n",
            "g_loss : [4.309292, 1.1453271, 4.3081465]\n",
            "Epoch :694\n",
            "d_loss : [0.2909426 0.4970703]\n",
            "g_loss : [3.1614056, 1.1046246, 3.160301]\n",
            "Epoch :695\n",
            "d_loss : [0.29091185 0.5126953 ]\n",
            "g_loss : [2.6276524, 1.1331834, 2.6265192]\n",
            "Epoch :696\n",
            "d_loss : [0.29328835 0.49609375]\n",
            "g_loss : [3.4440477, 1.1126349, 3.442935]\n",
            "Epoch :697\n",
            "d_loss : [0.29189083 0.4873047 ]\n",
            "g_loss : [2.3583977, 1.0949869, 2.3573027]\n",
            "Epoch :698\n",
            "d_loss : [0.2901912  0.50097656]\n",
            "g_loss : [3.2867732, 1.1126264, 3.2856605]\n",
            "Epoch :699\n",
            "d_loss : [0.29298908 0.49804688]\n",
            "g_loss : [2.3396733, 1.1295991, 2.3385437]\n",
            "Epoch :700\n",
            "d_loss : [0.28571087 0.5136719 ]\n",
            "g_loss : [3.580624, 1.1464164, 3.5794778]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "PSNR: 19.116478063167563\n",
            "SSIM: 0.6895238994603613\n",
            "Epoch :701\n",
            "d_loss : [0.29025495 0.50390625]\n",
            "g_loss : [2.6287594, 1.1119164, 2.6276474]\n",
            "Epoch :702\n",
            "d_loss : [0.28979394 0.5097656 ]\n",
            "g_loss : [2.2069898, 1.1225786, 2.2058673]\n",
            "Epoch :703\n",
            "d_loss : [0.2923541 0.5058594]\n",
            "g_loss : [3.2149258, 1.1357193, 3.21379]\n",
            "Epoch :704\n",
            "d_loss : [0.29081997 0.4892578 ]\n",
            "g_loss : [4.0169344, 1.123142, 4.0158114]\n",
            "Epoch :705\n",
            "d_loss : [0.28813726 0.5       ]\n",
            "g_loss : [3.771055, 1.1027753, 3.7699523]\n",
            "Epoch :706\n",
            "d_loss : [0.2933884 0.4951172]\n",
            "g_loss : [3.2649317, 1.1174214, 3.2638142]\n",
            "Epoch :707\n",
            "d_loss : [0.2911236  0.50878906]\n",
            "g_loss : [2.3565986, 1.1484041, 2.3554502]\n",
            "Epoch :708\n",
            "d_loss : [0.29079968 0.51171875]\n",
            "g_loss : [1.8555074, 1.1595609, 1.8543478]\n",
            "Epoch :709\n",
            "d_loss : [0.2929125  0.49023438]\n",
            "g_loss : [2.6437051, 1.1485224, 2.6425567]\n",
            "Epoch :710\n",
            "d_loss : [0.28925872 0.50683594]\n",
            "g_loss : [3.668319, 1.1417246, 3.6671772]\n",
            "Epoch :711\n",
            "d_loss : [0.29190522 0.5048828 ]\n",
            "g_loss : [2.6188538, 1.132688, 2.617721]\n",
            "Epoch :712\n",
            "d_loss : [0.2934824 0.4970703]\n",
            "g_loss : [1.8434119, 1.1403735, 1.8422716]\n",
            "Epoch :713\n",
            "d_loss : [0.29325184 0.49902344]\n",
            "g_loss : [3.5653121, 1.0845188, 3.5642276]\n",
            "Epoch :714\n",
            "d_loss : [0.2885799 0.5019531]\n",
            "g_loss : [3.9596405, 1.1444325, 3.958496]\n",
            "Epoch :715\n",
            "d_loss : [0.29387993 0.49804688]\n",
            "g_loss : [2.519694, 1.1171651, 2.5185769]\n",
            "Epoch :716\n",
            "d_loss : [0.2889186  0.50390625]\n",
            "g_loss : [3.5207307, 1.1379281, 3.5195928]\n",
            "Epoch :717\n",
            "d_loss : [0.2905594  0.49902344]\n",
            "g_loss : [2.9456198, 1.1012533, 2.9445186]\n",
            "Epoch :718\n",
            "d_loss : [0.29529217 0.5029297 ]\n",
            "g_loss : [2.6197586, 1.1123422, 2.6186461]\n",
            "Epoch :719\n",
            "d_loss : [0.29306436 0.49121094]\n",
            "g_loss : [2.6016088, 1.0954645, 2.6005132]\n",
            "Epoch :720\n",
            "d_loss : [0.29557377 0.5234375 ]\n",
            "g_loss : [2.1144974, 1.1312284, 2.1133661]\n",
            "Epoch :721\n",
            "d_loss : [0.2929073 0.5048828]\n",
            "g_loss : [3.353674, 1.1156998, 3.3525581]\n",
            "Epoch :722\n",
            "d_loss : [0.292988   0.49609375]\n",
            "g_loss : [2.69542, 1.1150547, 2.694305]\n",
            "Epoch :723\n",
            "d_loss : [0.28731024 0.48828125]\n",
            "g_loss : [2.8855443, 1.1269317, 2.8844173]\n",
            "Epoch :724\n",
            "d_loss : [0.28835446 0.52246094]\n",
            "g_loss : [2.1056628, 1.1048951, 2.104558]\n",
            "Epoch :725\n",
            "d_loss : [0.2938558  0.48828125]\n",
            "g_loss : [3.053399, 1.1277978, 3.0522714]\n",
            "Epoch :726\n",
            "d_loss : [0.29249597 0.5058594 ]\n",
            "g_loss : [2.6007574, 1.1183476, 2.599639]\n",
            "Epoch :727\n",
            "d_loss : [0.29407245 0.49609375]\n",
            "g_loss : [1.6523536, 1.1467407, 1.6512069]\n",
            "Epoch :728\n",
            "d_loss : [0.29395932 0.49902344]\n",
            "g_loss : [1.5368558, 1.1212428, 1.5357345]\n",
            "Epoch :729\n",
            "d_loss : [0.28984475 0.5058594 ]\n",
            "g_loss : [2.8754625, 1.1162114, 2.8743463]\n",
            "Epoch :730\n",
            "d_loss : [0.29060793 0.51171875]\n",
            "g_loss : [4.0799623, 1.1323131, 4.07883]\n",
            "Epoch :731\n",
            "d_loss : [0.29214025 0.48339844]\n",
            "g_loss : [2.3375444, 1.1053634, 2.3364391]\n",
            "Epoch :732\n",
            "d_loss : [0.29188094 0.4970703 ]\n",
            "g_loss : [2.628906, 1.1341758, 2.6277719]\n",
            "Epoch :733\n",
            "d_loss : [0.29620114 0.4970703 ]\n",
            "g_loss : [3.5034664, 1.1229459, 3.5023434]\n",
            "Epoch :734\n",
            "d_loss : [0.2896682 0.5058594]\n",
            "g_loss : [2.4701536, 1.1341596, 2.4690194]\n",
            "Epoch :735\n",
            "d_loss : [0.29203427 0.5097656 ]\n",
            "g_loss : [2.6442807, 1.1393738, 2.6431413]\n",
            "Epoch :736\n",
            "d_loss : [0.289994   0.51171875]\n",
            "g_loss : [1.8930938, 1.124622, 1.8919692]\n",
            "Epoch :737\n",
            "d_loss : [0.29285288 0.49902344]\n",
            "g_loss : [5.1018877, 1.1453125, 5.1007423]\n",
            "Epoch :738\n",
            "d_loss : [0.2892236 0.5      ]\n",
            "g_loss : [2.0512145, 1.1193162, 2.050095]\n",
            "Epoch :739\n",
            "d_loss : [0.29143333 0.49121094]\n",
            "g_loss : [2.3828385, 1.1268249, 2.3817117]\n",
            "Epoch :740\n",
            "d_loss : [0.2932089 0.4892578]\n",
            "g_loss : [2.8114061, 1.1047528, 2.8103013]\n",
            "Epoch :741\n",
            "d_loss : [0.29169482 0.49609375]\n",
            "g_loss : [2.7482803, 1.125099, 2.7471552]\n",
            "Epoch :742\n",
            "d_loss : [0.29444695 0.49414062]\n",
            "g_loss : [2.171217, 1.1347207, 2.1700823]\n",
            "Epoch :743\n",
            "d_loss : [0.29228514 0.49414062]\n",
            "g_loss : [2.1336155, 1.1052959, 2.1325102]\n",
            "Epoch :744\n",
            "d_loss : [0.28808573 0.5048828 ]\n",
            "g_loss : [3.309397, 1.1362731, 3.3082607]\n",
            "Epoch :745\n",
            "d_loss : [0.29170814 0.5029297 ]\n",
            "g_loss : [2.5863137, 1.1402336, 2.5851736]\n",
            "Epoch :746\n",
            "d_loss : [0.29111063 0.50683594]\n",
            "g_loss : [2.7815957, 1.1355644, 2.7804601]\n",
            "Epoch :747\n",
            "d_loss : [0.29231387 0.5       ]\n",
            "g_loss : [2.180121, 1.1216108, 2.1789994]\n",
            "Epoch :748\n",
            "d_loss : [0.29201907 0.5       ]\n",
            "g_loss : [2.4833891, 1.118927, 2.4822702]\n",
            "Epoch :749\n",
            "d_loss : [0.29090774 0.49902344]\n",
            "g_loss : [1.7548581, 1.1316402, 1.7537265]\n",
            "Epoch :750\n",
            "d_loss : [0.29070222 0.49804688]\n",
            "g_loss : [4.282127, 1.1492238, 4.2809777]\n",
            "Epoch :751\n",
            "d_loss : [0.29279765 0.49804688]\n",
            "g_loss : [2.094755, 1.1388514, 2.093616]\n",
            "Epoch :752\n",
            "d_loss : [0.29118663 0.49414062]\n",
            "g_loss : [2.3899713, 1.1237488, 2.3888476]\n",
            "Epoch :753\n",
            "d_loss : [0.29106683 0.49316406]\n",
            "g_loss : [3.3358037, 1.1170366, 3.3346868]\n",
            "Epoch :754\n",
            "d_loss : [0.2912136 0.4970703]\n",
            "g_loss : [2.5509675, 1.1173838, 2.54985]\n",
            "Epoch :755\n",
            "d_loss : [0.29466593 0.49804688]\n",
            "g_loss : [1.7007153, 1.1207793, 1.6995945]\n",
            "Epoch :756\n",
            "d_loss : [0.29569483 0.50683594]\n",
            "g_loss : [2.5434566, 1.1240526, 2.5423324]\n",
            "Epoch :757\n",
            "d_loss : [0.2936882  0.49609375]\n",
            "g_loss : [1.7852857, 1.1521146, 1.7841336]\n",
            "Epoch :758\n",
            "d_loss : [0.28815198 0.50390625]\n",
            "g_loss : [2.1544774, 1.1420345, 2.1533353]\n",
            "Epoch :759\n",
            "d_loss : [0.29044598 0.5078125 ]\n",
            "g_loss : [2.5461147, 1.129651, 2.544985]\n",
            "Epoch :760\n",
            "d_loss : [0.29337752 0.4873047 ]\n",
            "g_loss : [2.8412232, 1.12637, 2.840097]\n",
            "Epoch :761\n",
            "d_loss : [0.29475665 0.49609375]\n",
            "g_loss : [3.005269, 1.1110287, 3.004158]\n",
            "Epoch :762\n",
            "d_loss : [0.28905705 0.5       ]\n",
            "g_loss : [2.1001828, 1.1259389, 2.0990567]\n",
            "Epoch :763\n",
            "d_loss : [0.29210773 0.50878906]\n",
            "g_loss : [1.5571113, 1.1449362, 1.5559664]\n",
            "Epoch :764\n",
            "d_loss : [0.2935233 0.4951172]\n",
            "g_loss : [1.9966079, 1.1331093, 1.9954748]\n",
            "Epoch :765\n",
            "d_loss : [0.2888912 0.5078125]\n",
            "g_loss : [2.778994, 1.0936422, 2.7779005]\n",
            "Epoch :766\n",
            "d_loss : [0.2942531  0.48046875]\n",
            "g_loss : [2.7882183, 1.1466544, 2.7870717]\n",
            "Epoch :767\n",
            "d_loss : [0.29276758 0.49804688]\n",
            "g_loss : [2.3310912, 1.1274592, 2.3299637]\n",
            "Epoch :768\n",
            "d_loss : [0.29008892 0.5097656 ]\n",
            "g_loss : [2.781908, 1.0823522, 2.7808256]\n",
            "Epoch :769\n",
            "d_loss : [0.28861952 0.5058594 ]\n",
            "g_loss : [1.4365934, 1.1506103, 1.4354428]\n",
            "Epoch :770\n",
            "d_loss : [0.29303062 0.515625  ]\n",
            "g_loss : [1.6822883, 1.1497827, 1.6811385]\n",
            "Epoch :771\n",
            "d_loss : [0.2919913  0.49609375]\n",
            "g_loss : [2.6780806, 1.0897182, 2.6769907]\n",
            "Epoch :772\n",
            "d_loss : [0.287698   0.49902344]\n",
            "g_loss : [2.9298408, 1.1393728, 2.9287014]\n",
            "Epoch :773\n",
            "d_loss : [0.29150108 0.5097656 ]\n",
            "g_loss : [2.3940144, 1.1238084, 2.3928905]\n",
            "Epoch :774\n",
            "d_loss : [0.29166976 0.5136719 ]\n",
            "g_loss : [2.3636272, 1.1465634, 2.3624806]\n",
            "Epoch :775\n",
            "d_loss : [0.28830743 0.4921875 ]\n",
            "g_loss : [3.3421383, 1.1549842, 3.3409834]\n",
            "Epoch :776\n",
            "d_loss : [0.29291967 0.5107422 ]\n",
            "g_loss : [2.096703, 1.1215911, 2.0955815]\n",
            "Epoch :777\n",
            "d_loss : [0.2909082  0.50390625]\n",
            "g_loss : [2.2227724, 1.1223791, 2.22165]\n",
            "Epoch :778\n",
            "d_loss : [0.28952685 0.515625  ]\n",
            "g_loss : [1.4555091, 1.1555779, 1.4543535]\n",
            "Epoch :779\n",
            "d_loss : [0.29161704 0.50097656]\n",
            "g_loss : [1.4997218, 1.1137152, 1.498608]\n",
            "Epoch :780\n",
            "d_loss : [0.28788012 0.5058594 ]\n",
            "g_loss : [2.1608596, 1.1233982, 2.1597362]\n",
            "Epoch :781\n",
            "d_loss : [0.28783268 0.5185547 ]\n",
            "g_loss : [2.1170478, 1.1282549, 2.1159196]\n",
            "Epoch :782\n",
            "d_loss : [0.2905663 0.5019531]\n",
            "g_loss : [1.9259697, 1.1163465, 1.9248533]\n",
            "Epoch :783\n",
            "d_loss : [0.28682095 0.515625  ]\n",
            "g_loss : [4.0593762, 1.1561899, 4.05822]\n",
            "Epoch :784\n",
            "d_loss : [0.29422954 0.5048828 ]\n",
            "g_loss : [2.3494709, 1.1418743, 2.348329]\n",
            "Epoch :785\n",
            "d_loss : [0.29203767 0.5       ]\n",
            "g_loss : [2.0978923, 1.1292362, 2.0967631]\n",
            "Epoch :786\n",
            "d_loss : [0.29500166 0.49804688]\n",
            "g_loss : [2.260433, 1.1436955, 2.2592893]\n",
            "Epoch :787\n",
            "d_loss : [0.28923526 0.50878906]\n",
            "g_loss : [2.482019, 1.1339839, 2.480885]\n",
            "Epoch :788\n",
            "d_loss : [0.290038   0.51171875]\n",
            "g_loss : [2.8226566, 1.1172032, 2.8215394]\n",
            "Epoch :789\n",
            "d_loss : [0.29078722 0.5029297 ]\n",
            "g_loss : [2.6458738, 1.1216913, 2.644752]\n",
            "Epoch :790\n",
            "d_loss : [0.2893548 0.5097656]\n",
            "g_loss : [2.8432515, 1.1144812, 2.842137]\n",
            "Epoch :791\n",
            "d_loss : [0.28864533 0.48632812]\n",
            "g_loss : [1.9384198, 1.1241823, 1.9372957]\n",
            "Epoch :792\n",
            "d_loss : [0.2900214 0.5048828]\n",
            "g_loss : [2.5887363, 1.1361146, 2.5876002]\n",
            "Epoch :793\n",
            "d_loss : [0.2957225  0.49609375]\n",
            "g_loss : [3.0297043, 1.1051525, 3.0285993]\n",
            "Epoch :794\n",
            "d_loss : [0.29406178 0.50683594]\n",
            "g_loss : [2.2012691, 1.1166863, 2.2001524]\n",
            "Epoch :795\n",
            "d_loss : [0.2902318  0.49316406]\n",
            "g_loss : [2.3229585, 1.1152271, 2.3218431]\n",
            "Epoch :796\n",
            "d_loss : [0.2905959 0.5097656]\n",
            "g_loss : [3.0074174, 1.1385667, 3.006279]\n",
            "Epoch :797\n",
            "d_loss : [0.28982025 0.49804688]\n",
            "g_loss : [1.4408461, 1.1274142, 1.4397187]\n",
            "Epoch :798\n",
            "d_loss : [0.29355448 0.5107422 ]\n",
            "g_loss : [2.2634614, 1.0846622, 2.2623768]\n",
            "Epoch :799\n",
            "d_loss : [0.28968573 0.515625  ]\n",
            "g_loss : [1.7631415, 1.155991, 1.7619855]\n",
            "Epoch :800\n",
            "d_loss : [0.29286364 0.5097656 ]\n",
            "g_loss : [3.0933037, 1.1455826, 3.092158]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "PSNR: 19.615552627595715\n",
            "SSIM: 0.9067732879483432\n",
            "Epoch :801\n",
            "d_loss : [0.29179135 0.49414062]\n",
            "g_loss : [2.2000918, 1.0990566, 2.1989927]\n",
            "Epoch :802\n",
            "d_loss : [0.29363304 0.49902344]\n",
            "g_loss : [2.7936745, 1.1534368, 2.792521]\n",
            "Epoch :803\n",
            "d_loss : [0.29280072 0.49804688]\n",
            "g_loss : [1.9996209, 1.1502085, 1.9984707]\n",
            "Epoch :804\n",
            "d_loss : [0.29173154 0.49609375]\n",
            "g_loss : [2.7972858, 1.1393594, 2.7961464]\n",
            "Epoch :805\n",
            "d_loss : [0.29352814 0.5029297 ]\n",
            "g_loss : [2.8048441, 1.0954654, 2.8037486]\n",
            "Epoch :806\n",
            "d_loss : [0.29162616 0.5048828 ]\n",
            "g_loss : [1.7586116, 1.1294688, 1.757482]\n",
            "Epoch :807\n",
            "d_loss : [0.28978986 0.50878906]\n",
            "g_loss : [2.457357, 1.1063229, 2.4562507]\n",
            "Epoch :808\n",
            "d_loss : [0.2911457  0.50390625]\n",
            "g_loss : [3.022936, 1.1318108, 3.0218043]\n",
            "Epoch :809\n",
            "d_loss : [0.29077315 0.50097656]\n",
            "g_loss : [3.2505102, 1.1213167, 3.249389]\n",
            "Epoch :810\n",
            "d_loss : [0.291581  0.5058594]\n",
            "g_loss : [1.8054998, 1.1310537, 1.8043687]\n",
            "Epoch :811\n",
            "d_loss : [0.28983602 0.50878906]\n",
            "g_loss : [1.1999286, 1.1392355, 1.1987894]\n",
            "Epoch :812\n",
            "d_loss : [0.29001075 0.4970703 ]\n",
            "g_loss : [1.8132162, 1.1009135, 1.8121153]\n",
            "Epoch :813\n",
            "d_loss : [0.29141426 0.5097656 ]\n",
            "g_loss : [1.5334347, 1.1424999, 1.5322922]\n",
            "Epoch :814\n",
            "d_loss : [0.29191422 0.5058594 ]\n",
            "g_loss : [2.576323, 1.1305819, 2.5751925]\n",
            "Epoch :815\n",
            "d_loss : [0.28995478 0.5029297 ]\n",
            "g_loss : [2.2250867, 1.1309857, 2.2239556]\n",
            "Epoch :816\n",
            "d_loss : [0.2926783  0.49121094]\n",
            "g_loss : [1.2625314, 1.1186244, 1.2614127]\n",
            "Epoch :817\n",
            "d_loss : [0.29156697 0.49316406]\n",
            "g_loss : [2.7043107, 1.1150842, 2.7031956]\n",
            "Epoch :818\n",
            "d_loss : [0.29081005 0.49316406]\n",
            "g_loss : [1.6016295, 1.0864675, 1.600543]\n",
            "Epoch :819\n",
            "d_loss : [0.29200965 0.50390625]\n",
            "g_loss : [1.8956739, 1.1124889, 1.8945614]\n",
            "Epoch :820\n",
            "d_loss : [0.2939223  0.49414062]\n",
            "g_loss : [1.6138141, 1.1550382, 1.6126591]\n",
            "Epoch :821\n",
            "d_loss : [0.28460482 0.4892578 ]\n",
            "g_loss : [2.055611, 1.133249, 2.0544777]\n",
            "Epoch :822\n",
            "d_loss : [0.29348975 0.49804688]\n",
            "g_loss : [1.8660767, 1.1362782, 1.8649404]\n",
            "Epoch :823\n",
            "d_loss : [0.2912609  0.50097656]\n",
            "g_loss : [2.2757206, 1.111394, 2.274609]\n",
            "Epoch :824\n",
            "d_loss : [0.2902918  0.49316406]\n",
            "g_loss : [1.8139813, 1.1347914, 1.8128465]\n",
            "Epoch :825\n",
            "d_loss : [0.28970152 0.4970703 ]\n",
            "g_loss : [2.2079074, 1.1434498, 2.206764]\n",
            "Epoch :826\n",
            "d_loss : [0.29399642 0.50878906]\n",
            "g_loss : [2.0144222, 1.1407381, 2.0132813]\n",
            "Epoch :827\n",
            "d_loss : [0.28827253 0.49609375]\n",
            "g_loss : [3.319714, 1.1282718, 3.3185859]\n",
            "Epoch :828\n",
            "d_loss : [0.2932117  0.49023438]\n",
            "g_loss : [2.2645857, 1.1191392, 2.2634666]\n",
            "Epoch :829\n",
            "d_loss : [0.288136  0.5058594]\n",
            "g_loss : [2.2898982, 1.102536, 2.2887957]\n",
            "Epoch :830\n",
            "d_loss : [0.29041046 0.5029297 ]\n",
            "g_loss : [1.9241376, 1.120195, 1.9230174]\n",
            "Epoch :831\n",
            "d_loss : [0.2925196  0.50097656]\n",
            "g_loss : [2.6409843, 1.1076126, 2.6398766]\n",
            "Epoch :832\n",
            "d_loss : [0.2955487 0.4921875]\n",
            "g_loss : [1.7780862, 1.1061858, 1.77698]\n",
            "Epoch :833\n",
            "d_loss : [0.29275852 0.5078125 ]\n",
            "g_loss : [2.1127868, 1.0982265, 2.1116886]\n",
            "Epoch :834\n",
            "d_loss : [0.28790426 0.5029297 ]\n",
            "g_loss : [1.87111, 1.1234248, 1.8699865]\n",
            "Epoch :835\n",
            "d_loss : [0.29206902 0.5078125 ]\n",
            "g_loss : [1.8037343, 1.1405704, 1.8025937]\n",
            "Epoch :836\n",
            "d_loss : [0.28896472 0.5185547 ]\n",
            "g_loss : [1.9981986, 1.1184702, 1.9970802]\n",
            "Epoch :837\n",
            "d_loss : [0.27951294 0.5078125 ]\n",
            "g_loss : [2.586219, 1.1437145, 2.5850754]\n",
            "Epoch :838\n",
            "d_loss : [0.29180896 0.5019531 ]\n",
            "g_loss : [2.013678, 1.1343732, 2.0125437]\n",
            "Epoch :839\n",
            "d_loss : [0.2930631 0.4814453]\n",
            "g_loss : [1.8515365, 1.1000873, 1.8504364]\n",
            "Epoch :840\n",
            "d_loss : [0.29272133 0.49121094]\n",
            "g_loss : [1.4684716, 1.1208714, 1.4673507]\n",
            "Epoch :841\n",
            "d_loss : [0.2883249 0.5048828]\n",
            "g_loss : [2.9261906, 1.1536052, 2.925037]\n",
            "Epoch :842\n",
            "d_loss : [0.28849652 0.4892578 ]\n",
            "g_loss : [1.808995, 1.1236576, 1.8078713]\n",
            "Epoch :843\n",
            "d_loss : [0.2906366 0.4970703]\n",
            "g_loss : [2.7430344, 1.1475091, 2.7418869]\n",
            "Epoch :844\n",
            "d_loss : [0.28796083 0.5       ]\n",
            "g_loss : [1.7174736, 1.1544135, 1.7163192]\n",
            "Epoch :845\n",
            "d_loss : [0.28887576 0.5107422 ]\n",
            "g_loss : [2.9073281, 1.1097178, 2.9062185]\n",
            "Epoch :846\n",
            "d_loss : [0.29081127 0.50878906]\n",
            "g_loss : [2.1211169, 1.1326926, 2.1199841]\n",
            "Epoch :847\n",
            "d_loss : [0.29238185 0.48339844]\n",
            "g_loss : [1.33805, 1.1386658, 1.3369113]\n",
            "Epoch :848\n",
            "d_loss : [0.29394734 0.48242188]\n",
            "g_loss : [2.127045, 1.115598, 2.1259294]\n",
            "Epoch :849\n",
            "d_loss : [0.29375893 0.5029297 ]\n",
            "g_loss : [1.8308731, 1.1131009, 1.8297601]\n",
            "Epoch :850\n",
            "d_loss : [0.28993696 0.49804688]\n",
            "g_loss : [2.3233693, 1.1342186, 2.322235]\n",
            "Epoch :851\n",
            "d_loss : [0.2913681  0.49609375]\n",
            "g_loss : [2.6361063, 1.1299734, 2.6349764]\n",
            "Epoch :852\n",
            "d_loss : [0.2898805  0.50097656]\n",
            "g_loss : [2.2435706, 1.1417961, 2.2424288]\n",
            "Epoch :853\n",
            "d_loss : [0.28359234 0.5136719 ]\n",
            "g_loss : [1.8028141, 1.1221006, 1.801692]\n",
            "Epoch :854\n",
            "d_loss : [0.29142225 0.49316406]\n",
            "g_loss : [2.5668013, 1.1389258, 2.5656624]\n",
            "Epoch :855\n",
            "d_loss : [0.29147667 0.49414062]\n",
            "g_loss : [1.9168133, 1.0959303, 1.9157174]\n",
            "Epoch :856\n",
            "d_loss : [0.29397815 0.4892578 ]\n",
            "g_loss : [1.6522301, 1.1120216, 1.6511182]\n",
            "Epoch :857\n",
            "d_loss : [0.29129362 0.4873047 ]\n",
            "g_loss : [2.6881223, 1.122791, 2.6869996]\n",
            "Epoch :858\n",
            "d_loss : [0.29399687 0.5019531 ]\n",
            "g_loss : [2.3817065, 1.1260827, 2.3805804]\n",
            "Epoch :859\n",
            "d_loss : [0.29367137 0.4765625 ]\n",
            "g_loss : [2.6553438, 1.081691, 2.654262]\n",
            "Epoch :860\n",
            "d_loss : [0.28731525 0.5136719 ]\n",
            "g_loss : [2.2182045, 1.1233203, 2.217081]\n",
            "Epoch :861\n",
            "d_loss : [0.2912747 0.5058594]\n",
            "g_loss : [1.7531735, 1.1221828, 1.7520512]\n",
            "Epoch :862\n",
            "d_loss : [0.29124808 0.50683594]\n",
            "g_loss : [0.9709373, 1.1477838, 0.9697895]\n",
            "Epoch :863\n",
            "d_loss : [0.29265514 0.4794922 ]\n",
            "g_loss : [1.0818524, 1.1409695, 1.0807115]\n",
            "Epoch :864\n",
            "d_loss : [0.28672242 0.5       ]\n",
            "g_loss : [2.343419, 1.1166623, 2.3423023]\n",
            "Epoch :865\n",
            "d_loss : [0.2902363  0.49121094]\n",
            "g_loss : [2.386852, 1.1256394, 2.3857265]\n",
            "Epoch :866\n",
            "d_loss : [0.2927069 0.4951172]\n",
            "g_loss : [2.234789, 1.1415571, 2.2336473]\n",
            "Epoch :867\n",
            "d_loss : [0.29300484 0.5       ]\n",
            "g_loss : [2.404656, 1.121452, 2.4035344]\n",
            "Epoch :868\n",
            "d_loss : [0.29127973 0.50878906]\n",
            "g_loss : [2.4071774, 1.1377687, 2.4060397]\n",
            "Epoch :869\n",
            "d_loss : [0.29009074 0.5097656 ]\n",
            "g_loss : [1.7072041, 1.1427974, 1.7060614]\n",
            "Epoch :870\n",
            "d_loss : [0.2892086 0.5126953]\n",
            "g_loss : [2.1672916, 1.1277883, 2.166164]\n",
            "Epoch :871\n",
            "d_loss : [0.29182974 0.51171875]\n",
            "g_loss : [1.5253346, 1.1190815, 1.5242155]\n",
            "Epoch :872\n",
            "d_loss : [0.28505856 0.49121094]\n",
            "g_loss : [2.884009, 1.1476971, 2.8828611]\n",
            "Epoch :873\n",
            "d_loss : [0.29190174 0.49609375]\n",
            "g_loss : [2.0960288, 1.1182055, 2.0949106]\n",
            "Epoch :874\n",
            "d_loss : [0.29208314 0.5058594 ]\n",
            "g_loss : [1.5318861, 1.1312954, 1.5307548]\n",
            "Epoch :875\n",
            "d_loss : [0.28981394 0.49023438]\n",
            "g_loss : [2.5272348, 1.142736, 2.526092]\n",
            "Epoch :876\n",
            "d_loss : [0.2936657  0.48535156]\n",
            "g_loss : [1.6386398, 1.1260599, 1.6375138]\n",
            "Epoch :877\n",
            "d_loss : [0.29034424 0.5107422 ]\n",
            "g_loss : [2.020556, 1.1325927, 2.0194235]\n",
            "Epoch :878\n",
            "d_loss : [0.2943907  0.49804688]\n",
            "g_loss : [2.129841, 1.1339923, 2.1287072]\n",
            "Epoch :879\n",
            "d_loss : [0.29125118 0.4970703 ]\n",
            "g_loss : [1.339647, 1.095294, 1.3385518]\n",
            "Epoch :880\n",
            "d_loss : [0.28842556 0.5185547 ]\n",
            "g_loss : [1.9495047, 1.1373974, 1.9483674]\n",
            "Epoch :881\n",
            "d_loss : [0.29213822 0.5097656 ]\n",
            "g_loss : [1.5407807, 1.1346328, 1.539646]\n",
            "Epoch :882\n",
            "d_loss : [0.29007715 0.5058594 ]\n",
            "g_loss : [2.4731734, 1.1522515, 2.472021]\n",
            "Epoch :883\n",
            "d_loss : [0.29078427 0.5048828 ]\n",
            "g_loss : [2.0194318, 1.1229774, 2.0183089]\n",
            "Epoch :884\n",
            "d_loss : [0.2931992  0.49609375]\n",
            "g_loss : [1.5819981, 1.1453125, 1.5808527]\n",
            "Epoch :885\n",
            "d_loss : [0.29368496 0.5029297 ]\n",
            "g_loss : [1.8909087, 1.1129124, 1.8897958]\n",
            "Epoch :886\n",
            "d_loss : [0.29465485 0.49609375]\n",
            "g_loss : [0.8064192, 1.1414474, 0.80527776]\n",
            "Epoch :887\n",
            "d_loss : [0.29539305 0.51660156]\n",
            "g_loss : [1.299619, 1.129836, 1.2984891]\n",
            "Epoch :888\n",
            "d_loss : [0.287598 0.5     ]\n",
            "g_loss : [2.4829595, 1.1093464, 2.4818501]\n",
            "Epoch :889\n",
            "d_loss : [0.28989035 0.4921875 ]\n",
            "g_loss : [1.8892659, 1.1247841, 1.8881412]\n",
            "Epoch :890\n",
            "d_loss : [0.2919268  0.49121094]\n",
            "g_loss : [1.4437876, 1.1570458, 1.4426305]\n",
            "Epoch :891\n",
            "d_loss : [0.29135495 0.49609375]\n",
            "g_loss : [1.2940972, 1.1267632, 1.2929704]\n",
            "Epoch :892\n",
            "d_loss : [0.2924822 0.5058594]\n",
            "g_loss : [2.1536493, 1.1325746, 2.1525168]\n",
            "Epoch :893\n",
            "d_loss : [0.2940214  0.49902344]\n",
            "g_loss : [2.9672215, 1.1409428, 2.9660807]\n",
            "Epoch :894\n",
            "d_loss : [0.28675354 0.5097656 ]\n",
            "g_loss : [2.4998927, 1.1095159, 2.498783]\n",
            "Epoch :895\n",
            "d_loss : [0.29283255 0.4765625 ]\n",
            "g_loss : [2.5321386, 1.1149064, 2.5310237]\n",
            "Epoch :896\n",
            "d_loss : [0.28914043 0.49121094]\n",
            "g_loss : [2.1248176, 1.1522467, 2.1236653]\n",
            "Epoch :897\n",
            "d_loss : [0.2909388  0.49609375]\n",
            "g_loss : [1.0823569, 1.1569916, 1.0811999]\n",
            "Epoch :898\n",
            "d_loss : [0.29051942 0.5       ]\n",
            "g_loss : [1.468589, 1.1180524, 1.4674709]\n",
            "Epoch :899\n",
            "d_loss : [0.29183602 0.49121094]\n",
            "g_loss : [1.3281046, 1.1346912, 1.32697]\n",
            "Epoch :900\n",
            "d_loss : [0.29110736 0.5048828 ]\n",
            "g_loss : [1.4175267, 1.119767, 1.416407]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "PSNR: 23.08066459961887\n",
            "SSIM: 0.7714825264229027\n",
            "Epoch :901\n",
            "d_loss : [0.28950763 0.5097656 ]\n",
            "g_loss : [1.3148512, 1.1389802, 1.3137122]\n",
            "Epoch :902\n",
            "d_loss : [0.29068202 0.5175781 ]\n",
            "g_loss : [1.6656561, 1.1373651, 1.6645187]\n",
            "Epoch :903\n",
            "d_loss : [0.29266423 0.5048828 ]\n",
            "g_loss : [1.6832758, 1.129792, 1.6821461]\n",
            "Epoch :904\n",
            "d_loss : [0.28871417 0.49609375]\n",
            "g_loss : [2.0521278, 1.1353891, 2.0509925]\n",
            "Epoch :905\n",
            "d_loss : [0.2891816 0.4921875]\n",
            "g_loss : [1.4733936, 1.156239, 1.4722373]\n",
            "Epoch :906\n",
            "d_loss : [0.2906919  0.49609375]\n",
            "g_loss : [1.639726, 1.1078665, 1.6386182]\n",
            "Epoch :907\n",
            "d_loss : [0.29089212 0.515625  ]\n",
            "g_loss : [1.6427673, 1.1407559, 1.6416266]\n",
            "Epoch :908\n",
            "d_loss : [0.29257756 0.49804688]\n",
            "g_loss : [2.1687849, 1.1270375, 2.1676579]\n",
            "Epoch :909\n",
            "d_loss : [0.29349554 0.49804688]\n",
            "g_loss : [2.2430573, 1.1273978, 2.2419298]\n",
            "Epoch :910\n",
            "d_loss : [0.2918442  0.49121094]\n",
            "g_loss : [2.4537551, 1.1481097, 2.452607]\n",
            "Epoch :911\n",
            "d_loss : [0.29284814 0.49804688]\n",
            "g_loss : [2.105661, 1.127728, 2.1045332]\n",
            "Epoch :912\n",
            "d_loss : [0.29502743 0.49414062]\n",
            "g_loss : [2.2725518, 1.144275, 2.2714076]\n",
            "Epoch :913\n",
            "d_loss : [0.29475987 0.4892578 ]\n",
            "g_loss : [2.1587455, 1.1408902, 2.1576047]\n",
            "Epoch :914\n",
            "d_loss : [0.29032356 0.50097656]\n",
            "g_loss : [1.665895, 1.1277878, 1.6647671]\n",
            "Epoch :915\n",
            "d_loss : [0.28917822 0.49804688]\n",
            "g_loss : [2.123626, 1.1394612, 2.1224866]\n",
            "Epoch :916\n",
            "d_loss : [0.28703913 0.5126953 ]\n",
            "g_loss : [1.7794731, 1.126211, 1.7783469]\n",
            "Epoch :917\n",
            "d_loss : [0.2926939  0.49316406]\n",
            "g_loss : [3.041362, 1.1222776, 3.0402398]\n",
            "Epoch :918\n",
            "d_loss : [0.28834832 0.5078125 ]\n",
            "g_loss : [2.110229, 1.1548011, 2.109074]\n",
            "Epoch :919\n",
            "d_loss : [0.29363126 0.49609375]\n",
            "g_loss : [1.4200596, 1.0972965, 1.4189622]\n",
            "Epoch :920\n",
            "d_loss : [0.2897653  0.50878906]\n",
            "g_loss : [2.1063166, 1.1056511, 2.105211]\n",
            "Epoch :921\n",
            "d_loss : [0.293954  0.4951172]\n",
            "g_loss : [1.9096589, 1.1312811, 1.9085276]\n",
            "Epoch :922\n",
            "d_loss : [0.29128933 0.5078125 ]\n",
            "g_loss : [2.6803472, 1.1494308, 2.6791978]\n",
            "Epoch :923\n",
            "d_loss : [0.28945202 0.49121094]\n",
            "g_loss : [2.1213694, 1.1459398, 2.1202235]\n",
            "Epoch :924\n",
            "d_loss : [0.28571665 0.4921875 ]\n",
            "g_loss : [2.513079, 1.1503041, 2.5119286]\n",
            "Epoch :925\n",
            "d_loss : [0.29067528 0.50390625]\n",
            "g_loss : [1.5669612, 1.1347218, 1.5658264]\n",
            "Epoch :926\n",
            "d_loss : [0.29213652 0.49023438]\n",
            "g_loss : [1.4855062, 1.1421995, 1.484364]\n",
            "Epoch :927\n",
            "d_loss : [0.29004893 0.49414062]\n",
            "g_loss : [1.5365335, 1.1195035, 1.535414]\n",
            "Epoch :928\n",
            "d_loss : [0.29314741 0.4970703 ]\n",
            "g_loss : [2.7671242, 1.147028, 2.7659771]\n",
            "Epoch :929\n",
            "d_loss : [0.2929539 0.4814453]\n",
            "g_loss : [1.9384596, 1.125543, 1.9373341]\n",
            "Epoch :930\n",
            "d_loss : [0.28959864 0.4892578 ]\n",
            "g_loss : [1.2737765, 1.1273658, 1.2726492]\n",
            "Epoch :931\n",
            "d_loss : [0.29167813 0.5029297 ]\n",
            "g_loss : [2.2333212, 1.139317, 2.2321818]\n",
            "Epoch :932\n",
            "d_loss : [0.28980914 0.50683594]\n",
            "g_loss : [2.2682867, 1.1482104, 2.2671385]\n",
            "Epoch :933\n",
            "d_loss : [0.2911249 0.5097656]\n",
            "g_loss : [1.8632139, 1.1130193, 1.8621008]\n",
            "Epoch :934\n",
            "d_loss : [0.29128388 0.5019531 ]\n",
            "g_loss : [2.3439286, 1.1256019, 2.342803]\n",
            "Epoch :935\n",
            "d_loss : [0.2885853  0.50683594]\n",
            "g_loss : [2.2515674, 1.1301534, 2.2504373]\n",
            "Epoch :936\n",
            "d_loss : [0.29012355 0.51660156]\n",
            "g_loss : [1.9230603, 1.1281292, 1.9219322]\n",
            "Epoch :937\n",
            "d_loss : [0.29110736 0.5029297 ]\n",
            "g_loss : [1.6654539, 1.1298347, 1.664324]\n",
            "Epoch :938\n",
            "d_loss : [0.28837258 0.51464844]\n",
            "g_loss : [2.2354393, 1.1110024, 2.2343283]\n",
            "Epoch :939\n",
            "d_loss : [0.28773966 0.4970703 ]\n",
            "g_loss : [1.8739107, 1.1324692, 1.8727782]\n",
            "Epoch :940\n",
            "d_loss : [0.29276335 0.49609375]\n",
            "g_loss : [1.778799, 1.1261694, 1.7776729]\n",
            "Epoch :941\n",
            "d_loss : [0.29132828 0.5058594 ]\n",
            "g_loss : [1.0905404, 1.1446743, 1.0893958]\n",
            "Epoch :942\n",
            "d_loss : [0.29040062 0.49609375]\n",
            "g_loss : [1.9761302, 1.1196777, 1.9750105]\n",
            "Epoch :943\n",
            "d_loss : [0.291345   0.49804688]\n",
            "g_loss : [2.0134392, 1.1524348, 2.0122867]\n",
            "Epoch :944\n",
            "d_loss : [0.29456005 0.49902344]\n",
            "g_loss : [1.4257563, 1.1081244, 1.4246482]\n",
            "Epoch :945\n",
            "d_loss : [0.29108742 0.49902344]\n",
            "g_loss : [1.846404, 1.1085671, 1.8452954]\n",
            "Epoch :946\n",
            "d_loss : [0.2900669 0.5078125]\n",
            "g_loss : [2.0860662, 1.1293344, 2.0849369]\n",
            "Epoch :947\n",
            "d_loss : [0.28974396 0.51464844]\n",
            "g_loss : [1.0760494, 1.1254756, 1.074924]\n",
            "Epoch :948\n",
            "d_loss : [0.28723145 0.5078125 ]\n",
            "g_loss : [1.461155, 1.1445987, 1.4600104]\n",
            "Epoch :949\n",
            "d_loss : [0.28827846 0.5107422 ]\n",
            "g_loss : [2.192827, 1.1248083, 2.1917021]\n",
            "Epoch :950\n",
            "d_loss : [0.28972706 0.49609375]\n",
            "g_loss : [0.98628813, 1.1244681, 0.9851637]\n",
            "Epoch :951\n",
            "d_loss : [0.29336566 0.49902344]\n",
            "g_loss : [1.6451094, 1.1345807, 1.6439748]\n",
            "Epoch :952\n",
            "d_loss : [0.29070547 0.49609375]\n",
            "g_loss : [1.9033628, 1.0966183, 1.9022661]\n",
            "Epoch :953\n",
            "d_loss : [0.29031867 0.484375  ]\n",
            "g_loss : [1.8857013, 1.1416464, 1.8845596]\n",
            "Epoch :954\n",
            "d_loss : [0.2912074 0.5097656]\n",
            "g_loss : [2.1311605, 1.14453, 2.1300159]\n",
            "Epoch :955\n",
            "d_loss : [0.29011983 0.4970703 ]\n",
            "g_loss : [1.0703562, 1.1209092, 1.0692353]\n",
            "Epoch :956\n",
            "d_loss : [0.29435366 0.49414062]\n",
            "g_loss : [1.7566179, 1.1164875, 1.7555014]\n",
            "Epoch :957\n",
            "d_loss : [0.28922433 0.4921875 ]\n",
            "g_loss : [0.94152355, 1.1560664, 0.94036746]\n",
            "Epoch :958\n",
            "d_loss : [0.29159713 0.4873047 ]\n",
            "g_loss : [1.8855836, 1.1170386, 1.8844666]\n",
            "Epoch :959\n",
            "d_loss : [0.29283258 0.4970703 ]\n",
            "g_loss : [1.7901379, 1.1095302, 1.7890284]\n",
            "Epoch :960\n",
            "d_loss : [0.29180315 0.5       ]\n",
            "g_loss : [1.3907593, 1.1241623, 1.3896352]\n",
            "Epoch :961\n",
            "d_loss : [0.2895257  0.49609375]\n",
            "g_loss : [1.7329818, 1.1378739, 1.731844]\n",
            "Epoch :962\n",
            "d_loss : [0.29057238 0.49316406]\n",
            "g_loss : [1.6635042, 1.1236049, 1.6623807]\n",
            "Epoch :963\n",
            "d_loss : [0.29274368 0.5078125 ]\n",
            "g_loss : [1.4571705, 1.1320094, 1.4560385]\n",
            "Epoch :964\n",
            "d_loss : [0.29461035 0.4921875 ]\n",
            "g_loss : [1.8627056, 1.1495407, 1.861556]\n",
            "Epoch :965\n",
            "d_loss : [0.29375368 0.48242188]\n",
            "g_loss : [1.7802778, 1.1075658, 1.7791703]\n",
            "Epoch :966\n",
            "d_loss : [0.29000401 0.5078125 ]\n",
            "g_loss : [1.7602355, 1.1267924, 1.7591088]\n",
            "Epoch :967\n",
            "d_loss : [0.29099584 0.5048828 ]\n",
            "g_loss : [2.2100418, 1.1258439, 2.208916]\n",
            "Epoch :968\n",
            "d_loss : [0.29083294 0.5048828 ]\n",
            "g_loss : [1.2639319, 1.1363673, 1.2627954]\n",
            "Epoch :969\n",
            "d_loss : [0.29007325 0.4921875 ]\n",
            "g_loss : [1.5254674, 1.1329389, 1.5243344]\n",
            "Epoch :970\n",
            "d_loss : [0.29311198 0.4951172 ]\n",
            "g_loss : [1.3597782, 1.1485131, 1.3586297]\n",
            "Epoch :971\n",
            "d_loss : [0.2863746  0.49316406]\n",
            "g_loss : [1.299553, 1.117619, 1.2984354]\n",
            "Epoch :972\n",
            "d_loss : [0.2898398 0.4970703]\n",
            "g_loss : [1.233593, 1.1244411, 1.2324686]\n",
            "Epoch :973\n",
            "d_loss : [0.29425508 0.4970703 ]\n",
            "g_loss : [2.8785946, 1.133029, 2.8774617]\n",
            "Epoch :974\n",
            "d_loss : [0.2897721  0.50390625]\n",
            "g_loss : [1.1280631, 1.1223351, 1.1269407]\n",
            "Epoch :975\n",
            "d_loss : [0.28993922 0.5058594 ]\n",
            "g_loss : [1.3398254, 1.12372, 1.3387017]\n",
            "Epoch :976\n",
            "d_loss : [0.29556888 0.484375  ]\n",
            "g_loss : [2.5182421, 1.134276, 2.517108]\n",
            "Epoch :977\n",
            "d_loss : [0.29244816 0.48046875]\n",
            "g_loss : [1.8711511, 1.1205342, 1.8700305]\n",
            "Epoch :978\n",
            "d_loss : [0.2921814 0.5029297]\n",
            "g_loss : [1.4873542, 1.1181598, 1.486236]\n",
            "Epoch :979\n",
            "d_loss : [0.29338843 0.5019531 ]\n",
            "g_loss : [1.9966588, 1.1424606, 1.9955163]\n",
            "Epoch :980\n",
            "d_loss : [0.29225048 0.4921875 ]\n",
            "g_loss : [1.6875464, 1.1370323, 1.6864094]\n",
            "Epoch :981\n",
            "d_loss : [0.2943241 0.5019531]\n",
            "g_loss : [2.478909, 1.1167878, 2.4777923]\n",
            "Epoch :982\n",
            "d_loss : [0.29266053 0.49902344]\n",
            "g_loss : [1.3236316, 1.1293509, 1.3225023]\n",
            "Epoch :983\n",
            "d_loss : [0.2895077  0.50878906]\n",
            "g_loss : [1.1688328, 1.1358796, 1.167697]\n",
            "Epoch :984\n",
            "d_loss : [0.28872037 0.5       ]\n",
            "g_loss : [1.47175, 1.1383431, 1.4706117]\n",
            "Epoch :985\n",
            "d_loss : [0.28961498 0.50878906]\n",
            "g_loss : [1.568817, 1.117154, 1.5676999]\n",
            "Epoch :986\n",
            "d_loss : [0.29033414 0.50683594]\n",
            "g_loss : [1.8622178, 1.1392406, 1.8610785]\n",
            "Epoch :987\n",
            "d_loss : [0.2895525 0.4951172]\n",
            "g_loss : [1.7870415, 1.132559, 1.7859089]\n",
            "Epoch :988\n",
            "d_loss : [0.29004803 0.5107422 ]\n",
            "g_loss : [2.0082767, 1.1178498, 2.0071588]\n",
            "Epoch :989\n",
            "d_loss : [0.2871876 0.5078125]\n",
            "g_loss : [1.4667698, 1.1342521, 1.4656355]\n",
            "Epoch :990\n",
            "d_loss : [0.2944719  0.50683594]\n",
            "g_loss : [1.6577951, 1.1223934, 1.6566727]\n",
            "Epoch :991\n",
            "d_loss : [0.2962782 0.5097656]\n",
            "g_loss : [1.2413387, 1.1355486, 1.2402031]\n",
            "Epoch :992\n",
            "d_loss : [0.2922688 0.5048828]\n",
            "g_loss : [1.7073522, 1.1381546, 1.706214]\n",
            "Epoch :993\n",
            "d_loss : [0.29249567 0.5029297 ]\n",
            "g_loss : [1.0957489, 1.1595234, 1.0945894]\n",
            "Epoch :994\n",
            "d_loss : [0.28823888 0.49316406]\n",
            "g_loss : [1.42778, 1.1627322, 1.4266173]\n",
            "Epoch :995\n",
            "d_loss : [0.29427165 0.5029297 ]\n",
            "g_loss : [2.1959321, 1.1331886, 2.194799]\n",
            "Epoch :996\n",
            "d_loss : [0.2943954 0.5078125]\n",
            "g_loss : [1.951674, 1.1039412, 1.95057]\n",
            "Epoch :997\n",
            "d_loss : [0.29213855 0.5048828 ]\n",
            "g_loss : [1.9435577, 1.1238091, 1.942434]\n",
            "Epoch :998\n",
            "d_loss : [0.29207733 0.5       ]\n",
            "g_loss : [2.1652641, 1.1469197, 2.164117]\n",
            "Epoch :999\n",
            "d_loss : [0.29468143 0.49804688]\n",
            "g_loss : [1.2644515, 1.1379033, 1.2633137]\n",
            "Epoch :1000\n",
            "d_loss : [0.28739226 0.4970703 ]\n",
            "g_loss : [2.7924347, 1.090529, 2.7913442]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "  \n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "PSNR: 20.82989073461716\n",
            "SSIM: 0.6288558632324517\n",
            "Epoch :1001\n",
            "d_loss : [0.291381  0.4970703]\n",
            "g_loss : [1.1503818, 1.1051061, 1.1492767]\n",
            "Epoch :1002\n",
            "d_loss : [0.29068094 0.4921875 ]\n",
            "g_loss : [1.6593097, 1.1333683, 1.6581764]\n",
            "Epoch :1003\n",
            "d_loss : [0.2924568  0.51660156]\n",
            "g_loss : [2.3935146, 1.1420443, 2.3923726]\n",
            "Epoch :1004\n",
            "d_loss : [0.29167426 0.5029297 ]\n",
            "g_loss : [2.4807749, 1.1558528, 2.479619]\n",
            "Epoch :1005\n",
            "d_loss : [0.2953459  0.50683594]\n",
            "g_loss : [1.1686985, 1.1343503, 1.1675642]\n",
            "Epoch :1006\n",
            "d_loss : [0.28630146 0.5029297 ]\n",
            "g_loss : [1.8500729, 1.1086452, 1.8489642]\n",
            "Epoch :1007\n",
            "d_loss : [0.29512948 0.5097656 ]\n",
            "g_loss : [2.2125902, 1.1469777, 2.2114432]\n",
            "Epoch :1008\n",
            "d_loss : [0.2902495  0.49023438]\n",
            "g_loss : [1.9919729, 1.1076707, 1.9908652]\n",
            "Epoch :1009\n",
            "d_loss : [0.2900213 0.5048828]\n",
            "g_loss : [1.9507208, 1.1110593, 1.9496098]\n",
            "Epoch :1010\n",
            "d_loss : [0.29405344 0.4970703 ]\n",
            "g_loss : [1.9896953, 1.130855, 1.9885645]\n",
            "Epoch :1011\n",
            "d_loss : [0.29443717 0.5126953 ]\n",
            "g_loss : [1.698578, 1.1156225, 1.6974623]\n",
            "Epoch :1012\n",
            "d_loss : [0.2913388  0.50097656]\n",
            "g_loss : [1.4042246, 1.0795568, 1.4031451]\n",
            "Epoch :1013\n",
            "d_loss : [0.28997612 0.5029297 ]\n",
            "g_loss : [2.0804963, 1.1469618, 2.0793493]\n",
            "Epoch :1014\n",
            "d_loss : [0.29122958 0.5097656 ]\n",
            "g_loss : [1.6854314, 1.1097865, 1.6843215]\n",
            "Epoch :1015\n",
            "d_loss : [0.29061836 0.4970703 ]\n",
            "g_loss : [1.010241, 1.1234288, 1.0091176]\n",
            "Epoch :1016\n",
            "d_loss : [0.2929119 0.5058594]\n",
            "g_loss : [2.208795, 1.1233902, 2.2076716]\n",
            "Epoch :1017\n",
            "d_loss : [0.28877783 0.49804688]\n",
            "g_loss : [2.1516562, 1.1396282, 2.1505165]\n",
            "Epoch :1018\n",
            "d_loss : [0.29469788 0.49023438]\n",
            "g_loss : [2.0901551, 1.1048634, 2.0890503]\n",
            "Epoch :1019\n",
            "d_loss : [0.29214174 0.4951172 ]\n",
            "g_loss : [1.3065053, 1.1006442, 1.3054047]\n",
            "Epoch :1020\n",
            "d_loss : [0.29129618 0.48828125]\n",
            "g_loss : [1.815281, 1.1426208, 1.8141384]\n",
            "Epoch :1021\n",
            "d_loss : [0.2955129 0.515625 ]\n",
            "g_loss : [1.866561, 1.1407814, 1.8654202]\n",
            "Epoch :1022\n",
            "d_loss : [0.29291913 0.50683594]\n",
            "g_loss : [1.4808016, 1.1283927, 1.4796731]\n",
            "Epoch :1023\n",
            "d_loss : [0.2918989  0.50878906]\n",
            "g_loss : [1.4520082, 1.1265488, 1.4508817]\n",
            "Epoch :1024\n",
            "d_loss : [0.29258373 0.4970703 ]\n",
            "g_loss : [2.369321, 1.0904174, 2.3682306]\n",
            "Epoch :1025\n",
            "d_loss : [0.28986648 0.50097656]\n",
            "g_loss : [1.2516816, 1.1306306, 1.250551]\n",
            "Epoch :1026\n",
            "d_loss : [0.29028824 0.4970703 ]\n",
            "g_loss : [1.9090879, 1.1049321, 1.907983]\n",
            "Epoch :1027\n",
            "d_loss : [0.29329196 0.50878906]\n",
            "g_loss : [2.6595874, 1.1249719, 2.6584625]\n",
            "Epoch :1028\n",
            "d_loss : [0.28964028 0.5175781 ]\n",
            "g_loss : [2.1409857, 1.1531588, 2.1398325]\n",
            "Epoch :1029\n",
            "d_loss : [0.29331213 0.5029297 ]\n",
            "g_loss : [1.7901548, 1.1437576, 1.789011]\n",
            "Epoch :1030\n",
            "d_loss : [0.29374668 0.5029297 ]\n",
            "g_loss : [0.9586753, 1.1566024, 0.9575187]\n",
            "Epoch :1031\n",
            "d_loss : [0.29011315 0.4970703 ]\n",
            "g_loss : [1.6751145, 1.1359968, 1.6739786]\n",
            "Epoch :1032\n",
            "d_loss : [0.29088736 0.5       ]\n",
            "g_loss : [1.8142625, 1.1198102, 1.8131427]\n",
            "Epoch :1033\n",
            "d_loss : [0.29347277 0.4892578 ]\n",
            "g_loss : [1.177941, 1.1056567, 1.1768353]\n",
            "Epoch :1034\n",
            "d_loss : [0.29053956 0.49414062]\n",
            "g_loss : [1.673615, 1.142935, 1.672472]\n",
            "Epoch :1035\n",
            "d_loss : [0.29247358 0.5       ]\n",
            "g_loss : [3.1371827, 1.1483741, 3.1360343]\n",
            "Epoch :1036\n",
            "d_loss : [0.29166818 0.5078125 ]\n",
            "g_loss : [1.9887743, 1.1413329, 1.987633]\n",
            "Epoch :1037\n",
            "d_loss : [0.29012507 0.49609375]\n",
            "g_loss : [1.9161202, 1.1250235, 1.9149952]\n",
            "Epoch :1038\n",
            "d_loss : [0.28954643 0.4892578 ]\n",
            "g_loss : [1.437099, 1.1336884, 1.4359653]\n",
            "Epoch :1039\n",
            "d_loss : [0.29027337 0.5048828 ]\n",
            "g_loss : [2.3204796, 1.1297395, 2.31935]\n",
            "Epoch :1040\n",
            "d_loss : [0.2896213 0.5175781]\n",
            "g_loss : [1.8249011, 1.1300807, 1.823771]\n",
            "Epoch :1041\n",
            "d_loss : [0.29099655 0.5214844 ]\n",
            "g_loss : [1.5041068, 1.1278081, 1.5029789]\n",
            "Epoch :1042\n",
            "d_loss : [0.2900825 0.484375 ]\n",
            "g_loss : [1.6938251, 1.0952756, 1.6927298]\n",
            "Epoch :1043\n",
            "d_loss : [0.292562   0.50878906]\n",
            "g_loss : [1.7079706, 1.1172171, 1.7068534]\n",
            "Epoch :1044\n",
            "d_loss : [0.289244  0.5048828]\n",
            "g_loss : [1.9182433, 1.1335899, 1.9171097]\n",
            "Epoch :1045\n",
            "d_loss : [0.29199085 0.49902344]\n",
            "g_loss : [2.0091057, 1.1285715, 2.007977]\n",
            "Epoch :1046\n",
            "d_loss : [0.29018414 0.50097656]\n",
            "g_loss : [2.0326073, 1.1309772, 2.0314763]\n",
            "Epoch :1047\n",
            "d_loss : [0.293629   0.49804688]\n",
            "g_loss : [1.7950481, 1.1214815, 1.7939266]\n",
            "Epoch :1048\n",
            "d_loss : [0.29168168 0.50390625]\n",
            "g_loss : [1.0771587, 1.1625366, 1.0759962]\n",
            "Epoch :1049\n",
            "d_loss : [0.29075772 0.4921875 ]\n",
            "g_loss : [1.5398501, 1.114222, 1.5387359]\n",
            "Epoch :1050\n",
            "d_loss : [0.29083246 0.5058594 ]\n",
            "g_loss : [1.9168687, 1.0898569, 1.9157789]\n",
            "Epoch :1051\n",
            "d_loss : [0.28995872 0.5019531 ]\n",
            "g_loss : [2.284515, 1.1372335, 2.2833776]\n",
            "Epoch :1052\n",
            "d_loss : [0.29435444 0.4921875 ]\n",
            "g_loss : [1.5045488, 1.1260564, 1.5034227]\n",
            "Epoch :1053\n",
            "d_loss : [0.29522112 0.51953125]\n",
            "g_loss : [1.5359279, 1.1197865, 1.5348082]\n",
            "Epoch :1054\n",
            "d_loss : [0.2932986  0.49414062]\n",
            "g_loss : [0.94209146, 1.1301203, 0.94096136]\n",
            "Epoch :1055\n",
            "d_loss : [0.2868656 0.5175781]\n",
            "g_loss : [1.9031842, 1.1307833, 1.9020534]\n",
            "Epoch :1056\n",
            "d_loss : [0.29012007 0.5078125 ]\n",
            "g_loss : [1.5670294, 1.1223276, 1.565907]\n",
            "Epoch :1057\n",
            "d_loss : [0.29434162 0.4951172 ]\n",
            "g_loss : [1.7093264, 1.1319736, 1.7081944]\n",
            "Epoch :1058\n",
            "d_loss : [0.2927192 0.5019531]\n",
            "g_loss : [1.402749, 1.1301638, 1.4016187]\n",
            "Epoch :1059\n",
            "d_loss : [0.28883556 0.49804688]\n",
            "g_loss : [1.9878457, 1.1114986, 1.9867342]\n",
            "Epoch :1060\n",
            "d_loss : [0.2913695 0.5107422]\n",
            "g_loss : [1.5472507, 1.1171803, 1.5461335]\n",
            "Epoch :1061\n",
            "d_loss : [0.29212004 0.50097656]\n",
            "g_loss : [2.2291534, 1.1531767, 2.2280002]\n",
            "Epoch :1062\n",
            "d_loss : [0.29510188 0.51171875]\n",
            "g_loss : [1.1239665, 1.1348151, 1.1228316]\n",
            "Epoch :1063\n",
            "d_loss : [0.2927537  0.49316406]\n",
            "g_loss : [1.9383705, 1.103676, 1.9372668]\n",
            "Epoch :1064\n",
            "d_loss : [0.29225522 0.5107422 ]\n",
            "g_loss : [1.7351433, 1.1280551, 1.7340152]\n",
            "Epoch :1065\n",
            "d_loss : [0.29214156 0.5       ]\n",
            "g_loss : [1.7251927, 1.1066499, 1.724086]\n",
            "Epoch :1066\n",
            "d_loss : [0.29109454 0.49609375]\n",
            "g_loss : [1.8574119, 1.1251097, 1.8562868]\n",
            "Epoch :1067\n",
            "d_loss : [0.29017216 0.50390625]\n",
            "g_loss : [1.5238003, 1.1304907, 1.5226698]\n",
            "Epoch :1068\n",
            "d_loss : [0.29171267 0.48828125]\n",
            "g_loss : [1.4833862, 1.1204832, 1.4822657]\n",
            "Epoch :1069\n",
            "d_loss : [0.29218662 0.49316406]\n",
            "g_loss : [1.7771276, 1.1485872, 1.775979]\n",
            "Epoch :1070\n",
            "d_loss : [0.29052943 0.4970703 ]\n",
            "g_loss : [1.6618284, 1.1227882, 1.6607056]\n",
            "Epoch :1071\n",
            "d_loss : [0.29191476 0.50683594]\n",
            "g_loss : [1.9646302, 1.1311588, 1.9634991]\n",
            "Epoch :1072\n",
            "d_loss : [0.29375446 0.49804688]\n",
            "g_loss : [1.8691746, 1.1293623, 1.8680452]\n",
            "Epoch :1073\n",
            "d_loss : [0.28887215 0.5078125 ]\n",
            "g_loss : [2.2157447, 1.1280502, 2.2146168]\n",
            "Epoch :1074\n",
            "d_loss : [0.29483342 0.49316406]\n",
            "g_loss : [2.0839086, 1.1510649, 2.0827575]\n",
            "Epoch :1075\n",
            "d_loss : [0.29295558 0.4873047 ]\n",
            "g_loss : [2.191792, 1.1445591, 2.1906474]\n",
            "Epoch :1076\n",
            "d_loss : [0.2933979 0.5058594]\n",
            "g_loss : [1.0349845, 1.1580563, 1.0338265]\n",
            "Epoch :1077\n",
            "d_loss : [0.29191804 0.51464844]\n",
            "g_loss : [1.5230001, 1.133107, 1.521867]\n",
            "Epoch :1078\n",
            "d_loss : [0.29104072 0.49902344]\n",
            "g_loss : [0.84787256, 1.1426156, 0.84672993]\n",
            "Epoch :1079\n",
            "d_loss : [0.2919124  0.50097656]\n",
            "g_loss : [1.9819422, 1.0993311, 1.9808428]\n",
            "Epoch :1080\n",
            "d_loss : [0.29162955 0.4892578 ]\n",
            "g_loss : [1.406877, 1.116497, 1.4057605]\n",
            "Epoch :1081\n",
            "d_loss : [0.29107413 0.49023438]\n",
            "g_loss : [1.5176436, 1.1042905, 1.5165393]\n",
            "Epoch :1082\n",
            "d_loss : [0.29294395 0.5078125 ]\n",
            "g_loss : [1.445225, 1.123049, 1.4441019]\n",
            "Epoch :1083\n",
            "d_loss : [0.29210287 0.49023438]\n",
            "g_loss : [0.8431228, 1.1398299, 0.84198296]\n",
            "Epoch :1084\n",
            "d_loss : [0.29527867 0.49609375]\n",
            "g_loss : [0.7526318, 1.1473798, 0.7514844]\n",
            "Epoch :1085\n",
            "d_loss : [0.29084784 0.5175781 ]\n",
            "g_loss : [1.9921422, 1.1089165, 1.9910333]\n",
            "Epoch :1086\n",
            "d_loss : [0.28925025 0.4921875 ]\n",
            "g_loss : [1.4015281, 1.1286886, 1.4003994]\n",
            "Epoch :1087\n",
            "d_loss : [0.2871853  0.49316406]\n",
            "g_loss : [2.2367394, 1.0979998, 2.2356415]\n",
            "Epoch :1088\n",
            "d_loss : [0.292513   0.49023438]\n",
            "g_loss : [1.8142968, 1.1274092, 1.8131695]\n",
            "Epoch :1089\n",
            "d_loss : [0.2918453  0.49902344]\n",
            "g_loss : [1.1527865, 1.126481, 1.15166]\n",
            "Epoch :1090\n",
            "d_loss : [0.29302645 0.49023438]\n",
            "g_loss : [1.5213524, 1.1298794, 1.5202225]\n",
            "Epoch :1091\n",
            "d_loss : [0.29124856 0.4951172 ]\n",
            "g_loss : [1.1132275, 1.1361268, 1.1120913]\n",
            "Epoch :1092\n",
            "d_loss : [0.29261583 0.5078125 ]\n",
            "g_loss : [2.6811352, 1.1447567, 2.6799905]\n",
            "Epoch :1093\n",
            "d_loss : [0.29173934 0.4951172 ]\n",
            "g_loss : [1.1372228, 1.132488, 1.1360903]\n",
            "Epoch :1094\n",
            "d_loss : [0.29076326 0.5029297 ]\n",
            "g_loss : [1.913506, 1.1263213, 1.9123797]\n",
            "Epoch :1095\n",
            "d_loss : [0.28677976 0.49902344]\n",
            "g_loss : [1.5659521, 1.1237063, 1.5648284]\n",
            "Epoch :1096\n",
            "d_loss : [0.29370457 0.5058594 ]\n",
            "g_loss : [2.1228826, 1.1092896, 2.1217732]\n",
            "Epoch :1097\n",
            "d_loss : [0.29065627 0.4765625 ]\n",
            "g_loss : [1.17345, 1.1379324, 1.172312]\n",
            "Epoch :1098\n",
            "d_loss : [0.29096657 0.5097656 ]\n",
            "g_loss : [1.4641778, 1.096453, 1.4630814]\n",
            "Epoch :1099\n",
            "d_loss : [0.2890885  0.50878906]\n",
            "g_loss : [1.765255, 1.1102579, 1.7641447]\n",
            "Epoch :1100\n",
            "d_loss : [0.2901913  0.51171875]\n",
            "g_loss : [1.9085371, 1.1310687, 1.9074061]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "PSNR: 15.452149073317102\n",
            "SSIM: 0.7896198625121347\n",
            "Epoch :1101\n",
            "d_loss : [0.29293925 0.49804688]\n",
            "g_loss : [1.589331, 1.1280004, 1.5882031]\n",
            "Epoch :1102\n",
            "d_loss : [0.2940668 0.5029297]\n",
            "g_loss : [2.1145618, 1.1447604, 2.1134171]\n",
            "Epoch :1103\n",
            "d_loss : [0.29177988 0.5097656 ]\n",
            "g_loss : [1.7507527, 1.1348585, 1.7496178]\n",
            "Epoch :1104\n",
            "d_loss : [0.29018173 0.48828125]\n",
            "g_loss : [2.23974, 1.134332, 2.2386055]\n",
            "Epoch :1105\n",
            "d_loss : [0.29050088 0.5       ]\n",
            "g_loss : [2.480174, 1.118119, 2.479056]\n",
            "Epoch :1106\n",
            "d_loss : [0.2932305  0.49023438]\n",
            "g_loss : [1.6874151, 1.1397935, 1.6862754]\n",
            "Epoch :1107\n",
            "d_loss : [0.2917726 0.4951172]\n",
            "g_loss : [1.6608037, 1.1254425, 1.6596782]\n",
            "Epoch :1108\n",
            "d_loss : [0.29475352 0.4892578 ]\n",
            "g_loss : [1.0086968, 1.1417459, 1.007555]\n",
            "Epoch :1109\n",
            "d_loss : [0.2930708 0.5029297]\n",
            "g_loss : [2.1923223, 1.1430331, 2.1911793]\n",
            "Epoch :1110\n",
            "d_loss : [0.29114735 0.49804688]\n",
            "g_loss : [2.1513507, 1.1319702, 2.1502187]\n",
            "Epoch :1111\n",
            "d_loss : [0.2910031 0.4970703]\n",
            "g_loss : [1.6268263, 1.1307842, 1.6256955]\n",
            "Epoch :1112\n",
            "d_loss : [0.29416972 0.49121094]\n",
            "g_loss : [1.9622488, 1.1243109, 1.9611245]\n",
            "Epoch :1113\n",
            "d_loss : [0.29183954 0.5048828 ]\n",
            "g_loss : [1.3302828, 1.1034772, 1.3291793]\n",
            "Epoch :1114\n",
            "d_loss : [0.29548422 0.5019531 ]\n",
            "g_loss : [1.4544666, 1.1124393, 1.4533541]\n",
            "Epoch :1115\n",
            "d_loss : [0.29172415 0.5029297 ]\n",
            "g_loss : [1.7106894, 1.1359804, 1.7095535]\n",
            "Epoch :1116\n",
            "d_loss : [0.2893034 0.4873047]\n",
            "g_loss : [1.600972, 1.1327548, 1.5998393]\n",
            "Epoch :1117\n",
            "d_loss : [0.29372174 0.4873047 ]\n",
            "g_loss : [2.3731973, 1.1038058, 2.3720934]\n",
            "Epoch :1118\n",
            "d_loss : [0.28883755 0.4970703 ]\n",
            "g_loss : [1.3941638, 1.0850539, 1.3930788]\n",
            "Epoch :1119\n",
            "d_loss : [0.29114002 0.4951172 ]\n",
            "g_loss : [1.4740934, 1.1127079, 1.4729807]\n",
            "Epoch :1120\n",
            "d_loss : [0.29206693 0.49804688]\n",
            "g_loss : [2.1590908, 1.1398292, 2.1579509]\n",
            "Epoch :1121\n",
            "d_loss : [0.29019672 0.50683594]\n",
            "g_loss : [1.5624447, 1.1281407, 1.5613165]\n",
            "Epoch :1122\n",
            "d_loss : [0.29434758 0.4921875 ]\n",
            "g_loss : [1.6085731, 1.1387722, 1.6074343]\n",
            "Epoch :1123\n",
            "d_loss : [0.29288936 0.4814453 ]\n",
            "g_loss : [1.4088967, 1.1263196, 1.4077704]\n",
            "Epoch :1124\n",
            "d_loss : [0.2890079 0.5019531]\n",
            "g_loss : [0.96645355, 1.1448936, 0.96530867]\n",
            "Epoch :1125\n",
            "d_loss : [0.29141602 0.5048828 ]\n",
            "g_loss : [1.572364, 1.1335444, 1.5712304]\n",
            "Epoch :1126\n",
            "d_loss : [0.29007453 0.51171875]\n",
            "g_loss : [1.4399055, 1.1399077, 1.4387656]\n",
            "Epoch :1127\n",
            "d_loss : [0.2921273 0.5019531]\n",
            "g_loss : [2.025138, 1.1351404, 2.0240028]\n",
            "Epoch :1128\n",
            "d_loss : [0.2900687  0.50878906]\n",
            "g_loss : [2.185866, 1.1527624, 2.1847134]\n",
            "Epoch :1129\n",
            "d_loss : [0.29584092 0.5048828 ]\n",
            "g_loss : [1.7363663, 1.1105983, 1.7352557]\n",
            "Epoch :1130\n",
            "d_loss : [0.29350543 0.47851562]\n",
            "g_loss : [1.9225463, 1.14025, 1.921406]\n",
            "Epoch :1131\n",
            "d_loss : [0.28915992 0.5078125 ]\n",
            "g_loss : [1.273078, 1.1381987, 1.2719398]\n",
            "Epoch :1132\n",
            "d_loss : [0.29214793 0.49804688]\n",
            "g_loss : [1.2908602, 1.1195657, 1.2897406]\n",
            "Epoch :1133\n",
            "d_loss : [0.2913594  0.50390625]\n",
            "g_loss : [2.0346308, 1.1358833, 2.033495]\n",
            "Epoch :1134\n",
            "d_loss : [0.29359627 0.50390625]\n",
            "g_loss : [1.4881034, 1.1202884, 1.4869831]\n",
            "Epoch :1135\n",
            "d_loss : [0.28537908 0.5136719 ]\n",
            "g_loss : [2.267089, 1.119199, 2.2659698]\n",
            "Epoch :1136\n",
            "d_loss : [0.29402626 0.49316406]\n",
            "g_loss : [1.0505929, 1.1284513, 1.0494645]\n",
            "Epoch :1137\n",
            "d_loss : [0.29078645 0.49902344]\n",
            "g_loss : [1.375532, 1.1247962, 1.3744073]\n",
            "Epoch :1138\n",
            "d_loss : [0.2945106  0.49902344]\n",
            "g_loss : [1.333685, 1.1386039, 1.3325465]\n",
            "Epoch :1139\n",
            "d_loss : [0.28990963 0.5107422 ]\n",
            "g_loss : [1.1944137, 1.1237298, 1.1932899]\n",
            "Epoch :1140\n",
            "d_loss : [0.2935553 0.4970703]\n",
            "g_loss : [1.324288, 1.1327748, 1.3231553]\n",
            "Epoch :1141\n",
            "d_loss : [0.2929524 0.5048828]\n",
            "g_loss : [1.6744814, 1.0965967, 1.6733848]\n",
            "Epoch :1142\n",
            "d_loss : [0.29459357 0.4892578 ]\n",
            "g_loss : [1.2574973, 1.1074874, 1.2563899]\n",
            "Epoch :1143\n",
            "d_loss : [0.28964967 0.5126953 ]\n",
            "g_loss : [1.6001107, 1.1251307, 1.5989856]\n",
            "Epoch :1144\n",
            "d_loss : [0.29123968 0.50390625]\n",
            "g_loss : [2.090933, 1.1445584, 2.0897884]\n",
            "Epoch :1145\n",
            "d_loss : [0.28846025 0.50097656]\n",
            "g_loss : [1.6658309, 1.1484334, 1.6646824]\n",
            "Epoch :1146\n",
            "d_loss : [0.28816828 0.5019531 ]\n",
            "g_loss : [1.7514827, 1.1269635, 1.7503557]\n",
            "Epoch :1147\n",
            "d_loss : [0.2935589 0.4970703]\n",
            "g_loss : [0.96437764, 1.1233871, 0.9632543]\n",
            "Epoch :1148\n",
            "d_loss : [0.29038584 0.51171875]\n",
            "g_loss : [2.0034785, 1.1491687, 2.0023293]\n",
            "Epoch :1149\n",
            "d_loss : [0.29119   0.5078125]\n",
            "g_loss : [1.0430684, 1.1294417, 1.041939]\n",
            "Epoch :1150\n",
            "d_loss : [0.29102343 0.50683594]\n",
            "g_loss : [1.3529209, 1.1121567, 1.3518088]\n",
            "Epoch :1151\n",
            "d_loss : [0.29021686 0.49023438]\n",
            "g_loss : [0.88924414, 1.1282568, 0.8881159]\n",
            "Epoch :1152\n",
            "d_loss : [0.2936072  0.52734375]\n",
            "g_loss : [1.4218777, 1.1216606, 1.4207561]\n",
            "Epoch :1153\n",
            "d_loss : [0.29214463 0.49414062]\n",
            "g_loss : [1.7385637, 1.1130786, 1.7374506]\n",
            "Epoch :1154\n",
            "d_loss : [0.29449067 0.50390625]\n",
            "g_loss : [1.5110017, 1.1202943, 1.5098814]\n",
            "Epoch :1155\n",
            "d_loss : [0.29327196 0.51171875]\n",
            "g_loss : [1.3111464, 1.1152036, 1.3100312]\n",
            "Epoch :1156\n",
            "d_loss : [0.2877999 0.4951172]\n",
            "g_loss : [1.949847, 1.0983617, 1.9487486]\n",
            "Epoch :1157\n",
            "d_loss : [0.29192004 0.4970703 ]\n",
            "g_loss : [1.3066424, 1.1401962, 1.3055022]\n",
            "Epoch :1158\n",
            "d_loss : [0.29371697 0.4814453 ]\n",
            "g_loss : [0.8873451, 1.1216397, 0.88622344]\n",
            "Epoch :1159\n",
            "d_loss : [0.29519713 0.49316406]\n",
            "g_loss : [1.7222065, 1.1108763, 1.7210956]\n",
            "Epoch :1160\n",
            "d_loss : [0.29033995 0.49609375]\n",
            "g_loss : [1.286405, 1.1372488, 1.2852677]\n",
            "Epoch :1161\n",
            "d_loss : [0.2905384  0.50878906]\n",
            "g_loss : [1.4201536, 1.1244192, 1.4190292]\n",
            "Epoch :1162\n",
            "d_loss : [0.28989872 0.49804688]\n",
            "g_loss : [1.6695439, 1.1176553, 1.6684262]\n",
            "Epoch :1163\n",
            "d_loss : [0.29332298 0.49316406]\n",
            "g_loss : [0.9415411, 1.1314651, 0.9404096]\n",
            "Epoch :1164\n",
            "d_loss : [0.28801787 0.5078125 ]\n",
            "g_loss : [1.0009928, 1.1473792, 0.9998454]\n",
            "Epoch :1165\n",
            "d_loss : [0.29171878 0.4951172 ]\n",
            "g_loss : [1.2073437, 1.1078339, 1.2062359]\n",
            "Epoch :1166\n",
            "d_loss : [0.2920673  0.49609375]\n",
            "g_loss : [1.8097488, 1.1313839, 1.8086174]\n",
            "Epoch :1167\n",
            "d_loss : [0.29246587 0.5048828 ]\n",
            "g_loss : [1.50347, 1.114816, 1.5023551]\n",
            "Epoch :1168\n",
            "d_loss : [0.29483885 0.50390625]\n",
            "g_loss : [1.5544183, 1.1041322, 1.5533142]\n",
            "Epoch :1169\n",
            "d_loss : [0.28800327 0.5029297 ]\n",
            "g_loss : [1.522086, 1.1121312, 1.5209739]\n",
            "Epoch :1170\n",
            "d_loss : [0.29072565 0.5048828 ]\n",
            "g_loss : [2.0850759, 1.1210678, 2.0839548]\n",
            "Epoch :1171\n",
            "d_loss : [0.2910961  0.50390625]\n",
            "g_loss : [1.181832, 1.1237936, 1.1807082]\n",
            "Epoch :1172\n",
            "d_loss : [0.29148415 0.49902344]\n",
            "g_loss : [1.2426658, 1.1150247, 1.2415507]\n",
            "Epoch :1173\n",
            "d_loss : [0.28923663 0.4951172 ]\n",
            "g_loss : [1.2774217, 1.1191516, 1.2763026]\n",
            "Epoch :1174\n",
            "d_loss : [0.29059455 0.49609375]\n",
            "g_loss : [1.5767108, 1.1071067, 1.5756037]\n",
            "Epoch :1175\n",
            "d_loss : [0.29429048 0.51171875]\n",
            "g_loss : [1.399261, 1.107368, 1.3981537]\n",
            "Epoch :1176\n",
            "d_loss : [0.29276353 0.5126953 ]\n",
            "g_loss : [1.1912463, 1.1009991, 1.1901453]\n",
            "Epoch :1177\n",
            "d_loss : [0.2895931  0.50878906]\n",
            "g_loss : [2.0308654, 1.1483572, 2.029717]\n",
            "Epoch :1178\n",
            "d_loss : [0.2924645  0.48535156]\n",
            "g_loss : [1.2069689, 1.1361822, 1.2058327]\n",
            "Epoch :1179\n",
            "d_loss : [0.28976196 0.49609375]\n",
            "g_loss : [2.2014806, 1.1487446, 2.200332]\n",
            "Epoch :1180\n",
            "d_loss : [0.28991002 0.4921875 ]\n",
            "g_loss : [1.3052711, 1.1365349, 1.3041346]\n",
            "Epoch :1181\n",
            "d_loss : [0.29422393 0.4951172 ]\n",
            "g_loss : [1.612336, 1.1381078, 1.611198]\n",
            "Epoch :1182\n",
            "d_loss : [0.29457116 0.50390625]\n",
            "g_loss : [1.1602743, 1.0910088, 1.1591833]\n",
            "Epoch :1183\n",
            "d_loss : [0.29414713 0.50097656]\n",
            "g_loss : [1.2738248, 1.1211917, 1.2727036]\n",
            "Epoch :1184\n",
            "d_loss : [0.29254392 0.50390625]\n",
            "g_loss : [1.6384414, 1.1382723, 1.6373031]\n",
            "Epoch :1185\n",
            "d_loss : [0.28777808 0.5175781 ]\n",
            "g_loss : [1.0264174, 1.1247075, 1.0252926]\n",
            "Epoch :1186\n",
            "d_loss : [0.29049432 0.5029297 ]\n",
            "g_loss : [1.37935, 1.1315572, 1.3782184]\n",
            "Epoch :1187\n",
            "d_loss : [0.29313782 0.5029297 ]\n",
            "g_loss : [1.2429515, 1.136846, 1.2418146]\n",
            "Epoch :1188\n",
            "d_loss : [0.2892661 0.4970703]\n",
            "g_loss : [0.7659856, 1.1228578, 0.7648628]\n",
            "Epoch :1189\n",
            "d_loss : [0.28953657 0.5126953 ]\n",
            "g_loss : [1.1077349, 1.139219, 1.1065958]\n",
            "Epoch :1190\n",
            "d_loss : [0.29267973 0.5029297 ]\n",
            "g_loss : [1.4573598, 1.1275926, 1.4562322]\n",
            "Epoch :1191\n",
            "d_loss : [0.2894437  0.49804688]\n",
            "g_loss : [1.0603929, 1.1121682, 1.0592806]\n",
            "Epoch :1192\n",
            "d_loss : [0.296286 0.5     ]\n",
            "g_loss : [1.374906, 1.1391436, 1.3737668]\n",
            "Epoch :1193\n",
            "d_loss : [0.29055053 0.5       ]\n",
            "g_loss : [2.2059486, 1.1385055, 2.2048101]\n",
            "Epoch :1194\n",
            "d_loss : [0.29304937 0.48828125]\n",
            "g_loss : [1.4348483, 1.1253104, 1.433723]\n",
            "Epoch :1195\n",
            "d_loss : [0.29197803 0.5058594 ]\n",
            "g_loss : [1.0435061, 1.1301708, 1.0423759]\n",
            "Epoch :1196\n",
            "d_loss : [0.28997597 0.49609375]\n",
            "g_loss : [1.5029157, 1.1167611, 1.501799]\n",
            "Epoch :1197\n",
            "d_loss : [0.29299325 0.5097656 ]\n",
            "g_loss : [1.5417349, 1.1516346, 1.5405833]\n",
            "Epoch :1198\n",
            "d_loss : [0.29042178 0.51171875]\n",
            "g_loss : [2.0467634, 1.1452899, 2.045618]\n",
            "Epoch :1199\n",
            "d_loss : [0.2933008  0.49902344]\n",
            "g_loss : [1.2536614, 1.1241417, 1.2525373]\n",
            "Epoch :1200\n",
            "d_loss : [0.29260546 0.49609375]\n",
            "g_loss : [1.6471676, 1.1308224, 1.6460367]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "PSNR: 21.015185954751942\n",
            "SSIM: 0.7526720400059365\n",
            "Epoch :1201\n",
            "d_loss : [0.2910673 0.4873047]\n",
            "g_loss : [1.1178671, 1.1368859, 1.1167302]\n",
            "Epoch :1202\n",
            "d_loss : [0.29282337 0.48828125]\n",
            "g_loss : [1.4934412, 1.1279709, 1.4923133]\n",
            "Epoch :1203\n",
            "d_loss : [0.29008675 0.5029297 ]\n",
            "g_loss : [1.6824548, 1.1332109, 1.6813216]\n",
            "Epoch :1204\n",
            "d_loss : [0.28844577 0.5058594 ]\n",
            "g_loss : [1.162765, 1.1508377, 1.1616142]\n",
            "Epoch :1205\n",
            "d_loss : [0.29084826 0.5107422 ]\n",
            "g_loss : [1.0745245, 1.1295081, 1.073395]\n",
            "Epoch :1206\n",
            "d_loss : [0.292863 0.5     ]\n",
            "g_loss : [1.7044319, 1.1469572, 1.703285]\n",
            "Epoch :1207\n",
            "d_loss : [0.29383373 0.50097656]\n",
            "g_loss : [0.713322, 1.1389976, 0.712183]\n",
            "Epoch :1208\n",
            "d_loss : [0.2884085 0.5019531]\n",
            "g_loss : [1.5489874, 1.1206033, 1.5478668]\n",
            "Epoch :1209\n",
            "d_loss : [0.2938778  0.49609375]\n",
            "g_loss : [1.8008764, 1.1044346, 1.7997719]\n",
            "Epoch :1210\n",
            "d_loss : [0.28711572 0.50097656]\n",
            "g_loss : [1.5563099, 1.1494303, 1.5551605]\n",
            "Epoch :1211\n",
            "d_loss : [0.2900844  0.50097656]\n",
            "g_loss : [1.5228001, 1.1056192, 1.5216944]\n",
            "Epoch :1212\n",
            "d_loss : [0.2921134 0.4951172]\n",
            "g_loss : [1.3154655, 1.139987, 1.3143255]\n",
            "Epoch :1213\n",
            "d_loss : [0.28816727 0.50097656]\n",
            "g_loss : [1.5097464, 1.129123, 1.5086173]\n",
            "Epoch :1214\n",
            "d_loss : [0.29088292 0.5078125 ]\n",
            "g_loss : [1.0664697, 1.1296356, 1.06534]\n",
            "Epoch :1215\n",
            "d_loss : [0.29364803 0.5058594 ]\n",
            "g_loss : [1.0114858, 1.1225418, 1.0103632]\n",
            "Epoch :1216\n",
            "d_loss : [0.29406685 0.5126953 ]\n",
            "g_loss : [1.4433236, 1.1261246, 1.4421974]\n",
            "Epoch :1217\n",
            "d_loss : [0.29234597 0.49804688]\n",
            "g_loss : [1.0735145, 1.1190434, 1.0723954]\n",
            "Epoch :1218\n",
            "d_loss : [0.29130197 0.5019531 ]\n",
            "g_loss : [0.8734712, 1.1215138, 0.8723497]\n",
            "Epoch :1219\n",
            "d_loss : [0.28801036 0.50097656]\n",
            "g_loss : [1.511647, 1.1123928, 1.5105346]\n",
            "Epoch :1220\n",
            "d_loss : [0.29034615 0.49414062]\n",
            "g_loss : [1.7700707, 1.1271322, 1.7689435]\n",
            "Epoch :1221\n",
            "d_loss : [0.29077506 0.49316406]\n",
            "g_loss : [1.3296771, 1.1265309, 1.3285506]\n",
            "Epoch :1222\n",
            "d_loss : [0.2908384  0.50878906]\n",
            "g_loss : [0.9937095, 1.1394095, 0.9925701]\n",
            "Epoch :1223\n",
            "d_loss : [0.29145372 0.5048828 ]\n",
            "g_loss : [1.3911487, 1.108742, 1.3900399]\n",
            "Epoch :1224\n",
            "d_loss : [0.2885688  0.50097656]\n",
            "g_loss : [1.36368, 1.120644, 1.3625593]\n",
            "Epoch :1225\n",
            "d_loss : [0.29139006 0.5126953 ]\n",
            "g_loss : [1.229311, 1.1148158, 1.2281961]\n",
            "Epoch :1226\n",
            "d_loss : [0.2891671 0.5126953]\n",
            "g_loss : [1.1426688, 1.1292658, 1.1415396]\n",
            "Epoch :1227\n",
            "d_loss : [0.2925932  0.50097656]\n",
            "g_loss : [1.1415635, 1.1239221, 1.1404396]\n",
            "Epoch :1228\n",
            "d_loss : [0.28893358 0.50878906]\n",
            "g_loss : [0.75161636, 1.1059318, 0.75051045]\n",
            "Epoch :1229\n",
            "d_loss : [0.29282546 0.4921875 ]\n",
            "g_loss : [1.4357123, 1.1033324, 1.434609]\n",
            "Epoch :1230\n",
            "d_loss : [0.29281998 0.49316406]\n",
            "g_loss : [1.3339349, 1.0877883, 1.3328471]\n",
            "Epoch :1231\n",
            "d_loss : [0.29215378 0.5097656 ]\n",
            "g_loss : [1.6617213, 1.1345954, 1.6605867]\n",
            "Epoch :1232\n",
            "d_loss : [0.29110435 0.50390625]\n",
            "g_loss : [1.0941759, 1.151752, 1.0930241]\n",
            "Epoch :1233\n",
            "d_loss : [0.290234  0.5058594]\n",
            "g_loss : [1.5200518, 1.1321955, 1.5189196]\n",
            "Epoch :1234\n",
            "d_loss : [0.29455188 0.49414062]\n",
            "g_loss : [1.6001886, 1.1439097, 1.5990447]\n",
            "Epoch :1235\n",
            "d_loss : [0.2913758 0.5      ]\n",
            "g_loss : [1.3405248, 1.1332984, 1.3393915]\n",
            "Epoch :1236\n",
            "d_loss : [0.2950718  0.49804688]\n",
            "g_loss : [1.0825675, 1.1227407, 1.0814447]\n",
            "Epoch :1237\n",
            "d_loss : [0.29066527 0.5029297 ]\n",
            "g_loss : [1.7192839, 1.1400349, 1.7181439]\n",
            "Epoch :1238\n",
            "d_loss : [0.29003465 0.5048828 ]\n",
            "g_loss : [1.2802427, 1.0981753, 1.2791445]\n",
            "Epoch :1239\n",
            "d_loss : [0.2900202 0.5107422]\n",
            "g_loss : [1.1301585, 1.1142765, 1.1290443]\n",
            "Epoch :1240\n",
            "d_loss : [0.29283905 0.5126953 ]\n",
            "g_loss : [1.2794684, 1.1132407, 1.2783551]\n",
            "Epoch :1241\n",
            "d_loss : [0.29258072 0.4970703 ]\n",
            "g_loss : [0.6723649, 1.1556518, 0.6712092]\n",
            "Epoch :1242\n",
            "d_loss : [0.29521158 0.4951172 ]\n",
            "g_loss : [1.6624336, 1.1037623, 1.6613299]\n",
            "Epoch :1243\n",
            "d_loss : [0.2896472  0.51464844]\n",
            "g_loss : [1.3005086, 1.1333687, 1.2993753]\n",
            "Epoch :1244\n",
            "d_loss : [0.295001  0.5048828]\n",
            "g_loss : [1.7871419, 1.1287994, 1.7860131]\n",
            "Epoch :1245\n",
            "d_loss : [0.29228792 0.49902344]\n",
            "g_loss : [1.6947647, 1.1251934, 1.6936395]\n",
            "Epoch :1246\n",
            "d_loss : [0.29074305 0.4951172 ]\n",
            "g_loss : [0.76282716, 1.0971153, 0.76173]\n",
            "Epoch :1247\n",
            "d_loss : [0.28967667 0.5058594 ]\n",
            "g_loss : [1.3440964, 1.1128402, 1.3429836]\n",
            "Epoch :1248\n",
            "d_loss : [0.29108778 0.515625  ]\n",
            "g_loss : [1.064312, 1.1301409, 1.0631819]\n",
            "Epoch :1249\n",
            "d_loss : [0.28802896 0.49804688]\n",
            "g_loss : [2.0017042, 1.1276443, 2.0005765]\n",
            "Epoch :1250\n",
            "d_loss : [0.2919079  0.49902344]\n",
            "g_loss : [1.1544187, 1.1425498, 1.1532762]\n",
            "Epoch :1251\n",
            "d_loss : [0.2897467  0.50097656]\n",
            "g_loss : [1.3086628, 1.1357125, 1.3075271]\n",
            "Epoch :1252\n",
            "d_loss : [0.29046655 0.5058594 ]\n",
            "g_loss : [1.3508065, 1.1405497, 1.3496659]\n",
            "Epoch :1253\n",
            "d_loss : [0.29019487 0.50390625]\n",
            "g_loss : [1.2174299, 1.1350949, 1.2162948]\n",
            "Epoch :1254\n",
            "d_loss : [0.28981307 0.49609375]\n",
            "g_loss : [1.6895963, 1.1388628, 1.6884575]\n",
            "Epoch :1255\n",
            "d_loss : [0.29097784 0.5029297 ]\n",
            "g_loss : [2.0369422, 1.1188834, 2.0358233]\n",
            "Epoch :1256\n",
            "d_loss : [0.29223895 0.5048828 ]\n",
            "g_loss : [1.11614, 1.1137432, 1.1150262]\n",
            "Epoch :1257\n",
            "d_loss : [0.29176104 0.4951172 ]\n",
            "g_loss : [1.4494896, 1.1253272, 1.4483643]\n",
            "Epoch :1258\n",
            "d_loss : [0.29206008 0.484375  ]\n",
            "g_loss : [0.8712203, 1.1611814, 0.87005913]\n",
            "Epoch :1259\n",
            "d_loss : [0.29211858 0.5029297 ]\n",
            "g_loss : [1.1033901, 1.1374176, 1.1022527]\n",
            "Epoch :1260\n",
            "d_loss : [0.2946057  0.49804688]\n",
            "g_loss : [1.4817469, 1.1195812, 1.4806273]\n",
            "Epoch :1261\n",
            "d_loss : [0.29375267 0.49316406]\n",
            "g_loss : [1.7698061, 1.131634, 1.7686745]\n",
            "Epoch :1262\n",
            "d_loss : [0.29329798 0.48632812]\n",
            "g_loss : [1.2379252, 1.1285317, 1.2367966]\n",
            "Epoch :1263\n",
            "d_loss : [0.29435754 0.5078125 ]\n",
            "g_loss : [1.2326816, 1.1266131, 1.231555]\n",
            "Epoch :1264\n",
            "d_loss : [0.28949627 0.49609375]\n",
            "g_loss : [1.0286719, 1.1451993, 1.0275266]\n",
            "Epoch :1265\n",
            "d_loss : [0.2937218  0.49414062]\n",
            "g_loss : [1.4291372, 1.1187174, 1.4280186]\n",
            "Epoch :1266\n",
            "d_loss : [0.2862601  0.49121094]\n",
            "g_loss : [1.7535646, 1.1201395, 1.7524445]\n",
            "Epoch :1267\n",
            "d_loss : [0.29251152 0.5019531 ]\n",
            "g_loss : [1.23412, 1.1240797, 1.232996]\n",
            "Epoch :1268\n",
            "d_loss : [0.2918943  0.50390625]\n",
            "g_loss : [1.2828239, 1.1299748, 1.2816939]\n",
            "Epoch :1269\n",
            "d_loss : [0.2912982  0.49121094]\n",
            "g_loss : [1.6055888, 1.1460979, 1.6044427]\n",
            "Epoch :1270\n",
            "d_loss : [0.28956473 0.49804688]\n",
            "g_loss : [0.9655986, 1.1527357, 0.9644458]\n",
            "Epoch :1271\n",
            "d_loss : [0.28653753 0.5136719 ]\n",
            "g_loss : [1.0878354, 1.1415055, 1.0866939]\n",
            "Epoch :1272\n",
            "d_loss : [0.29366392 0.49121094]\n",
            "g_loss : [1.1809437, 1.1330881, 1.1798106]\n",
            "Epoch :1273\n",
            "d_loss : [0.29518822 0.4951172 ]\n",
            "g_loss : [1.1423558, 1.1243627, 1.1412314]\n",
            "Epoch :1274\n",
            "d_loss : [0.2874636  0.51171875]\n",
            "g_loss : [1.1221488, 1.1189125, 1.1210299]\n",
            "Epoch :1275\n",
            "d_loss : [0.29359713 0.484375  ]\n",
            "g_loss : [1.3536035, 1.1260316, 1.3524774]\n",
            "Epoch :1276\n",
            "d_loss : [0.29047242 0.5097656 ]\n",
            "g_loss : [1.1423569, 1.1311002, 1.1412258]\n",
            "Epoch :1277\n",
            "d_loss : [0.28781626 0.5       ]\n",
            "g_loss : [1.7455012, 1.1380627, 1.7443631]\n",
            "Epoch :1278\n",
            "d_loss : [0.28757545 0.51171875]\n",
            "g_loss : [2.1674998, 1.1448302, 2.166355]\n",
            "Epoch :1279\n",
            "d_loss : [0.28992406 0.5078125 ]\n",
            "g_loss : [1.0820594, 1.1309909, 1.0809284]\n",
            "Epoch :1280\n",
            "d_loss : [0.2920114  0.50390625]\n",
            "g_loss : [1.7231166, 1.1155546, 1.7220011]\n",
            "Epoch :1281\n",
            "d_loss : [0.29281324 0.4951172 ]\n",
            "g_loss : [0.91946155, 1.1561317, 0.9183054]\n",
            "Epoch :1282\n",
            "d_loss : [0.29132444 0.4951172 ]\n",
            "g_loss : [1.4688298, 1.1103555, 1.4677194]\n",
            "Epoch :1283\n",
            "d_loss : [0.29268527 0.48046875]\n",
            "g_loss : [1.5665879, 1.1039913, 1.5654839]\n",
            "Epoch :1284\n",
            "d_loss : [0.29266244 0.4951172 ]\n",
            "g_loss : [1.4104321, 1.1200154, 1.4093121]\n",
            "Epoch :1285\n",
            "d_loss : [0.29120266 0.49609375]\n",
            "g_loss : [1.1971494, 1.1473405, 1.196002]\n",
            "Epoch :1286\n",
            "d_loss : [0.28405675 0.5136719 ]\n",
            "g_loss : [1.5692014, 1.1142701, 1.5680871]\n",
            "Epoch :1287\n",
            "d_loss : [0.29150945 0.49804688]\n",
            "g_loss : [1.1087998, 1.1473905, 1.1076524]\n",
            "Epoch :1288\n",
            "d_loss : [0.2893613  0.48632812]\n",
            "g_loss : [1.726072, 1.1361617, 1.7249358]\n",
            "Epoch :1289\n",
            "d_loss : [0.28896847 0.49121094]\n",
            "g_loss : [1.9555491, 1.1205577, 1.9544286]\n",
            "Epoch :1290\n",
            "d_loss : [0.2916239 0.5029297]\n",
            "g_loss : [1.2388111, 1.1060257, 1.2377051]\n",
            "Epoch :1291\n",
            "d_loss : [0.29164833 0.50097656]\n",
            "g_loss : [1.8509623, 1.1439996, 1.8498182]\n",
            "Epoch :1292\n",
            "d_loss : [0.29224497 0.4951172 ]\n",
            "g_loss : [1.3605055, 1.1398308, 1.3593656]\n",
            "Epoch :1293\n",
            "d_loss : [0.29044914 0.5019531 ]\n",
            "g_loss : [1.1135293, 1.1333721, 1.112396]\n",
            "Epoch :1294\n",
            "d_loss : [0.28990337 0.5       ]\n",
            "g_loss : [1.0838673, 1.1124508, 1.0827549]\n",
            "Epoch :1295\n",
            "d_loss : [0.29106054 0.5019531 ]\n",
            "g_loss : [1.2443256, 1.147505, 1.2431781]\n",
            "Epoch :1296\n",
            "d_loss : [0.29160124 0.50390625]\n",
            "g_loss : [1.6095631, 1.1292081, 1.608434]\n",
            "Epoch :1297\n",
            "d_loss : [0.29434466 0.5175781 ]\n",
            "g_loss : [1.2039592, 1.1329596, 1.2028263]\n",
            "Epoch :1298\n",
            "d_loss : [0.29455948 0.50097656]\n",
            "g_loss : [0.90217036, 1.1264818, 0.9010439]\n",
            "Epoch :1299\n",
            "d_loss : [0.29178673 0.5078125 ]\n",
            "g_loss : [1.7497067, 1.1154827, 1.7485913]\n",
            "Epoch :1300\n",
            "d_loss : [0.2921968 0.5019531]\n",
            "g_loss : [1.5284001, 1.1387858, 1.5272613]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "PSNR: 23.959163385816886\n",
            "SSIM: 0.8342429422850387\n",
            "Epoch :1301\n",
            "d_loss : [0.2912364  0.51660156]\n",
            "g_loss : [0.7412559, 1.1416776, 0.7401142]\n",
            "Epoch :1302\n",
            "d_loss : [0.29392183 0.5019531 ]\n",
            "g_loss : [1.4100561, 1.1424459, 1.4089136]\n",
            "Epoch :1303\n",
            "d_loss : [0.29240286 0.5126953 ]\n",
            "g_loss : [0.6824068, 1.137397, 0.6812694]\n",
            "Epoch :1304\n",
            "d_loss : [0.28898704 0.515625  ]\n",
            "g_loss : [1.170627, 1.1149182, 1.169512]\n",
            "Epoch :1305\n",
            "d_loss : [0.2892226  0.50878906]\n",
            "g_loss : [1.134789, 1.1179018, 1.133671]\n",
            "Epoch :1306\n",
            "d_loss : [0.29502842 0.4951172 ]\n",
            "g_loss : [1.2942497, 1.1285712, 1.2931211]\n",
            "Epoch :1307\n",
            "d_loss : [0.29256815 0.49414062]\n",
            "g_loss : [0.9706725, 1.119249, 0.96955323]\n",
            "Epoch :1308\n",
            "d_loss : [0.29159963 0.4970703 ]\n",
            "g_loss : [1.8830054, 1.1303012, 1.881875]\n",
            "Epoch :1309\n",
            "d_loss : [0.29116553 0.49121094]\n",
            "g_loss : [1.0562005, 1.1209085, 1.0550796]\n",
            "Epoch :1310\n",
            "d_loss : [0.29353765 0.50097656]\n",
            "g_loss : [0.9501758, 1.109869, 0.9490659]\n",
            "Epoch :1311\n",
            "d_loss : [0.29171285 0.49609375]\n",
            "g_loss : [0.9582318, 1.1552501, 0.95707655]\n",
            "Epoch :1312\n",
            "d_loss : [0.29004702 0.5       ]\n",
            "g_loss : [1.0837818, 1.1435639, 1.0826383]\n",
            "Epoch :1313\n",
            "d_loss : [0.28822345 0.5       ]\n",
            "g_loss : [1.4826175, 1.1331192, 1.4814844]\n",
            "Epoch :1314\n",
            "d_loss : [0.29296085 0.49121094]\n",
            "g_loss : [1.1795106, 1.1388109, 1.1783718]\n",
            "Epoch :1315\n",
            "d_loss : [0.29211676 0.5058594 ]\n",
            "g_loss : [1.2676467, 1.1269258, 1.2665198]\n",
            "Epoch :1316\n",
            "d_loss : [0.289166  0.5136719]\n",
            "g_loss : [1.5977571, 1.1300886, 1.596627]\n",
            "Epoch :1317\n",
            "d_loss : [0.2946025  0.49609375]\n",
            "g_loss : [1.2651634, 1.1265464, 1.2640369]\n",
            "Epoch :1318\n",
            "d_loss : [0.29256195 0.50390625]\n",
            "g_loss : [1.4064405, 1.1187856, 1.4053217]\n",
            "Epoch :1319\n",
            "d_loss : [0.28985038 0.5029297 ]\n",
            "g_loss : [1.1066071, 1.1203239, 1.1054868]\n",
            "Epoch :1320\n",
            "d_loss : [0.29049572 0.4951172 ]\n",
            "g_loss : [1.139492, 1.1253374, 1.1383667]\n",
            "Epoch :1321\n",
            "d_loss : [0.2929721  0.49609375]\n",
            "g_loss : [1.2773546, 1.1198053, 1.2762347]\n",
            "Epoch :1322\n",
            "d_loss : [0.29491916 0.4873047 ]\n",
            "g_loss : [1.1689675, 1.130801, 1.1678367]\n",
            "Epoch :1323\n",
            "d_loss : [0.2895404 0.5126953]\n",
            "g_loss : [1.1345105, 1.1207561, 1.1333897]\n",
            "Epoch :1324\n",
            "d_loss : [0.28984115 0.50097656]\n",
            "g_loss : [0.7940075, 1.1444006, 0.7928631]\n",
            "Epoch :1325\n",
            "d_loss : [0.28966942 0.5097656 ]\n",
            "g_loss : [1.1509708, 1.1216168, 1.1498492]\n",
            "Epoch :1326\n",
            "d_loss : [0.28798488 0.5126953 ]\n",
            "g_loss : [1.7958989, 1.1468189, 1.7947521]\n",
            "Epoch :1327\n",
            "d_loss : [0.29252124 0.4921875 ]\n",
            "g_loss : [1.3641024, 1.1088226, 1.3629936]\n",
            "Epoch :1328\n",
            "d_loss : [0.29425985 0.48535156]\n",
            "g_loss : [1.5191743, 1.1020056, 1.5180724]\n",
            "Epoch :1329\n",
            "d_loss : [0.29278266 0.49121094]\n",
            "g_loss : [1.2359544, 1.124691, 1.2348297]\n",
            "Epoch :1330\n",
            "d_loss : [0.2929538  0.49316406]\n",
            "g_loss : [1.0759201, 1.1278764, 1.0747923]\n",
            "Epoch :1331\n",
            "d_loss : [0.29092628 0.49902344]\n",
            "g_loss : [1.258455, 1.1288661, 1.2573261]\n",
            "Epoch :1332\n",
            "d_loss : [0.29371697 0.4892578 ]\n",
            "g_loss : [0.89333516, 1.1377971, 0.8921974]\n",
            "Epoch :1333\n",
            "d_loss : [0.29559982 0.49121094]\n",
            "g_loss : [1.4932619, 1.1385927, 1.4921234]\n",
            "Epoch :1334\n",
            "d_loss : [0.2902276 0.5029297]\n",
            "g_loss : [0.97472316, 1.1306221, 0.9735925]\n",
            "Epoch :1335\n",
            "d_loss : [0.294268   0.48828125]\n",
            "g_loss : [1.2492197, 1.1164825, 1.2481031]\n",
            "Epoch :1336\n",
            "d_loss : [0.2912752 0.5      ]\n",
            "g_loss : [0.951781, 1.1279218, 0.9506531]\n",
            "Epoch :1337\n",
            "d_loss : [0.29547316 0.5       ]\n",
            "g_loss : [1.1559765, 1.1268549, 1.1548496]\n",
            "Epoch :1338\n",
            "d_loss : [0.29220924 0.50390625]\n",
            "g_loss : [1.6840731, 1.1435136, 1.6829296]\n",
            "Epoch :1339\n",
            "d_loss : [0.29155943 0.4951172 ]\n",
            "g_loss : [1.7508259, 1.0839064, 1.749742]\n",
            "Epoch :1340\n",
            "d_loss : [0.29333413 0.515625  ]\n",
            "g_loss : [1.4677203, 1.1285129, 1.4665917]\n",
            "Epoch :1341\n",
            "d_loss : [0.29171008 0.49609375]\n",
            "g_loss : [1.4401871, 1.1089859, 1.4390781]\n",
            "Epoch :1342\n",
            "d_loss : [0.2920125 0.5048828]\n",
            "g_loss : [1.0409948, 1.1326618, 1.0398622]\n",
            "Epoch :1343\n",
            "d_loss : [0.2924679  0.49804688]\n",
            "g_loss : [0.8128129, 1.1340165, 0.8116789]\n",
            "Epoch :1344\n",
            "d_loss : [0.29472202 0.5107422 ]\n",
            "g_loss : [0.6688875, 1.1354527, 0.667752]\n",
            "Epoch :1345\n",
            "d_loss : [0.28928047 0.50390625]\n",
            "g_loss : [1.0275335, 1.130548, 1.026403]\n",
            "Epoch :1346\n",
            "d_loss : [0.29235715 0.49414062]\n",
            "g_loss : [1.1104792, 1.1337531, 1.1093454]\n",
            "Epoch :1347\n",
            "d_loss : [0.2927912  0.49609375]\n",
            "g_loss : [1.1992359, 1.139663, 1.1980963]\n",
            "Epoch :1348\n",
            "d_loss : [0.28826314 0.5029297 ]\n",
            "g_loss : [1.5910448, 1.1450619, 1.5898998]\n",
            "Epoch :1349\n",
            "d_loss : [0.29352707 0.49902344]\n",
            "g_loss : [0.88676286, 1.1316025, 0.88563126]\n",
            "Epoch :1350\n",
            "d_loss : [0.2886446 0.5205078]\n",
            "g_loss : [1.3897347, 1.1022553, 1.3886325]\n",
            "Epoch :1351\n",
            "d_loss : [0.29263914 0.5078125 ]\n",
            "g_loss : [1.4878474, 1.1279191, 1.4867195]\n",
            "Epoch :1352\n",
            "d_loss : [0.2931515 0.5058594]\n",
            "g_loss : [1.1790977, 1.1282856, 1.1779693]\n",
            "Epoch :1353\n",
            "d_loss : [0.28871608 0.4921875 ]\n",
            "g_loss : [1.3717864, 1.1241261, 1.3706622]\n",
            "Epoch :1354\n",
            "d_loss : [0.2907228  0.50390625]\n",
            "g_loss : [1.3559862, 1.104941, 1.3548813]\n",
            "Epoch :1355\n",
            "d_loss : [0.28768027 0.5078125 ]\n",
            "g_loss : [2.0459096, 1.1361616, 2.0447736]\n",
            "Epoch :1356\n",
            "d_loss : [0.29270256 0.4873047 ]\n",
            "g_loss : [1.0738453, 1.1218503, 1.0727234]\n",
            "Epoch :1357\n",
            "d_loss : [0.29121807 0.49609375]\n",
            "g_loss : [0.85284454, 1.135455, 0.85170907]\n",
            "Epoch :1358\n",
            "d_loss : [0.29235077 0.50390625]\n",
            "g_loss : [1.2649474, 1.1226747, 1.2638247]\n",
            "Epoch :1359\n",
            "d_loss : [0.29145062 0.4951172 ]\n",
            "g_loss : [1.1130742, 1.1318995, 1.1119423]\n",
            "Epoch :1360\n",
            "d_loss : [0.29161173 0.5058594 ]\n",
            "g_loss : [1.1875162, 1.1150833, 1.1864011]\n",
            "Epoch :1361\n",
            "d_loss : [0.28919688 0.5185547 ]\n",
            "g_loss : [0.8531742, 1.1096995, 0.8520645]\n",
            "Epoch :1362\n",
            "d_loss : [0.29257727 0.48535156]\n",
            "g_loss : [1.1876457, 1.1559527, 1.1864897]\n",
            "Epoch :1363\n",
            "d_loss : [0.29360607 0.5126953 ]\n",
            "g_loss : [1.1485432, 1.105371, 1.1474378]\n",
            "Epoch :1364\n",
            "d_loss : [0.2901113 0.4970703]\n",
            "g_loss : [1.2600235, 1.1209623, 1.2589025]\n",
            "Epoch :1365\n",
            "d_loss : [0.2883043 0.5029297]\n",
            "g_loss : [1.6337805, 1.1036148, 1.6326768]\n",
            "Epoch :1366\n",
            "d_loss : [0.2918322  0.49316406]\n",
            "g_loss : [1.2966259, 1.1446854, 1.2954812]\n",
            "Epoch :1367\n",
            "d_loss : [0.29479498 0.4892578 ]\n",
            "g_loss : [0.78667825, 1.143605, 0.7855346]\n",
            "Epoch :1368\n",
            "d_loss : [0.2901407 0.5078125]\n",
            "g_loss : [1.3056074, 1.1223154, 1.3044851]\n",
            "Epoch :1369\n",
            "d_loss : [0.29049477 0.4970703 ]\n",
            "g_loss : [1.1946245, 1.1233244, 1.1935012]\n",
            "Epoch :1370\n",
            "d_loss : [0.28980166 0.49609375]\n",
            "g_loss : [1.326956, 1.1226428, 1.3258334]\n",
            "Epoch :1371\n",
            "d_loss : [0.28962463 0.51464844]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxh_Bst-edHq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}